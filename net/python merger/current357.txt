
========================================
# File: /home/jarvis/Downloads/WhatNowAI_test/app.py
========================================

"""
WhatNowAI Flask Application

An intelligent activity recommendation system that helps users discover local events 
and activities based on their location, interests, and preferences. Features include:

- Multi-step onboarding with text-to-speech guidance
- Ticketmaster API integration for event discovery
- Interactive maps with event visualization
- Background research for personalized recommendations
"""
import logging.config
from flask import Flask

from routes import main_bp
from config.settings import FLASK_CONFIG, LOGGING_CONFIG, AUDIO_DIR, check_api_keys
from services.tts_service import TTSService

# Configure logging
logging.config.dictConfig(LOGGING_CONFIG)
logger = logging.getLogger(__name__)


def create_app() -> Flask:
    """
    Application factory function
    
    Returns:
        Configured Flask application instance
    """
    app = Flask(__name__)
    
    # Register blueprints
    app.register_blueprint(main_bp)
    
    # Initialize services
    tts_service = TTSService(str(AUDIO_DIR))
    
    # Cleanup old audio files on startup
    try:
        tts_service.cleanup_old_audio()
        logger.info("Audio cleanup completed")
    except Exception as e:
        logger.warning(f"Audio cleanup failed: {e}")
    
    logger.info("WhatNowAI application initialized successfully")
    return app


def main():
    """Main entry point"""
    # Check API keys on startup
    check_api_keys()
    
    app = create_app()
    
    logger.info(f"Starting WhatNowAI on {FLASK_CONFIG['HOST']}:{FLASK_CONFIG['PORT']}")
    app.run(
        debug=FLASK_CONFIG['DEBUG'],
        host=FLASK_CONFIG['HOST'],
        port=FLASK_CONFIG['PORT']
    )


if __name__ == '__main__':
    main()

========================================
# File: /home/jarvis/Downloads/WhatNowAI_test/routes.py
========================================

"""
Flask application routes for WhatNowAI

This module defines all the API endpoints for the WhatNowAI application, including:
- Onboarding flow with TTS integration
- Location services and geocoding
- Event discovery and mapping
- Background research and personalization
"""
from flask import Blueprint, render_template, request, jsonify, abort, send_file
import logging
from typing import Dict, Any

from services.tts_service import TTSService, get_introduction_text, INTRODUCTION_TEXTS
from services.geocoding_service import GeocodingService
from services.ticketmaster_service import TicketmasterService
from services.allevents_service import AllEventsService
from services.mapping_service import MappingService
from services.user_profiling_service import EnhancedUserProfilingService
from utils.helpers import validate_coordinates, generate_response_text
from config.settings import (AUDIO_DIR, DEFAULT_TTS_VOICE, TICKETMASTER_API_KEY, ALLEVENTS_API_KEY,
                           TICKETMASTER_CONFIG, ALLEVENTS_CONFIG, MAP_CONFIG)
from searchmethods.background_search import UserProfile, perform_background_search

logger = logging.getLogger(__name__)

# Create blueprint
main_bp = Blueprint('main', __name__)

# Initialize services
tts_service = TTSService(str(AUDIO_DIR), DEFAULT_TTS_VOICE)
geocoding_service = GeocodingService()
ticketmaster_service = TicketmasterService(TICKETMASTER_API_KEY, TICKETMASTER_CONFIG)
allevents_service = AllEventsService(ALLEVENTS_API_KEY, ALLEVENTS_CONFIG)
mapping_service = MappingService(MAP_CONFIG)
user_profiling_service = EnhancedUserProfilingService()


@main_bp.route('/')
def home():
    """Render the homepage with the form"""
    return render_template('home.html')


@main_bp.route('/tts/introduction/<step>', methods=['POST'])
def generate_introduction_tts(step: str):
    """Generate TTS for introduction steps"""
    try:
        # Get any location data from request for context
        data = request.get_json() if request.is_json else {}
        location_data = data.get('location')
        
        # Generate dynamic text based on time and location
        text = get_introduction_text(step, location_data)
        
        # Fallback to static text if dynamic generation fails
        if not text:
            text = INTRODUCTION_TEXTS.get(step)
            
        if not text:
            return jsonify({
                'success': False,
                'message': 'Invalid introduction step'
            }), 400
        
        audio_id, audio_path = tts_service.generate_audio_sync(text)
        
        if audio_id:
            return jsonify({
                'success': True,
                'audio_id': audio_id,
                'text': text
            })
        else:
            return jsonify({
                'success': False,
                'message': 'Failed to generate audio'
            }), 500
            
    except Exception as e:
        logger.error(f"Error generating introduction TTS: {e}")
        return jsonify({
            'success': False,
            'message': 'An error occurred while generating audio'
        }), 500


@main_bp.route('/submit', methods=['POST'])
def submit_info():
    """Handle form submission with user's name and activity"""
    try:
        data = request.get_json()
        name = data.get('name', '').strip()
        activity = data.get('activity', '').strip()
        social = data.get('social', {})
        
        if not name or not activity:
            return jsonify({
                'success': False,
                'message': 'Please provide both your name and what you want to do.'
            }), 400
        
        # Process the user input - start background processing
        response_message = f"Hello {name}! I'm processing your request to {activity}. Please wait while I work on this..."
        
        return jsonify({
            'success': True,
            'message': response_message,
            'name': name,
            'activity': activity,
            'social': social,
            'processing': True
        })
    
    except Exception as e:
        logger.error(f"Error in submit_info: {e}")
        return jsonify({
            'success': False,
            'message': 'An error occurred while processing your request.'
        }), 500


@main_bp.route('/chat', methods=['POST'])
def chat():
    """Handle chat messages"""
    try:
        data = request.get_json()
        message = data.get('message', '').strip()
        
        if not message:
            return jsonify({
                'success': False,
                'message': 'Please provide a message.'
            }), 400
        
        # Simple response logic (you can enhance this with AI)
        response = f"I received your message: '{message}'. How can I help you further?"
        
        return jsonify({
            'success': True,
            'response': response
        })
    
    except Exception as e:
        logger.error(f"Error in chat: {e}")
        return jsonify({
            'success': False,
            'message': 'An error occurred while processing your message.'
        }), 500


@main_bp.route('/process', methods=['POST'])
def process_request():
    """Handle background processing of user request"""
    try:
        data = request.get_json()
        name = data.get('name', '').strip()
        activity = data.get('activity', '').strip()
        location_data = data.get('location', {})
        social_data = data.get('social', {})
        
        if not name or not activity:
            return jsonify({
                'success': False,
                'message': 'Missing name or activity information.'
            }), 400
        
        # Perform background search
        logger.info(f"Starting background search for user: {name}")
        
        # Create user profile for search
        user_profile = UserProfile(
            name=name,
            location=location_data.get('city', '') + ', ' + location_data.get('country', ''),
            social_handles={
                'twitter': social_data.get('twitter', ''),
                'instagram': social_data.get('instagram', ''),
                'github': social_data.get('github', ''),
                'linkedin': social_data.get('linkedin', ''),
                'tiktok': social_data.get('tiktok', ''),
                'youtube': social_data.get('youtube', '')
            },
            activity=activity
        )
        
        # Perform background search (this may take some time)
        search_results = None
        search_summaries = None
        
        try:
            search_data = perform_background_search(user_profile)
            search_results = search_data.get('raw_results', {})
            search_summaries = search_data.get('summaries', {})
            logger.info(f"Background search completed. Found {search_data.get('total_results', 0)} total results")
        except Exception as search_error:
            logger.warning(f"Background search failed: {search_error}")
            search_summaries = {
                'general': 'Background search temporarily unavailable.',
                'social': 'Social media search temporarily unavailable.',
                'location': 'Location search temporarily unavailable.',
                'activity': 'Activity search temporarily unavailable.'
            }
        
        # Generate response text with search context
        result = generate_response_text(name, activity, location_data, social_data, search_summaries)
        
        # Create enhanced user profile using the new profiling service
        enhanced_user_profile = None
        try:
            enhanced_user_profile = user_profiling_service.create_enhanced_profile(
                name=name,
                location=location_data,
                activity=activity,
                social_data=social_data,
                search_results={
                    'search_results': search_results,
                    'search_summaries': search_summaries
                }
            )
            logger.info(f"Enhanced user profile created with {enhanced_user_profile.profile_completion:.1f}% completion")
            
            # Get recommendation context for events
            recommendation_context = user_profiling_service.get_recommendation_context(enhanced_user_profile)
            
        except Exception as profile_error:
            logger.warning(f"Enhanced user profiling failed: {profile_error}")
            recommendation_context = {}
        
        # Prepare personalization data for later use
        personalization_data = {
            'search_results': search_results,
            'search_summaries': search_summaries,
            'user_profile': {
                'name': name,
                'activity': activity,
                'location': location_data,
                'social': social_data
            },
            'enhanced_profile': recommendation_context,  # Include enhanced profile context
            'activity': activity  # Ensure activity is available at top level
        }
        
        return jsonify({
            'success': True,
            'result': result,
            'name': name,
            'activity': activity,
            'location': location_data,
            'social': social_data,
            'search_summaries': search_summaries,
            'personalization_data': personalization_data,  # Include personalization data
            'enhanced_profile_completion': enhanced_user_profile.profile_completion if enhanced_user_profile else 0,
            'total_search_results': len(search_results) if search_results else 0,
            'redirect_to_map': True,  # Signal frontend to redirect to map
            'map_url': '/map'
        })
    
    except Exception as e:
        logger.error(f"Error in process_request: {e}")
        return jsonify({
            'success': False,
            'message': 'An error occurred while processing your request.'
        }), 500


@main_bp.route('/geocode', methods=['POST'])
def reverse_geocode():
    """Reverse geocode latitude/longitude to get address information"""
    try:
        data = request.get_json()
        latitude = data.get('latitude')
        longitude = data.get('longitude')
        
        # Try to convert to float if they're strings
        try:
            if latitude is not None:
                latitude = float(latitude)
            if longitude is not None:
                longitude = float(longitude)
        except (ValueError, TypeError) as e:
            logger.error(f"Failed to convert coordinates to float in geocode: {e}")
            return jsonify({
                'success': False,
                'message': 'Invalid coordinate format. Coordinates must be numbers.'
            }), 400
        
        if not validate_coordinates(latitude, longitude):
            return jsonify({
                'success': False,
                'message': 'Invalid latitude or longitude coordinates.'
            }), 400
        
        location_info = geocoding_service.reverse_geocode(latitude, longitude)
        
        if location_info:
            return jsonify({
                'success': True,
                'location': location_info
            })
        else:
            return jsonify({
                'success': False,
                'message': 'Failed to geocode location.'
            }), 500
            
    except Exception as e:
        logger.error(f"Error in reverse_geocode: {e}")
        return jsonify({
            'success': False,
            'message': 'An error occurred while processing location.'
        }), 500


@main_bp.route('/audio/<audio_id>')
def serve_audio(audio_id: str):
    """Serve generated audio files"""
    try:
        if not tts_service.audio_exists(audio_id):
            abort(404)
        
        audio_path = tts_service.get_audio_path(audio_id)
        return send_file(audio_path, mimetype='audio/mpeg')
        
    except Exception as e:
        logger.error(f"Audio serve error: {e}")
        abort(500)


@main_bp.route('/map/events', methods=['POST'])
def get_map_events():
    """Get events and activities for map display"""
    try:
        data = request.get_json()
        location_data = data.get('location', {})
        user_interests = data.get('interests', [])
        user_activity = data.get('activity', '')
        personalization_data = data.get('personalization_data', {})  # Enhanced personalization data
        
        # Debug logging for incoming request
        logger.info(f"=== DEBUG: Incoming request data ===")
        logger.info(f"Location data: {location_data}")
        logger.info(f"User interests: {user_interests}")
        logger.info(f"User activity: '{user_activity}'")
        logger.info(f"Personalization data keys: {list(personalization_data.keys()) if personalization_data else 'None'}")
        logger.info(f"Full request data keys: {list(data.keys())}")
        
        # If no personalization data, try to construct basic context from available data
        if not personalization_data:
            logger.warning("No personalization_data in request, attempting to construct basic context")
            
            # Check if user data is available in the request directly
            user_name = data.get('name', '')
            user_social = data.get('social', {})
            
            if user_name or user_activity or user_social:
                logger.info(f"Found basic user data: name='{user_name}', activity='{user_activity}', social={bool(user_social)}")
                
                # Create minimal personalization context
                personalization_data = {
                    'user_profile': {
                        'name': user_name,
                        'activity': user_activity,
                        'location': location_data,
                        'social': user_social
                    },
                    'activity': user_activity,
                    'basic_context': True
                }
                logger.info("Created basic personalization context from request data")
            else:
                logger.warning("No user context data available in request")
        
        latitude = location_data.get('latitude')
        longitude = location_data.get('longitude')
        
        # Debug logging
        logger.info(f"Received location_data: {location_data}")
        logger.info(f"Raw coordinates - lat: {latitude} (type: {type(latitude)}), lon: {longitude} (type: {type(longitude)})")
        
        # Try to convert to float if they're strings
        try:
            if latitude is not None:
                latitude = float(latitude)
            if longitude is not None:
                longitude = float(longitude)
        except (ValueError, TypeError) as e:
            logger.error(f"Failed to convert coordinates to float: {e}")
            return jsonify({
                'success': False,
                'message': 'Invalid coordinate format. Coordinates must be numbers.'
            }), 400
        
        if not validate_coordinates(latitude, longitude):
            logger.error(f"Got invalid coordinates: {latitude}, {longitude}")
            return jsonify({
                'success': False,
                'message': 'Valid location is required. Please go back to onboarding and share your location to find events near you.'
            }), 400
        
        # Clear previous markers
        mapping_service.clear_markers()
        
        # Get events from Ticketmaster with enhanced profiling
        logger.info(f"Searching Ticketmaster events for location: {latitude}, {longitude}")
        logger.info(f"Received personalization_data keys: {list(personalization_data.keys()) if personalization_data else 'None'}")
        logger.info(f"User activity from request: '{user_activity}'")
        
        try:
            # Extract enhanced profile data if available
            enhanced_profile_data = personalization_data.get('enhanced_profile', {})
            logger.info(f"Enhanced profile data available: {bool(enhanced_profile_data)}")
            
            # Create a user profile object for the AI analysis
            user_profile_for_ai = None
            if enhanced_profile_data:
                user_profile_for_ai = enhanced_profile_data
                logger.info(f"Using enhanced profile with {len(enhanced_profile_data.get('interests', []))} interests")
            elif personalization_data.get('user_profile'):
                # Fallback to basic profile data
                basic_profile = personalization_data['user_profile']
                user_profile_for_ai = {
                    'name': basic_profile.get('name', ''),
                    'location': basic_profile.get('location', {}),
                    'primary_activity': basic_profile.get('activity', user_activity),  # Use current activity if not in profile
                    'interests': [],
                    'preferences': {'activity_style': 'balanced'},
                    'behavioral_patterns': {},
                    'activity_context': {'intent': 'seeking'},
                    'completion_score': 25  # Basic completion
                }
                logger.info(f"Using basic profile fallback for user: {basic_profile.get('name', 'Anonymous')}")
            elif user_activity:
                # Create minimal profile from just the activity
                user_profile_for_ai = {
                    'name': 'Anonymous',
                    'location': location_data,
                    'primary_activity': user_activity,
                    'interests': [],
                    'preferences': {'activity_style': 'balanced'},
                    'behavioral_patterns': {},
                    'activity_context': {'intent': 'seeking'},
                    'completion_score': 10  # Minimal completion
                }
                logger.info(f"Created minimal profile from activity: '{user_activity}'")
            else:
                logger.warning("No personalization data available - will use basic search only")
            
            ticketmaster_events = ticketmaster_service.search_events(
                location=location_data,
                user_interests=user_interests,
                user_activity=user_activity,
                personalization_data=personalization_data,
                user_profile=user_profile_for_ai  # Pass enhanced profile to AI ranking
            )
            
            if ticketmaster_events:
                mapping_service.add_ticketmaster_events(ticketmaster_events)
                logger.info(f"Added {len(ticketmaster_events)} Ticketmaster events to map")
            else:
                logger.info("No Ticketmaster events found")
                
        except Exception as tm_error:
            logger.warning(f"Ticketmaster search failed: {tm_error}")
        
        # Get events from AllEvents with enhanced profiling
        logger.info(f"Searching AllEvents events for location: {latitude}, {longitude}")
        
        try:
            allevents_events = allevents_service.search_events(
                location=location_data,
                user_interests=user_interests,
                user_activity=user_activity,
                personalization_data=personalization_data,
                user_profile=user_profile_for_ai  # Pass enhanced profile to AI ranking
            )
            
            if allevents_events:
                mapping_service.add_allevents_events(allevents_events)
                logger.info(f"Added {len(allevents_events)} AllEvents events to map")
            else:
                logger.info("No AllEvents events found")
                
        except Exception as ae_error:
            logger.warning(f"AllEvents search failed: {ae_error}")
        
        # TODO: Add other API integrations here
        # mapping_service.add_eventbrite_events(eventbrite_events)
        # mapping_service.add_meetup_events(meetup_events)
        
        # Get map data
        map_data = mapping_service.get_map_data(latitude, longitude)
        category_stats = mapping_service.get_category_stats()
        
        return jsonify({
            'success': True,
            'map_data': map_data,
            'category_stats': category_stats,
            'total_events': len(mapping_service.get_all_markers())
        })
        
    except Exception as e:
        logger.error(f"Error getting map events: {e}")
        return jsonify({
            'success': False,
            'message': 'An error occurred while loading events.'
        }), 500


@main_bp.route('/map/search', methods=['POST'])
def search_map_events():
    """Search events on the map"""
    try:
        data = request.get_json()
        query = data.get('query', '').strip()
        
        if not query:
            return jsonify({
                'success': False,
                'message': 'Please provide a search query.'
            }), 400
        
        # Search markers
        matching_markers = mapping_service.search_markers(query)
        
        return jsonify({
            'success': True,
            'markers': [marker.to_dict() for marker in matching_markers],
            'total_results': len(matching_markers)
        })
        
    except Exception as e:
        logger.error(f"Error searching map events: {e}")
        return jsonify({
            'success': False,
            'message': 'An error occurred while searching events.'
        }), 500


@main_bp.route('/map')
def map_view():
    """Render the map page"""
    # The map page will get user data from sessionStorage via JavaScript
    # We provide empty defaults that will be overridden by the frontend
    return render_template('map.html', 
                         name='', 
                         activity='', 
                         location={}, 
                         social={})

========================================
# File: /home/jarvis/Downloads/WhatNowAI_test/searchmethods/__init__.py
========================================

"""
Search methods package for WhatNowAI
Provides background search and web scraping functionality
"""

from .background_search import (
    BackgroundSearchService,
    UserProfile,
    SearchResult,
    perform_background_search
)

__all__ = [
    'BackgroundSearchService',
    'UserProfile', 
    'SearchResult',
    'perform_background_search'
]

========================================
# File: /home/jarvis/Downloads/WhatNowAI_test/searchmethods/background_search.py
========================================

"""
Background search service for gathering user and location context
Uses web scraping and search engines to find relevant information
"""

import asyncio
import aiohttp
import logging
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from urllib.parse import quote_plus, urljoin, urlparse
import json
import re
from bs4 import BeautifulSoup
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

logger = logging.getLogger(__name__)


@dataclass
class UserProfile:
    """User profile data structure"""
    name: str
    location: str = ""
    social_handles: Dict[str, str] = None
    activity: str = ""
    
    def __post_init__(self):
        if self.social_handles is None:
            self.social_handles = {}


@dataclass
class SearchResult:
    """Search result data structure"""
    source: str
    title: str
    url: str
    content: str
    relevance_score: float = 0.0
    timestamp: str = ""


class BackgroundSearchService:
    """Service for performing background searches on user information"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """
        Initialize the background search service
        
        Args:
            config: Configuration dictionary with search parameters
        """
        from config.settings import SEARCH_CONFIG
        
        self.config = config or SEARCH_CONFIG
        self.session = None
        self.results_cache = {}
        
    def _setup_session(self) -> requests.Session:
        """Setup requests session with retries and proper headers"""
        session = requests.Session()
        
        # Setup retry strategy
        retry_strategy = Retry(
            total=3,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET", "OPTIONS"]  # Updated parameter name
        )
        
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        # Set headers
        session.headers.update({
            'User-Agent': self.config.get('USER_AGENT', 'WhatNowAI/1.0'),
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        })
        
        return session
    
    def search_user_info(self, user_profile: UserProfile) -> Dict[str, List[SearchResult]]:
        """
        Search for information about the user focusing only on social media and local activities
        
        Args:
            user_profile: User profile containing name, location, social handles, etc.
            
        Returns:
            Dictionary of search results organized by source
        """
        logger.info(f"Starting focused search for user: {user_profile.name}")
        
        results = {
            'general': [],  # Will remain empty - no general searches
            'social': [],
            'location': [],
            'activity': []
        }
        
        if not self.session:
            self.session = self._setup_session()
        
        import time
        start_time = time.time()
        search_timeout = 10  # 10 second limit
        
        try:
            # Only search social media platforms if handles are provided
            if user_profile.social_handles:
                # Check if we still have time
                if time.time() - start_time < search_timeout:
                    social_results = self._search_social_media(user_profile.social_handles)
                    results['social'].extend(social_results)
                    logger.info(f"Found {len(social_results)} social media results")
            
            # Search location-specific information if we have time
            if user_profile.location and (time.time() - start_time < search_timeout):
                location_results = self._search_location_info(user_profile.location, user_profile.activity)
                results['location'].extend(location_results)
                logger.info(f"Found {len(location_results)} location results")
            
            # Search activity-related information if we have time
            if user_profile.activity and (time.time() - start_time < search_timeout):
                activity_results = self._search_activity_info(user_profile.activity, user_profile.location)
                results['activity'].extend(activity_results)
                logger.info(f"Found {len(activity_results)} activity results")
            
            # Log if we hit the timeout
            elapsed_time = time.time() - start_time
            if elapsed_time >= search_timeout:
                logger.warning(f"Search timeout reached ({elapsed_time:.1f}s), returning partial results")
            else:
                logger.info(f"Search completed in {elapsed_time:.1f}s")
                
        except Exception as e:
            logger.error(f"Error during focused search: {str(e)}")
        
        return results
    
    def _search_general_info(self, name: str) -> List[SearchResult]:
        """Search for specific information about this person (not celebrities)"""
        results = []
        
        # Focus on finding the actual user, not celebrities with the same name
        # Use more specific search terms to filter out famous people
        specific_queries = [
            f'"{name}" -wikipedia -celebrity -famous -actor -singer -politician',
            f'"{name}" profile personal',
            f'"{name}" professional background'
        ]
        
        # Use DuckDuckGo for privacy-focused search
        for query in specific_queries:
            encoded_query = quote_plus(query)
            search_urls = [
                f"https://duckduckgo.com/html/?q={encoded_query}",
            ]
            
            for url in search_urls:
                try:
                    response = self.session.get(url, timeout=self.config.get('TIMEOUT', 30))
                    if response.status_code == 200:
                        search_results = self._parse_search_results(response.text, 'general')
                        # Filter out celebrity/famous person results
                        filtered_results = [r for r in search_results if not self._is_celebrity_result(r)]
                        results.extend(filtered_results[:3])  # Limit to 3 per query
                        time.sleep(1)  # Rate limiting
                except Exception as e:
                    logger.warning(f"Failed to search {url}: {str(e)}")
                    continue
        
        return results[:self.config.get('MAX_RESULTS_PER_SOURCE', 8)]
    
    def _is_celebrity_result(self, result: SearchResult) -> bool:
        """Check if a search result is about a celebrity/famous person"""
        celebrity_keywords = [
            'wikipedia', 'celebrity', 'famous', 'actor', 'actress', 'singer', 
            'musician', 'politician', 'athlete', 'sports', 'movie', 'film',
            'album', 'song', 'tv show', 'series', 'biography', 'born in',
            'filmography', 'discography', 'awards', 'grammy', 'oscar', 'emmy'
        ]
        
        content_lower = result.content.lower()
        title_lower = result.title.lower()
        
        return any(keyword in content_lower or keyword in title_lower for keyword in celebrity_keywords)
    
    def _search_social_media(self, social_handles: Dict[str, str]) -> List[SearchResult]:
        """Search social media platforms for user information - fast and focused"""
        results = []
        start_time = time.time()
        timeout_per_platform = 2  # Max 2 seconds per platform
        
        for platform, handle in social_handles.items():
            if not handle:
                continue
            
            # Check timeout
            if time.time() - start_time > 8:  # Reserve 2 seconds for other searches
                logger.warning("Social media search timeout reached, skipping remaining platforms")
                break
                
            try:
                platform_start = time.time()
                
                if platform.lower() == 'github':
                    # GitHub API is fastest, prioritize it
                    platform_results = self._search_github_info(handle)
                    results.extend(platform_results)
                elif platform.lower() in ['twitter', 'linkedin', 'instagram', 'tiktok', 'youtube']:
                    # Quick search for other platforms
                    platform_results = self._quick_social_search(platform, handle)
                    results.extend(platform_results)
                
                # Check if this platform took too long
                if time.time() - platform_start > timeout_per_platform:
                    logger.warning(f"{platform} search took too long, skipping remaining platforms")
                    break
                    
            except Exception as e:
                logger.warning(f"Failed to search {platform} for {handle}: {str(e)}")
                continue
        
        return results[:self.config.get('MAX_RESULTS_PER_SOURCE', 3)]
    
    def _quick_social_search(self, platform: str, handle: str) -> List[SearchResult]:
        """Quick search for social media platforms with minimal processing"""
        results = []
        
        try:
            # Simple site-specific search
            query = quote_plus(f"site:{platform}.com {handle}")
            url = f"https://duckduckgo.com/html/?q={query}"
            
            response = self.session.get(url, timeout=3)  # Short timeout
            if response.status_code == 200:
                # Quick parse - just get first few results
                soup = BeautifulSoup(response.text, 'html.parser')
                result_elements = soup.find_all('div', class_='result')[:2]  # Max 2 results
                
                for element in result_elements:
                    try:
                        title_elem = element.find('a', class_='result__a')
                        snippet_elem = element.find('a', class_='result__snippet')
                        
                        if title_elem and snippet_elem:
                            result = SearchResult(
                                source='social',
                                title=title_elem.get_text(strip=True)[:100],  # Truncate for speed
                                url=title_elem.get('href', ''),
                                content=snippet_elem.get_text(strip=True)[:200],  # Truncate for speed
                                relevance_score=0.7
                            )
                            results.append(result)
                    except:
                        continue
                        
        except Exception as e:
            logger.warning(f"Quick search failed for {platform}: {str(e)}")
        
        return results
    
    def _search_location_info(self, location: str, activity: str = "") -> List[SearchResult]:
        """Fast search for location-specific activities"""
        results = []
        
        if not self.config.get('LOCAL_ACTIVITY_SEARCH', True):
            return results
        
        # Limit to most important queries for speed
        queries = [
            f"things to do {location} today",
        ]
        
        # Add one activity-specific query if provided
        if activity:
            queries.append(f"{activity} {location} classes")
        
        for query in queries[:2]:  # Max 2 queries for speed
            try:
                encoded_query = quote_plus(query)
                url = f"https://duckduckgo.com/html/?q={encoded_query}"
                
                response = self.session.get(url, timeout=self.config.get('TIMEOUT', 5))
                if response.status_code == 200:
                    search_results = self._quick_parse_results(response.text, 'location')
                    results.extend(search_results[:2])  # Max 2 per query
                    
            except Exception as e:
                logger.warning(f"Failed location search for {query}: {str(e)}")
                continue
        
        return results[:self.config.get('MAX_RESULTS_PER_SOURCE', 3)]
    
    def _search_activity_info(self, activity: str, location: str = "") -> List[SearchResult]:
        """Fast search for activity-related information"""
        results = []
        
        # Limit to essential queries for speed
        queries = [
            f"how to get started with {activity}",
        ]
        
        # Add location-specific query if provided
        if location:
            queries.append(f"{activity} beginner guide {location}")
        
        for query in queries[:2]:  # Max 2 queries for speed
            try:
                encoded_query = quote_plus(query)
                url = f"https://duckduckgo.com/html/?q={encoded_query}"
                
                response = self.session.get(url, timeout=self.config.get('TIMEOUT', 5))
                if response.status_code == 200:
                    search_results = self._quick_parse_results(response.text, 'activity')
                    results.extend(search_results[:2])  # Max 2 per query
                    
            except Exception as e:
                logger.warning(f"Failed activity search for {query}: {str(e)}")
                continue
        
        return results[:self.config.get('MAX_RESULTS_PER_SOURCE', 3)]
    
    def _quick_parse_results(self, html_content: str, source_type: str) -> List[SearchResult]:
        """Fast parsing of search results with minimal processing"""
        results = []
        
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            result_elements = soup.find_all('div', class_='result')[:3]  # Max 3 for speed
            
            for element in result_elements:
                try:
                    title_elem = element.find('a', class_='result__a')
                    snippet_elem = element.find('a', class_='result__snippet')
                    
                    if title_elem and snippet_elem:
                        result = SearchResult(
                            source=source_type,
                            title=title_elem.get_text(strip=True)[:80],  # Truncate for speed
                            url=title_elem.get('href', ''),
                            content=snippet_elem.get_text(strip=True)[:150],  # Truncate for speed
                            relevance_score=0.5
                        )
                        results.append(result)
                        
                except Exception:
                    continue
                    
        except Exception as e:
            logger.warning(f"Quick parse failed: {str(e)}")
        
        return results
    
    def _search_twitter_info(self, handle: str) -> List[SearchResult]:
        """Search for Twitter profile information (public data only)"""
        results = []
        
        # Search for public information about the Twitter handle
        query = quote_plus(f"site:twitter.com {handle}")
        url = f"https://duckduckgo.com/html/?q={query}"
        
        try:
            response = self.session.get(url, timeout=self.config.get('TIMEOUT', 30))
            if response.status_code == 200:
                results = self._parse_search_results(response.text, 'social')
        except Exception as e:
            logger.warning(f"Failed to search Twitter info for {handle}: {str(e)}")
        
        return results
    
    def _search_linkedin_info(self, handle: str) -> List[SearchResult]:
        """Search for LinkedIn profile information (public data only)"""
        results = []
        
        # Search for public LinkedIn information
        query = quote_plus(f"site:linkedin.com {handle}")
        url = f"https://duckduckgo.com/html/?q={query}"
        
        try:
            response = self.session.get(url, timeout=self.config.get('TIMEOUT', 30))
            if response.status_code == 200:
                results = self._parse_search_results(response.text, 'social')
        except Exception as e:
            logger.warning(f"Failed to search LinkedIn info for {handle}: {str(e)}")
        
        return results
    
    def _search_github_info(self, handle: str) -> List[SearchResult]:
        """Search for GitHub profile information using GitHub API"""
        results = []
        
        try:
            # Try to get public GitHub profile information
            api_url = f"https://api.github.com/users/{handle}"
            response = self.session.get(api_url, timeout=self.config.get('TIMEOUT', 30))
            
            if response.status_code == 200:
                data = response.json()
                
                # Create a search result from GitHub profile
                result = SearchResult(
                    source='github',
                    title=f"GitHub Profile: {data.get('name', handle)}",
                    url=data.get('html_url', f"https://github.com/{handle}"),
                    content=f"Bio: {data.get('bio', 'No bio available')}. "
                           f"Public repos: {data.get('public_repos', 0)}. "
                           f"Followers: {data.get('followers', 0)}. "
                           f"Location: {data.get('location', 'Not specified')}.",
                    relevance_score=0.8
                )
                results.append(result)
                
        except Exception as e:
            logger.warning(f"Failed to search GitHub info for {handle}: {str(e)}")
        
        return results
    
    def _search_instagram_info(self, handle: str) -> List[SearchResult]:
        """Search for Instagram profile information (public data only)"""
        results = []
        
        # Search for public Instagram information
        query = quote_plus(f"site:instagram.com {handle}")
        url = f"https://duckduckgo.com/html/?q={query}"
        
        try:
            response = self.session.get(url, timeout=self.config.get('TIMEOUT', 30))
            if response.status_code == 200:
                results = self._parse_search_results(response.text, 'social')
        except Exception as e:
            logger.warning(f"Failed to search Instagram info for {handle}: {str(e)}")
        
        return results
    
    def _search_tiktok_info(self, handle: str) -> List[SearchResult]:
        """Search for TikTok profile information (public data only)"""
        results = []
        
        # Search for public TikTok information
        query = quote_plus(f"site:tiktok.com @{handle}")
        url = f"https://duckduckgo.com/html/?q={query}"
        
        try:
            response = self.session.get(url, timeout=self.config.get('TIMEOUT', 30))
            if response.status_code == 200:
                results = self._parse_search_results(response.text, 'social')
        except Exception as e:
            logger.warning(f"Failed to search TikTok info for {handle}: {str(e)}")
        
        return results
    
    def _search_youtube_info(self, handle: str) -> List[SearchResult]:
        """Search for YouTube channel information (public data only)"""
        results = []
        
        # Search for public YouTube information
        queries = [
            quote_plus(f"site:youtube.com {handle}"),
            quote_plus(f"site:youtube.com/c/{handle}"),
            quote_plus(f"site:youtube.com/@{handle}")
        ]
        
        for query in queries:
            try:
                url = f"https://duckduckgo.com/html/?q={query}"
                response = self.session.get(url, timeout=self.config.get('TIMEOUT', 30))
                if response.status_code == 200:
                    search_results = self._parse_search_results(response.text, 'social')
                    results.extend(search_results[:2])
                    time.sleep(1)
            except Exception as e:
                logger.warning(f"Failed to search YouTube info for {handle}: {str(e)}")
                continue
        
        return results

    def _parse_search_results(self, html_content: str, source_type: str) -> List[SearchResult]:
        """Parse HTML search results and extract relevant information"""
        results = []
        
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # Parse DuckDuckGo results
            if 'duckduckgo.com' in html_content or 'ddg' in html_content:
                results.extend(self._parse_duckduckgo_results(soup, source_type))
            # Parse Bing results
            elif 'bing.com' in html_content:
                results.extend(self._parse_bing_results(soup, source_type))
                
        except Exception as e:
            logger.warning(f"Failed to parse search results: {str(e)}")
        
        return results
    
    def _parse_duckduckgo_results(self, soup: BeautifulSoup, source_type: str) -> List[SearchResult]:
        """Parse DuckDuckGo search results"""
        results = []
        
        # Find result elements (DuckDuckGo HTML structure)
        result_elements = soup.find_all('div', class_='result')
        
        for element in result_elements[:self.config.get('MAX_RESULTS_PER_SOURCE', 10)]:
            try:
                title_elem = element.find('a', class_='result__a')
                snippet_elem = element.find('a', class_='result__snippet')
                
                if title_elem and snippet_elem:
                    title = title_elem.get_text(strip=True)
                    url = title_elem.get('href', '')
                    content = snippet_elem.get_text(strip=True)
                    
                    if title and url and content:
                        result = SearchResult(
                            source=source_type,
                            title=title,
                            url=url,
                            content=content,
                            relevance_score=0.5
                        )
                        results.append(result)
                        
            except Exception as e:
                logger.warning(f"Failed to parse individual result: {str(e)}")
                continue
        
        return results
    
    def _parse_bing_results(self, soup: BeautifulSoup, source_type: str) -> List[SearchResult]:
        """Parse Bing search results"""
        results = []
        
        # Find result elements (Bing HTML structure)
        result_elements = soup.find_all('li', class_='b_algo')
        
        for element in result_elements[:self.config.get('MAX_RESULTS_PER_SOURCE', 10)]:
            try:
                title_elem = element.find('h2')
                if title_elem:
                    title_link = title_elem.find('a')
                    if title_link:
                        title = title_link.get_text(strip=True)
                        url = title_link.get('href', '')
                        
                        # Find snippet
                        snippet_elem = element.find('p')
                        content = snippet_elem.get_text(strip=True) if snippet_elem else ""
                        
                        if title and url:
                            result = SearchResult(
                                source=source_type,
                                title=title,
                                url=url,
                                content=content,
                                relevance_score=0.5
                            )
                            results.append(result)
                            
            except Exception as e:
                logger.warning(f"Failed to parse individual Bing result: {str(e)}")
                continue
        
        return results
    
    def summarize_search_results(self, search_results: Dict[str, List[SearchResult]]) -> Dict[str, str]:
        """
        Summarize search results into a concise format - optimized for speed
        
        Args:
            search_results: Dictionary of search results by category
            
        Returns:
            Dictionary of summarized information by category
        """
        summaries = {}
        
        for category, results in search_results.items():
            if not results:
                if category == 'general':
                    summaries[category] = "General search skipped for faster personalization."
                else:
                    summaries[category] = f"No relevant {category} information found."
                continue
            
            # Quick summary generation for speed
            if category == 'social':
                platforms = set()
                for result in results:
                    if 'github' in result.url.lower():
                        platforms.add('GitHub')
                    elif 'twitter' in result.url.lower():
                        platforms.add('Twitter')
                    elif 'linkedin' in result.url.lower():
                        platforms.add('LinkedIn')
                    elif 'instagram' in result.url.lower():
                        platforms.add('Instagram')
                    elif 'tiktok' in result.url.lower():
                        platforms.add('TikTok')
                    elif 'youtube' in result.url.lower():
                        platforms.add('YouTube')
                
                if platforms:
                    platform_list = ', '.join(sorted(platforms))
                    summaries[category] = f"Found social presence on: {platform_list}. This provides context for personalized recommendations."
                else:
                    summaries[category] = f"Found {len(results)} social media references for personalization context."
            
            elif category == 'location':
                summaries[category] = f"Found {len(results)} local activities and events in your area for relevant suggestions."
            
            elif category == 'activity':
                summaries[category] = f"Found {len(results)} learning resources and guides for your activity interests."
            
            else:
                # Generic summary for any other categories
                summaries[category] = f"Found {len(results)} relevant results for enhanced personalization."
        
        return summaries
    
    def close(self):
        """Clean up resources"""
        if self.session:
            self.session.close()


# Convenience function for easy integration
def perform_background_search(user_profile: UserProfile) -> Dict[str, Any]:
    """
    Perform background search and return summarized results
    
    Args:
        user_profile: User profile information
        
    Returns:
        Dictionary containing raw results and summaries
    """
    search_service = BackgroundSearchService()
    
    try:
        # Perform the search
        raw_results = search_service.search_user_info(user_profile)
        
        # Summarize the results
        summaries = search_service.summarize_search_results(raw_results)
        
        return {
            'raw_results': raw_results,
            'summaries': summaries,
            'total_results': sum(len(results) for results in raw_results.values())
        }
        
    finally:
        search_service.close()


if __name__ == "__main__":
    # Test the search functionality
    test_profile = UserProfile(
        name="John Doe",
        location="San Francisco, CA",
        social_handles={"github": "johndoe", "twitter": "johndoe"},
        activity="learn python programming"
    )
    
    results = perform_background_search(test_profile)
    print(json.dumps(results['summaries'], indent=2))

========================================
# File: /home/jarvis/Downloads/WhatNowAI_test/utils/__init__.py
========================================

# Utils package

========================================
# File: /home/jarvis/Downloads/WhatNowAI_test/utils/helpers.py
========================================

"""
Utility functions for data processing
"""
import re
from typing import Dict, Any, Optional


def clean_text_for_tts(text: str) -> str:
    """
    Clean text for better TTS pronunciation
    
    Args:
        text: Input text to clean
        
    Returns:
        Cleaned text suitable for TTS
    """
    if not text:
        return ""
    
    # Remove markdown formatting
    text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)  # Remove bold
    text = re.sub(r'\*(.*?)\*', r'\1', text)      # Remove italic
    text = re.sub(r'`(.*?)`', r'\1', text)        # Remove code
    
    # Replace multiple newlines with periods
    text = re.sub(r'\n\n+', '. ', text)
    text = re.sub(r'\n', '. ', text)
    
    # Clean up multiple periods
    text = re.sub(r'\.{2,}', '.', text)
    
    # Remove extra whitespace
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text


def validate_coordinates(latitude: Optional[float], longitude: Optional[float]) -> bool:
    """
    Validate latitude and longitude coordinates
    
    Args:
        latitude: Latitude value
        longitude: Longitude value
        
    Returns:
        True if coordinates are valid, False otherwise
    """
    if latitude is None or longitude is None:
        return False
    
    try:
        lat = float(latitude)
        lon = float(longitude)
        
        # Check if coordinates are in valid range
        if -90 <= lat <= 90 and -180 <= lon <= 180:
            return True
        return False
    except (ValueError, TypeError, OverflowError):
        return False


def sanitize_social_handle(handle: str) -> str:
    """
    Sanitize social media handle
    
    Args:
        handle: Raw social media handle
        
    Returns:
        Cleaned handle without @ symbol
    """
    if not handle:
        return ""
    
    # Remove @ symbol and whitespace
    return handle.replace('@', '').strip()


def format_location_string(location_data: Dict[str, Any]) -> str:
    """
    Format location data into a readable string
    
    Args:
        location_data: Dictionary containing location information
        
    Returns:
        Formatted location string
    """
    if not location_data:
        return "Unknown location"
    
    city = location_data.get('city', 'Unknown')
    country = location_data.get('country', 'Unknown')
    zipcode = location_data.get('zipcode', 'Unknown')
    
    location_str = f"{city}, {country}"
    if zipcode != 'Unknown':
        location_str += f" ({zipcode})"
    
    return location_str


def generate_response_text(name: str, activity: str, location_data: Dict, social_data: Dict, search_summaries: Dict = None) -> str:
    """
    Generate the main response text for user request
    
    Args:
        name: User's name
        activity: User's desired activity
        location_data: Location information
        social_data: Social media information
        search_summaries: Background search summaries (optional)
        
    Returns:
        Formatted response text
    """
    location_str = format_location_string(location_data)
    
    result = f"Great news, {name}! I've analyzed your request to {activity} in {location_str}.\n\n"
    
    # Add background search context if available
    if search_summaries:
        result += "Based on my background research, here's what I found:\n\n"
        
        # Add location insights
        if search_summaries.get('location') and 'No relevant' not in search_summaries['location']:
            result += f"📍 **Location Insights**: {search_summaries['location']}\n\n"
        
        # Add activity insights
        if search_summaries.get('activity') and 'No relevant' not in search_summaries['activity']:
            result += f"🎯 **Activity Insights**: {search_summaries['activity']}\n\n"
        
        # Add social media insights
        if search_summaries.get('social') and 'No relevant' not in search_summaries['social']:
            result += f"👥 **Social Context**: {search_summaries['social']}\n\n"
    
    # Add social media context if provided
    twitter_handle = sanitize_social_handle(social_data.get('twitter', ''))
    instagram_handle = sanitize_social_handle(social_data.get('instagram', ''))
    
    if twitter_handle or instagram_handle:
        result += f"I noticed you're active on social media"
        if twitter_handle and instagram_handle:
            result += f" (@{twitter_handle} on X, @{instagram_handle} on Instagram)"
        elif twitter_handle:
            result += f" (@{twitter_handle} on X)"
        elif instagram_handle:
            result += f" (@{instagram_handle} on Instagram)"
        result += f". This gives me additional context about your interests!\n\n"
    
    # Add personalized recommendations based on search results
    result += f"Here are my personalized recommendations for you:\n\n"
    
    # Add location-specific suggestions
    country = location_data.get('country', 'Unknown')
    result += f"1. **Start with the basics**: Break down '{activity}' into smaller, manageable steps\n" \
              f"2. **Local resources**: Research what's available in {country} to help with {activity}\n" \
              f"3. **Requirements check**: Look for any location-specific requirements or regulations\n" \
              f"4. **Timeline planning**: Set realistic milestones and deadlines\n" \
              f"5. **Community connection**: Find local groups or communities interested in {activity}\n\n"
    
    # Add social media suggestions if applicable
    if twitter_handle or instagram_handle:
        result += f"6. **Social sharing**: Document your {activity} journey to connect with like-minded people\n" \
                 f"7. **Follow experts**: Connect with relevant accounts and hashtags related to {activity}\n\n"
    
    # Add search-informed suggestions
    if search_summaries and any('No relevant' not in summary for summary in search_summaries.values()):
        result += f"8. **Research-based insights**: Based on my background research, focus on the most promising approaches mentioned above\n\n"
    
    # Add precise location info if available
    latitude = location_data.get('latitude')
    longitude = location_data.get('longitude')
    if validate_coordinates(latitude, longitude):
        result += f"📍 **Precise location advantage**: With your exact coordinates ({latitude:.4f}, {longitude:.4f}), " \
                 f"I can provide hyper-local recommendations.\n\n"
    
    result += f"💡 **Next steps**: Would you like me to create a detailed, step-by-step action plan " \
              f"tailored specifically to your location and background?"
    
    return result

========================================
# File: /home/jarvis/Downloads/WhatNowAI_test/config/settings.py
========================================

"""
Application configuration
"""
import os
from pathlib import Path

# Base directory
BASE_DIR = Path(__file__).parent.parent

def load_secrets():
    """Load API keys and secrets from secrets.txt file"""
    secrets = {}
    secrets_file = BASE_DIR / 'secrets.txt'
    
    if secrets_file.exists():
        try:
            with open(secrets_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and '=' in line and not line.startswith('#'):
                        key, value = line.split('=', 1)
                        secrets[key.strip()] = value.strip()
        except Exception as e:
            print(f"Warning: Could not load secrets.txt: {e}")
    
    return secrets

# Load secrets from file
_secrets = load_secrets()

# Audio configuration
AUDIO_DIR = BASE_DIR / 'static' / 'audio'
DEFAULT_TTS_VOICE = "en-US-JennyNeural"
AUDIO_CLEANUP_HOURS = 24

# Flask configuration
FLASK_CONFIG = {
    'DEBUG': True,
    'HOST': '0.0.0.0',
    'PORT': 5002
}

# Logging configuration
LOGGING_CONFIG = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'default': {
            'format': '[%(asctime)s] %(levelname)s in %(module)s: %(message)s',
        }
    },
    'handlers': {
        'console': {
            'class': 'logging.StreamHandler',
            'level': 'INFO',
            'formatter': 'default',
            'stream': 'ext://sys.stdout'
        }
    },
    'root': {
        'level': 'INFO',
        'handlers': ['console']
    }
}

# Geocoding configuration
GEOCODING_CONFIG = {
    'USER_AGENT': 'WhatNowAI/1.0',
    'TIMEOUT': 10
}

# API Keys from secrets.txt file and environment variables (env vars take precedence)
TICKETMASTER_API_KEY = os.getenv('TICKETMASTER_API_KEY', _secrets.get('TICKETMASTER_CONSUMER_KEY', ''))
ALLEVENTS_API_KEY = os.getenv('ALLEVENTS_API_KEY', _secrets.get('ALLEVENTS_API_KEY', ''))
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', _secrets.get('OPENAI_API_KEY', ''))

# Optional API keys for advanced features
HUGGINGFACE_TOKEN = os.getenv('HUGGINGFACE_TOKEN', _secrets.get('HUGGINGFACE_TOKEN', ''))

# Debug function to check API key status
def check_api_keys():
    """Check which API keys are available"""
    keys_status = {
        'TICKETMASTER_API_KEY': 'SET' if TICKETMASTER_API_KEY else 'NOT SET',
        'ALLEVENTS_API_KEY': 'SET' if ALLEVENTS_API_KEY else 'NOT SET',
        'OPENAI_API_KEY': 'SET' if OPENAI_API_KEY else 'NOT SET',
        'HUGGINGFACE_TOKEN': 'SET' if HUGGINGFACE_TOKEN else 'NOT SET'
    }
    
    print("🔑 API Keys Status:")
    for key, status in keys_status.items():
        print(f"   {key}: {status}")
        if status == 'SET' and key in ['TICKETMASTER_API_KEY', 'ALLEVENTS_API_KEY']:
            print(f"   {key} value: {globals()[key][:10]}...")
    
    return keys_status

# Search configuration
SEARCH_CONFIG = {
    'MAX_RESULTS_PER_SOURCE': 3,  # Reduced for faster searches
    'TIMEOUT': 5,  # Reduced timeout per request
    'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    'SOCIAL_PLATFORMS': ['twitter', 'linkedin', 'instagram', 'github', 'tiktok', 'youtube'],
    'MAX_CONCURRENT_REQUESTS': 3,  # Reduced for faster processing
    'FOCUS_ON_USER': True,  # Only search for the specific user, not celebrities/general info
    'LOCAL_ACTIVITY_SEARCH': True,  # Include local activity searches
    'SEARCH_TIMEOUT': 10,  # Total search timeout in seconds
    'SKIP_GENERAL_SEARCH': True  # Skip general name searches
}

# Ticketmaster API configuration
TICKETMASTER_CONFIG = {
    'BASE_URL': 'https://app.ticketmaster.com/discovery/v2',
    'SEARCH_RADIUS': 50,  # miles
    'MAX_EVENTS': 20,
    'DEFAULT_CATEGORIES': ['music', 'sports', 'arts', 'miscellaneous'],
    'TIMEOUT': 10,
    'MIN_RELEVANCE_SCORE': 0.15  # Minimum relevance score for event filtering
}

# AllEvents API configuration
ALLEVENTS_CONFIG = {
    'BASE_URL': 'https://allevents.developer.azure-api.net/api',
    'SEARCH_RADIUS': 50,  # km
    'MAX_EVENTS': 30,
    'TIMEOUT': 10,
    'MIN_RELEVANCE_SCORE': 0.15  # Minimum relevance score for event filtering
}

# Map configuration
MAP_CONFIG = {
    'DEFAULT_ZOOM': 12,
    'MAX_MARKERS': 50,
    'TILE_SERVER': 'https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png',
    'ATTRIBUTION': '&copy; <a href="https://www.openstreetmap.org/copyright">OpenStreetMap</a> contributors'
}

========================================
# File: /home/jarvis/Downloads/WhatNowAI_test/config/__init__.py
========================================

# Config package

========================================
# File: /home/jarvis/Downloads/WhatNowAI_test/services/allevents_service.py
========================================

"""
AllEvents API service for event discovery

This module integrates with the AllEvents API to find local events
and activities based on user location and interests. Includes advanced personalization,
event categorization, filtering, and comprehensive error handling for intelligent
event discovery that adapts to user preferences and behavioral patterns.
"""

import requests
import logging
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from datetime import datetime, timedelta
import json
import re

logger = logging.getLogger(__name__)


class AllEventsService:
    """Service for intelligent event discovery from AllEvents API with personalization"""
    
    def __init__(self, api_key: str, config: Dict[str, Any]):
        """
        Initialize AllEvents service
        
        Args:
            api_key: AllEvents API key
            config: Configuration dictionary
        """
        self.api_key = api_key
        self.config = config
        self.base_url = config.get('BASE_URL', 'https://allevents.developer.azure-api.net/api')
        self.session = requests.Session()
        
        # Set default headers for API
        self.session.headers.update({
            'Ocp-Apim-Subscription-Key': self.api_key,
            'Content-Type': 'application/json'
        })
        
    def search_events(self, location: Dict[str, Any], user_interests: List[str] = None, 
                     user_activity: str = "", personalization_data: Dict[str, Any] = None,
                     user_profile: Any = None) -> List[Any]:
        """
        Search for events near a location based on user interests and enhanced personalization
        
        Args:
            location: Dictionary with latitude, longitude, city, country
            user_interests: List of user interest categories
            user_activity: What the user wants to do
            personalization_data: Enhanced personalization data from background search
            user_profile: Enhanced user profile from user_profiling_service
            
        Returns:
            List of Event objects (using same structure as Ticketmaster) filtered and ranked by AI and user preferences
        """
        if not self.api_key:
            logger.warning("AllEvents API key not provided")
            return []
        
        latitude = location.get('latitude')
        longitude = location.get('longitude')
        city = location.get('city', '')
        country = location.get('country', '')
        
        # Convert to float if needed
        try:
            if latitude is not None:
                latitude = float(latitude)
            if longitude is not None:
                longitude = float(longitude)
        except (ValueError, TypeError) as e:
            logger.error(f"Failed to convert coordinates to float in AllEvents service: {e}")
            return []
        
        if not latitude or not longitude:
            logger.warning("Location coordinates not provided or invalid for AllEvents")
            return []
        
        logger.info(f"Searching AllEvents with AI-enhanced personalization: "
                   f"location=({latitude},{longitude}), "
                   f"basic_interests={user_interests}, "
                   f"activity='{user_activity}', "
                   f"has_personalization_data={bool(personalization_data)}, "
                   f"has_profile={bool(user_profile)}")
        
        events = []
        
        try:
            # Build search parameters
            params = {
                'latitude': latitude,
                'longitude': longitude,
                'radius': 50,  # 50km radius
                'limit': 50,   # Get more events for better filtering
                'sort': 'relevance'
            }
            
            # Add city/location if available
            if city:
                params['city'] = city
            
            # Add date range (next 30 days)
            today = datetime.now()
            end_date = today + timedelta(days=30)
            params['start_date'] = today.strftime('%Y-%m-%d')
            params['end_date'] = end_date.strftime('%Y-%m-%d')
            
            # Add categories based on user interests and activity
            categories = self._map_interests_to_categories(user_interests, user_activity, user_profile)
            if categories:
                params['categories'] = ','.join(categories)
            
            logger.info(f"AllEvents API request params: {params}")
            
            # Make API request
            response = self.session.get(
                f"{self.base_url}/events/search",
                params=params,
                timeout=self.config.get('TIMEOUT', 10)
            )
            
            if response.status_code == 200:
                data = response.json()
                raw_events = data.get('events', [])
                
                logger.info(f"AllEvents API returned {len(raw_events)} raw events")
                
                # Convert to our Event format
                for event_data in raw_events:
                    try:
                        event = self._convert_to_event_format(event_data, location)
                        if event:
                            events.append(event)
                    except Exception as e:
                        logger.warning(f"Failed to convert AllEvents event: {e}")
                        continue
                
                logger.info(f"Successfully converted {len(events)} AllEvents events")
                
                # Apply AI-powered filtering and ranking
                if user_profile and events:
                    events = self._apply_ai_filtering(events, user_profile, user_activity, personalization_data)
                
            else:
                logger.error(f"AllEvents API error: {response.status_code} - {response.text}")
                
        except requests.exceptions.RequestException as e:
            logger.error(f"AllEvents API request failed: {e}")
        except Exception as e:
            logger.error(f"Unexpected error in AllEvents search: {e}")
        
        return events
    
    def _map_interests_to_categories(self, user_interests: List[str], user_activity: str, user_profile: Any) -> List[str]:
        """Map user interests and activities to AllEvents categories"""
        category_mapping = {
            # Music and Entertainment
            'music': ['music', 'concerts', 'festivals'],
            'concerts': ['music', 'concerts'],
            'festivals': ['festivals', 'music', 'food'],
            'nightlife': ['nightlife', 'parties'],
            'comedy': ['comedy', 'entertainment'],
            'theatre': ['theatre', 'performing-arts'],
            'entertainment': ['entertainment', 'performing-arts'],
            
            # Sports and Fitness
            'sports': ['sports', 'fitness'],
            'fitness': ['fitness', 'sports', 'health'],
            'running': ['sports', 'fitness', 'running'],
            'yoga': ['fitness', 'health', 'wellness'],
            'gym': ['fitness', 'health'],
            
            # Arts and Culture
            'art': ['art', 'exhibitions', 'culture'],
            'museums': ['art', 'culture', 'exhibitions'],
            'exhibitions': ['art', 'exhibitions', 'culture'],
            'culture': ['culture', 'art', 'history'],
            'history': ['culture', 'history', 'education'],
            
            # Food and Drink
            'food': ['food', 'restaurants', 'culinary'],
            'restaurants': ['food', 'culinary'],
            'cooking': ['food', 'culinary', 'workshops'],
            'wine': ['food', 'wine', 'culinary'],
            'beer': ['food', 'beer', 'nightlife'],
            
            # Technology and Business
            'technology': ['technology', 'business', 'conferences'],
            'tech': ['technology', 'business'],
            'business': ['business', 'networking', 'conferences'],
            'networking': ['business', 'networking', 'professional'],
            'conferences': ['conferences', 'business', 'education'],
            
            # Outdoor and Nature
            'outdoor': ['outdoor', 'nature', 'adventure'],
            'hiking': ['outdoor', 'nature', 'sports'],
            'nature': ['nature', 'outdoor', 'environment'],
            'adventure': ['adventure', 'outdoor', 'sports'],
            'cycling': ['sports', 'outdoor', 'cycling'],
            
            # Family and Kids
            'family': ['family', 'kids', 'children'],
            'kids': ['kids', 'family', 'children'],
            'children': ['children', 'family', 'kids'],
            
            # Education and Learning
            'education': ['education', 'workshops', 'learning'],
            'workshops': ['workshops', 'education', 'learning'],
            'learning': ['education', 'workshops', 'personal-development'],
            'books': ['education', 'literature', 'culture'],
            
            # Health and Wellness
            'health': ['health', 'wellness', 'fitness'],
            'wellness': ['wellness', 'health', 'mindfulness'],
            'meditation': ['wellness', 'mindfulness', 'health'],
            
            # Community and Social
            'community': ['community', 'social', 'networking'],
            'volunteering': ['community', 'charity', 'social'],
            'charity': ['charity', 'community', 'volunteering']
        }
        
        categories = set()
        
        # Add categories based on user interests
        if user_interests:
            for interest in user_interests:
                interest_lower = interest.lower()
                if interest_lower in category_mapping:
                    categories.update(category_mapping[interest_lower])
        
        # Add categories based on activity text
        if user_activity:
            activity_lower = user_activity.lower()
            for keyword, cats in category_mapping.items():
                if keyword in activity_lower:
                    categories.update(cats)
        
        # Add categories based on enhanced user profile
        if user_profile and hasattr(user_profile, 'get'):
            profile_interests = user_profile.get('interests', [])
            for interest in profile_interests:
                if isinstance(interest, dict):
                    interest_text = interest.get('category', '').lower()
                elif hasattr(interest, 'category'):
                    interest_text = interest.category.lower()
                else:
                    interest_text = str(interest).lower()
                
                if interest_text in category_mapping:
                    categories.update(category_mapping[interest_text])
        
        return list(categories)
    
    def _convert_to_event_format(self, event_data: Dict[str, Any], location: Dict[str, Any]) -> Any:
        """Convert AllEvents API response to our standard Event format"""
        try:
            # Import Event class from ticketmaster_service to maintain consistency
            from services.ticketmaster_service import Event
            
            # Extract basic event information
            event_id = str(event_data.get('id', ''))
            name = event_data.get('title', '').strip()
            url = event_data.get('url', '')
            
            # Parse date and time
            start_date = event_data.get('start_date', '')
            start_time = event_data.get('start_time', '')
            
            # Format date and time
            date_str = start_date if start_date else 'TBA'
            time_str = start_time if start_time else 'TBA'
            
            # Venue information
            venue_info = event_data.get('venue', {})
            venue_name = venue_info.get('name', 'TBA')
            venue_address = venue_info.get('address', '')
            
            # Location coordinates
            venue_lat = venue_info.get('latitude')
            venue_lon = venue_info.get('longitude')
            
            # Use provided location as fallback
            if not venue_lat or not venue_lon:
                venue_lat = location.get('latitude', 0.0)
                venue_lon = location.get('longitude', 0.0)
            
            # Convert to float
            try:
                venue_lat = float(venue_lat) if venue_lat else 0.0
                venue_lon = float(venue_lon) if venue_lon else 0.0
            except (ValueError, TypeError):
                venue_lat = float(location.get('latitude', 0.0))
                venue_lon = float(location.get('longitude', 0.0))
            
            # Category mapping
            category = event_data.get('category', 'Other')
            subcategory = event_data.get('subcategory', '')
            
            # Image URL
            image_url = event_data.get('image_url', '')
            if isinstance(event_data.get('images'), list) and event_data['images']:
                image_url = event_data['images'][0].get('url', image_url)
            
            # Description
            description = event_data.get('description', '')
            
            # Note: Removing price information as requested
            # price_min = None
            # price_max = None
            
            # Create Event object
            event = Event(
                id=f"allevents_{event_id}",  # Prefix to distinguish from Ticketmaster
                name=name,
                url=url,
                date=date_str,
                time=time_str,
                venue=venue_name,
                address=venue_address,
                city=location.get('city', ''),
                latitude=venue_lat,
                longitude=venue_lon,
                category=category,
                subcategory=subcategory,
                price_min=None,  # Removed as requested
                price_max=None,  # Removed as requested
                image_url=image_url,
                description=description
            )
            
            return event
            
        except Exception as e:
            logger.error(f"Error converting AllEvents event to standard format: {e}")
            logger.error(f"Event data: {event_data}")
            return None
    
    def _apply_ai_filtering(self, events: List[Any], user_profile: Any, user_activity: str, 
                          personalization_data: Dict[str, Any]) -> List[Any]:
        """Apply AI-powered filtering and ranking to events"""
        try:
            # Import AI filtering from ticketmaster service for consistency
            from services.ticketmaster_service import TicketmasterService
            
            # Create a temporary instance to use its AI filtering methods
            # We'll use the same AI logic for consistency
            temp_service = TicketmasterService("", {})
            
            if hasattr(temp_service, '_apply_ai_filtering_and_ranking'):
                return temp_service._apply_ai_filtering_and_ranking(
                    events, user_profile, user_activity, personalization_data
                )
            else:
                # Fallback: simple relevance scoring
                for event in events:
                    event.relevance_score = self._calculate_simple_relevance(
                        event, user_profile, user_activity
                    )
                
                # Sort by relevance score
                events.sort(key=lambda x: getattr(x, 'relevance_score', 0), reverse=True)
                
                return events[:20]  # Return top 20 events
                
        except Exception as e:
            logger.warning(f"AI filtering failed for AllEvents, using simple filtering: {e}")
            return events[:20]  # Return first 20 events as fallback
    
    def _calculate_simple_relevance(self, event: Any, user_profile: Any, user_activity: str) -> float:
        """Calculate simple relevance score for an event"""
        score = 0.5  # Base score
        
        try:
            # Check if event category matches user interests
            if user_profile and hasattr(user_profile, 'get'):
                interests = user_profile.get('interests', [])
                event_category = getattr(event, 'category', '').lower()
                
                for interest in interests:
                    if isinstance(interest, dict):
                        interest_text = interest.get('category', '').lower()
                    elif hasattr(interest, 'category'):
                        interest_text = interest.category.lower()
                    else:
                        interest_text = str(interest).lower()
                    
                    if interest_text in event_category or event_category in interest_text:
                        score += 0.3
                        break
            
            # Check if event name/description matches user activity
            if user_activity:
                event_text = f"{getattr(event, 'name', '')} {getattr(event, 'description', '')}".lower()
                activity_words = user_activity.lower().split()
                
                for word in activity_words:
                    if len(word) > 2 and word in event_text:
                        score += 0.1
            
            # Prefer events with images
            if getattr(event, 'image_url', ''):
                score += 0.1
            
            # Prefer events with detailed descriptions
            if len(getattr(event, 'description', '')) > 50:
                score += 0.1
                
        except Exception as e:
            logger.warning(f"Error calculating relevance score: {e}")
        
        return min(score, 1.0)  # Cap at 1.0

========================================
# File: /home/jarvis/Downloads/WhatNowAI_test/services/geocoding_service.py
========================================

"""
Geocoding service for location handling

This module provides location services using OpenStreetMap's Nominatim API,
including reverse geocoding for converting coordinates to address information.
Privacy-focused implementation with configurable timeouts and user agents.
"""
import requests
import logging
from typing import Dict, Optional

logger = logging.getLogger(__name__)


class GeocodingService:
    """Service for handling geocoding operations"""
    
    def __init__(self, user_agent: str = "WhatNowAI/1.0"):
        """
        Initialize geocoding service
        
        Args:
            user_agent: User agent string for API requests
        """
        self.user_agent = user_agent
        self.base_url = "https://nominatim.openstreetmap.org/reverse"
    
    def reverse_geocode(self, latitude: float, longitude: float) -> Optional[Dict]:
        """
        Reverse geocode coordinates to address information
        
        Args:
            latitude: Latitude coordinate
            longitude: Longitude coordinate
            
        Returns:
            Dictionary with location information or None if failed
        """
        try:
            params = {
                'format': 'json',
                'lat': latitude,
                'lon': longitude,
                'zoom': 18,
                'addressdetails': 1
            }
            
            headers = {
                'User-Agent': self.user_agent
            }
            
            response = requests.get(
                self.base_url, 
                params=params, 
                headers=headers, 
                timeout=10
            )
            
            if response.status_code == 200:
                geo_data = response.json()
                return self._extract_location_info(geo_data, latitude, longitude)
            else:
                logger.error(f"Geocoding API returned status {response.status_code}")
                return None
                
        except requests.RequestException as e:
            logger.error(f"Geocoding request error: {e}")
            return None
        except Exception as e:
            logger.error(f"Geocoding error: {e}")
            return None
    
    def _extract_location_info(self, geo_data: Dict, latitude: float, longitude: float) -> Dict:
        """
        Extract relevant location information from geocoding response
        
        Args:
            geo_data: Raw geocoding response
            latitude: Original latitude
            longitude: Original longitude
            
        Returns:
            Cleaned location information dictionary
        """
        address = geo_data.get('address', {})
        
        # Extract city with fallback options
        city = (address.get('city') or 
                address.get('town') or 
                address.get('village') or 
                address.get('hamlet') or 
                'Unknown')
        
        return {
            'country': address.get('country', 'Unknown'),
            'city': city,
            'zipcode': address.get('postcode', 'Unknown'),
            'latitude': latitude,
            'longitude': longitude,
            'full_address': geo_data.get('display_name', 'Unknown')
        }

========================================
# File: /home/jarvis/Downloads/WhatNowAI_test/services/unified_events_service.py
========================================

"""
Unified Events Service

This service coordinates multiple event APIs (Ticketmaster, AllEvents, etc.),
applies AI-powered filtering and ranking, and provides a unified interface
for event discovery with advanced personalization.
"""

import logging
import asyncio
from typing import Dict, List, Optional, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
import json

logger = logging.getLogger(__name__)


@dataclass
class EventSource:
    """Metadata about an event source"""
    name: str
    priority: float  # Higher priority = more trusted source
    reliability: float  # 0-1 reliability score
    coverage: str  # geographical coverage description


class UnifiedEventsService:
    """
    Unified service that coordinates multiple event sources and applies AI evaluation
    """
    
    def __init__(self, ticketmaster_service=None, allevents_service=None, ai_service=None):
        """
        Initialize the unified events service
        
        Args:
            ticketmaster_service: Ticketmaster API service instance
            allevents_service: AllEvents API service instance  
            ai_service: AI service for intelligent filtering (optional)
        """
        self.ticketmaster_service = ticketmaster_service
        self.allevents_service = allevents_service
        self.ai_service = ai_service
        
        # Define event sources with metadata
        self.event_sources = {
            'ticketmaster': EventSource(
                name='Ticketmaster',
                priority=0.9,
                reliability=0.95,
                coverage='Global, strong in North America and Europe'
            ),
            'allevents': EventSource(
                name='AllEvents',
                priority=0.7,
                reliability=0.8,
                coverage='Global, diverse event types'
            )
        }
        
        # Configuration
        self.max_events_per_source = 50
        self.final_event_limit = 30
        self.ai_confidence_threshold = 0.6
        
    def search_unified_events(self, location: Dict[str, Any], user_interests: List[str] = None,
                            user_activity: str = "", personalization_data: Dict[str, Any] = None,
                            user_profile: Any = None) -> Dict[str, Any]:
        """
        Search for events from all available sources, group them, and apply AI evaluation
        
        Args:
            location: Dictionary with latitude, longitude, city, country
            user_interests: List of user interest categories
            user_activity: What the user wants to do
            personalization_data: Enhanced personalization data from background search
            user_profile: Enhanced user profile from user_profiling_service
            
        Returns:
            Dictionary containing:
            - events: List of AI-evaluated and ranked events
            - sources_used: List of sources that were queried
            - ai_insights: AI analysis of user preferences and event matching
            - total_found: Total events found before filtering
            - total_returned: Number of events after AI filtering
        """
        logger.info(f"Starting unified event search for location: {location}")
        logger.info(f"User activity: '{user_activity}', interests: {user_interests}")
        
        all_events = []
        sources_used = []
        search_results = {}
        
        # Collect events from all available sources in parallel
        with ThreadPoolExecutor(max_workers=3) as executor:
            future_to_source = {}
            
            # Submit search tasks for each available service
            if self.ticketmaster_service:
                future = executor.submit(
                    self._search_source_safely,
                    'ticketmaster',
                    self.ticketmaster_service,
                    location, user_interests, user_activity, personalization_data, user_profile
                )
                future_to_source[future] = 'ticketmaster'
            
            if self.allevents_service:
                future = executor.submit(
                    self._search_source_safely,
                    'allevents',
                    self.allevents_service,
                    location, user_interests, user_activity, personalization_data, user_profile
                )
                future_to_source[future] = 'allevents'
            
            # Collect results as they complete
            for future in as_completed(future_to_source):
                source_name = future_to_source[future]
                try:
                    events = future.result(timeout=30)  # 30 second timeout per source
                    if events:
                        all_events.extend(events)
                        sources_used.append(source_name)
                        search_results[source_name] = len(events)
                        logger.info(f"✅ {source_name}: Found {len(events)} events")
                    else:
                        logger.info(f"⚠️ {source_name}: No events found")
                        search_results[source_name] = 0
                except Exception as e:
                    logger.error(f"❌ {source_name}: Search failed - {e}")
                    search_results[source_name] = 0
        
        logger.info(f"Total events collected from all sources: {len(all_events)}")
        
        # Remove duplicates and group similar events
        deduplicated_events = self._deduplicate_events(all_events)
        logger.info(f"Events after deduplication: {len(deduplicated_events)}")
        
        # Apply AI-powered evaluation and ranking
        ai_results = self._apply_ai_evaluation(
            deduplicated_events, user_profile, user_activity, personalization_data
        )
        
        # Final filtering and ranking
        final_events = self._final_ranking_and_filtering(
            ai_results.get('ranked_events', deduplicated_events),
            user_profile,
            user_activity
        )
        
        # Remove cost information as requested
        final_events = self._remove_cost_information(final_events)
        
        logger.info(f"Final events returned after AI evaluation: {len(final_events)}")
        
        return {
            'events': final_events,
            'sources_used': sources_used,
            'search_results': search_results,
            'ai_insights': ai_results.get('insights', {}),
            'total_found': len(all_events),
            'total_returned': len(final_events),
            'deduplication_saved': len(all_events) - len(deduplicated_events)
        }
    
    def _search_source_safely(self, source_name: str, service: Any, *args) -> List[Any]:
        """Safely search a single event source with error handling"""
        try:
            logger.info(f"🔍 Searching {source_name}...")
            events = service.search_events(*args)
            return events if events else []
        except Exception as e:
            logger.error(f"Error searching {source_name}: {e}")
            return []
    
    def _deduplicate_events(self, events: List[Any]) -> List[Any]:
        """
        Remove duplicate events and group similar ones
        Uses event name, venue, and date for deduplication
        """
        seen_events = {}
        deduplicated = []
        
        for event in events:
            # Create a unique key for the event
            event_key = self._create_event_key(event)
            
            if event_key not in seen_events:
                seen_events[event_key] = event
                deduplicated.append(event)
            else:
                # If we find a duplicate, keep the one with higher reliability
                existing_event = seen_events[event_key]
                if self._should_replace_event(existing_event, event):
                    # Replace the existing event
                    deduplicated.remove(existing_event)
                    deduplicated.append(event)
                    seen_events[event_key] = event
        
        return deduplicated
    
    def _create_event_key(self, event: Any) -> str:
        """Create a unique key for event deduplication"""
        try:
            name = getattr(event, 'name', '').lower().strip()
            venue = getattr(event, 'venue', '').lower().strip()
            date = getattr(event, 'date', '').strip()
            
            # Normalize the name (remove common variations)
            name = self._normalize_event_name(name)
            
            return f"{name}|{venue}|{date}"
        except Exception as e:
            logger.warning(f"Error creating event key: {e}")
            return f"unknown_{id(event)}"
    
    def _normalize_event_name(self, name: str) -> str:
        """Normalize event name for better deduplication"""
        import re
        
        # Remove common prefixes/suffixes and normalize
        name = re.sub(r'\\b(the|a|an)\\b', '', name, flags=re.IGNORECASE)
        name = re.sub(r'[^a-z0-9\\s]', '', name)
        name = re.sub(r'\\s+', ' ', name).strip()
        
        return name
    
    def _should_replace_event(self, existing: Any, new: Any) -> bool:
        """Determine if a new event should replace an existing duplicate"""
        try:
            # Prefer events with more information
            existing_score = self._calculate_completeness_score(existing)
            new_score = self._calculate_completeness_score(new)
            
            return new_score > existing_score
        except Exception:
            return False
    
    def _calculate_completeness_score(self, event: Any) -> float:
        """Calculate how complete an event's information is"""
        score = 0.0
        
        # Check various fields for completeness
        if getattr(event, 'name', ''):
            score += 1.0
        if getattr(event, 'description', ''):
            score += 1.0
        if getattr(event, 'image_url', ''):
            score += 0.5
        if getattr(event, 'venue', '') != 'TBA':
            score += 0.5
        if getattr(event, 'address', ''):
            score += 0.5
        if getattr(event, 'time', '') != 'TBA':
            score += 0.5
        if getattr(event, 'url', ''):
            score += 0.5
        
        # Prefer events from higher reliability sources
        event_id = getattr(event, 'id', '')
        if 'ticketmaster' in event_id:
            score += 0.5  # Ticketmaster bonus
        
        return score
    
    def _apply_ai_evaluation(self, events: List[Any], user_profile: Any, 
                           user_activity: str, personalization_data: Dict[str, Any]) -> Dict[str, Any]:
        """Apply AI-powered evaluation and ranking to events"""
        try:
            # If we have an AI service, use it for advanced evaluation
            if self.ai_service:
                return self._advanced_ai_evaluation(events, user_profile, user_activity, personalization_data)
            else:
                # Fallback to rule-based evaluation
                return self._rule_based_evaluation(events, user_profile, user_activity, personalization_data)
        except Exception as e:
            logger.error(f"AI evaluation failed, using fallback: {e}")
            return {
                'ranked_events': events,
                'insights': {'error': str(e), 'method': 'fallback'}
            }
    
    def _rule_based_evaluation(self, events: List[Any], user_profile: Any,
                             user_activity: str, personalization_data: Dict[str, Any]) -> Dict[str, Any]:
        """Rule-based evaluation and ranking when AI service is not available"""
        
        logger.info("Applying rule-based event evaluation")
        
        for event in events:
            score = 0.5  # Base score
            factors = {}
            
            # Activity matching
            if user_activity:
                activity_score = self._calculate_activity_match(event, user_activity)
                score += activity_score * 0.3
                factors['activity_match'] = activity_score
            
            # Interest matching
            if user_profile:
                interest_score = self._calculate_interest_match(event, user_profile)
                score += interest_score * 0.3
                factors['interest_match'] = interest_score
            
            # Time relevance (prefer closer dates)
            time_score = self._calculate_time_relevance(event)
            score += time_score * 0.2
            factors['time_relevance'] = time_score
            
            # Completeness bonus
            completeness_score = self._calculate_completeness_score(event) / 5.0
            score += completeness_score * 0.2
            factors['completeness'] = completeness_score
            
            # Set the relevance score
            event.relevance_score = min(score, 1.0)
            event.personalization_factors = factors
            event.recommendation_reason = self._generate_recommendation_reason(factors, user_activity)
        
        # Sort by relevance score
        ranked_events = sorted(events, key=lambda x: getattr(x, 'relevance_score', 0), reverse=True)
        
        insights = {
            'method': 'rule_based',
            'total_evaluated': len(events),
            'avg_score': sum(getattr(e, 'relevance_score', 0) for e in events) / len(events) if events else 0,
            'top_factors': ['activity_match', 'interest_match', 'time_relevance', 'completeness']
        }
        
        return {
            'ranked_events': ranked_events,
            'insights': insights
        }
    
    def _calculate_activity_match(self, event: Any, user_activity: str) -> float:
        """Calculate how well an event matches the user's stated activity"""
        try:
            event_text = f"{getattr(event, 'name', '')} {getattr(event, 'description', '')} {getattr(event, 'category', '')}".lower()
            activity_lower = user_activity.lower()
            
            # Simple keyword matching
            activity_words = [word for word in activity_lower.split() if len(word) > 2]
            matches = sum(1 for word in activity_words if word in event_text)
            
            if not activity_words:
                return 0.0
            
            return min(matches / len(activity_words), 1.0)
        except Exception:
            return 0.0
    
    def _calculate_interest_match(self, event: Any, user_profile: Any) -> float:
        """Calculate how well an event matches the user's interests"""
        try:
            if not user_profile or not hasattr(user_profile, 'get'):
                return 0.0
            
            interests = user_profile.get('interests', [])
            if not interests:
                return 0.0
            
            event_category = getattr(event, 'category', '').lower()
            event_name = getattr(event, 'name', '').lower()
            
            matches = 0
            for interest in interests[:10]:  # Check top 10 interests
                if isinstance(interest, dict):
                    interest_text = interest.get('category', '').lower()
                    keywords = interest.get('keywords', [])
                elif hasattr(interest, 'category'):
                    interest_text = interest.category.lower()
                    keywords = getattr(interest, 'keywords', [])
                else:
                    interest_text = str(interest).lower()
                    keywords = []
                
                # Check category match
                if interest_text in event_category or event_category in interest_text:
                    matches += 1
                
                # Check keyword matches
                for keyword in keywords[:5]:  # Check top 5 keywords
                    if keyword.lower() in event_name:
                        matches += 0.5
            
            return min(matches / len(interests), 1.0)
        except Exception:
            return 0.0
    
    def _calculate_time_relevance(self, event: Any) -> float:
        """Calculate time relevance (prefer events happening soon)"""
        try:
            from datetime import datetime, timedelta
            
            event_date = getattr(event, 'date', '')
            if not event_date or event_date == 'TBA':
                return 0.3  # Neutral score for unknown dates
            
            # Try to parse the date
            try:
                # Assuming date format is YYYY-MM-DD or similar
                event_dt = datetime.strptime(event_date[:10], '%Y-%m-%d')
                now = datetime.now()
                days_diff = (event_dt - now).days
                
                if days_diff < 0:
                    return 0.1  # Past event
                elif days_diff <= 7:
                    return 1.0  # This week
                elif days_diff <= 14:
                    return 0.8  # Next week
                elif days_diff <= 30:
                    return 0.6  # This month
                else:
                    return 0.4  # Future
            except ValueError:
                return 0.3  # Can't parse date
                
        except Exception:
            return 0.3
    
    def _generate_recommendation_reason(self, factors: Dict[str, float], user_activity: str) -> str:
        """Generate a human-readable recommendation reason"""
        reasons = []
        
        if factors.get('activity_match', 0) > 0.7:
            reasons.append(f"closely matches your interest in '{user_activity}'")
        elif factors.get('activity_match', 0) > 0.4:
            reasons.append(f"relates to your interest in '{user_activity}'")
        
        if factors.get('interest_match', 0) > 0.7:
            reasons.append("aligns with your profile interests")
        elif factors.get('interest_match', 0) > 0.4:
            reasons.append("matches some of your interests")
        
        if factors.get('time_relevance', 0) > 0.8:
            reasons.append("happening soon")
        
        if factors.get('completeness', 0) > 0.8:
            reasons.append("has detailed information available")
        
        if not reasons:
            return "recommended based on your location and general interests"
        
        return "Recommended because it " + " and ".join(reasons)
    
    def _final_ranking_and_filtering(self, events: List[Any], user_profile: Any, user_activity: str) -> List[Any]:
        """Apply final ranking and filtering to events"""
        # Filter out events with very low relevance scores
        filtered_events = [e for e in events if getattr(e, 'relevance_score', 0) > 0.2]
        
        # Limit to configured maximum
        final_events = filtered_events[:self.final_event_limit]
        
        logger.info(f"Final filtering: {len(events)} -> {len(filtered_events)} -> {len(final_events)}")
        
        return final_events
    
    def _remove_cost_information(self, events: List[Any]) -> List[Any]:
        """Remove cost/price information from events as requested"""
        for event in events:
            # Set price fields to None
            if hasattr(event, 'price_min'):
                event.price_min = None
            if hasattr(event, 'price_max'):
                event.price_max = None
        
        return events
    
    def _advanced_ai_evaluation(self, events: List[Any], user_profile: Any,
                              user_activity: str, personalization_data: Dict[str, Any]) -> Dict[str, Any]:
        """Advanced AI evaluation using external AI service (placeholder for future implementation)"""
        # This would integrate with OpenAI or other AI services for more sophisticated evaluation
        # For now, fall back to rule-based evaluation
        logger.info("Advanced AI evaluation not yet implemented, using rule-based evaluation")
        return self._rule_based_evaluation(events, user_profile, user_activity, personalization_data)

========================================
# File: /home/jarvis/Downloads/WhatNowAI_test/services/ticketmaster_service.py
========================================

"""
Ticketmaster API service for event discovery

This module integrates with the Ticketmaster Discovery API to find local events
and activities based on user location and interests. Includes advanced personalization,
event categorization, filtering, and comprehensive error handling for intelligent
event discovery that adapts to user preferences and behavioral patterns.
"""

import requests
import logging
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from datetime import datetime, timedelta
import json
import re

logger = logging.getLogger(__name__)


@dataclass
class Event:
    """Enhanced event data structure with personalization metrics"""
    id: str
    name: str
    url: str
    date: str
    time: str
    venue: str
    address: str
    city: str
    latitude: float
    longitude: float
    category: str
    subcategory: str = ""
    price_min: Optional[float] = None
    price_max: Optional[float] = None
    image_url: str = ""
    description: str = ""
    
    # Enhanced fields for personalization
    relevance_score: float = 0.0
    personalization_factors: Dict[str, float] = None
    recommendation_reason: str = ""
    interest_matches: List[str] = None
    behavioral_fit: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.personalization_factors is None:
            self.personalization_factors = {}
        if self.interest_matches is None:
            self.interest_matches = []
        if self.behavioral_fit is None:
            self.behavioral_fit = {}
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert event to dictionary for JSON serialization"""
        return {
            'id': self.id,
            'name': self.name,
            'url': self.url,
            'date': self.date,
            'time': self.time,
            'venue': self.venue,
            'address': self.address,
            'city': self.city,
            'latitude': self.latitude,
            'longitude': self.longitude,
            'category': self.category,
            'subcategory': self.subcategory,
            'price_min': self.price_min,
            'price_max': self.price_max,
            'image_url': self.image_url,
            'description': self.description,
            'relevance_score': getattr(self, 'relevance_score', 0.0),
            'personalization_factors': getattr(self, 'personalization_factors', {}),
            'recommendation_reason': getattr(self, 'recommendation_reason', ''),
            'interest_matches': getattr(self, 'interest_matches', []),
            'behavioral_fit': getattr(self, 'behavioral_fit', {}),
            'ai_analysis': {
                'score': getattr(self, 'personalization_factors', {}).get('ai_score', 0),
                'confidence': getattr(self, 'personalization_factors', {}).get('ai_confidence', 0),
                'reason': getattr(self, 'personalization_factors', {}).get('ai_reason', '')
            }
        }


class TicketmasterService:
    """Advanced service for intelligent event discovery with personalization"""
    
    def __init__(self, api_key: str, config: Dict[str, Any]):
        """
        Initialize Ticketmaster service
        
        Args:
            api_key: Ticketmaster API key
            config: Configuration dictionary
        """
        self.api_key = api_key
        self.config = config
        self.base_url = config.get('BASE_URL', 'https://app.ticketmaster.com/discovery/v2')
        self.session = requests.Session()
        
        # Enhanced personalization components
        self.category_mapper = self._init_category_mapper()
        self.preference_analyzer = self._init_preference_analyzer()
        self.behavioral_filter = self._init_behavioral_filter()
        
    def search_events(self, location: Dict[str, Any], user_interests: List[str] = None, 
                     user_activity: str = "", personalization_data: Dict[str, Any] = None,
                     user_profile: Any = None) -> List[Event]:
        """
        Search for events near a location based on user interests and enhanced personalization
        
        Args:
            location: Dictionary with latitude, longitude, city, country
            user_interests: List of user interest categories
            user_activity: What the user wants to do
            personalization_data: Enhanced personalization data from background search
            user_profile: Enhanced user profile from user_profiling_service
            
        Returns:
            List of Event objects filtered and ranked by AI and user preferences
        """
        if not self.api_key:
            logger.warning("Ticketmaster API key not provided")
            return []
        
        latitude = location.get('latitude')
        longitude = location.get('longitude')
        
        # Convert to float if needed
        try:
            if latitude is not None:
                latitude = float(latitude)
            if longitude is not None:
                longitude = float(longitude)
        except (ValueError, TypeError) as e:
            logger.error(f"Failed to convert coordinates to float in Ticketmaster service: {e}")
            return []
        
        if not latitude or not longitude:
            logger.warning("Location coordinates not provided or invalid")
            return []
        
        logger.info(f"Searching events with AI-enhanced personalization: "
                   f"location=({latitude},{longitude}), "
                   f"basic_interests={user_interests}, "
                   f"activity='{user_activity}', "
                   f"has_personalization_data={bool(personalization_data)}, "
                   f"has_user_profile={bool(user_profile)}")
        
        events = []
        
        try:
            # Create enhanced personalization data that includes user profile
            enhanced_personalization = self._merge_personalization_data(
                personalization_data, user_profile, user_activity
            )
            
            # Extract enhanced interests from all sources
            enhanced_interests = self._extract_enhanced_interests(
                enhanced_personalization, user_interests, user_activity
            )
            
            # Search for events based on location
            base_events = self._search_by_location(latitude, longitude)
            events.extend(base_events)
            
            # Search for events based on enhanced user profile
            if enhanced_interests['categories'] or user_activity:
                interest_events = self._search_by_enhanced_interests(
                    latitude, longitude, enhanced_interests, user_activity
                )
                events.extend(interest_events)
            
            # Remove duplicates based on event ID
            unique_events = {event.id: event for event in events}
            events = list(unique_events.values())
            
            # Filter and rank events using AI and personalization
            events = self._filter_and_rank_events(events, enhanced_interests, enhanced_personalization)
            
            # Sort by relevance score (highest first) then by date
            events.sort(key=lambda e: (-getattr(e, 'relevance_score', 0), e.date))
            
            # Limit results
            max_events = self.config.get('MAX_EVENTS', 20)
            final_events = events[:max_events]
            
            # Add personalization metadata to events
            self._add_personalization_metadata(final_events, enhanced_interests, enhanced_personalization)
            
            logger.info(f"AI-enhanced search completed: {len(final_events)} events returned")
            
            return final_events
            
        except Exception as e:
            logger.error(f"Error searching Ticketmaster events: {e}")
            return []
    
    def _merge_personalization_data(self, personalization_data: Dict[str, Any], 
                                   user_profile: Any, user_activity: str) -> Dict[str, Any]:
        """Merge personalization data from different sources"""
        merged_data = personalization_data.copy() if personalization_data else {}
        
        # Add user activity
        merged_data['activity'] = user_activity
        
        # If we have minimal data, ensure we have at least basic context
        if not merged_data and user_activity:
            logger.info("Creating minimal personalization context from activity")
            merged_data = {
                'activity': user_activity,
                'user_profile': {
                    'primary_activity': user_activity,
                    'interests': [],
                    'preferences': {'activity_style': 'balanced'},
                    'behavioral_patterns': {},
                    'activity_context': {'intent': 'seeking'},
                    'completion_score': 10
                },
                'minimal_context': True
            }
        
        # Add user profile data if available
        if user_profile:
            try:
                # Get recommendation context from enhanced user profile
                from services.user_profiling_service import EnhancedUserProfilingService
                
                if hasattr(user_profile, 'get_top_interests'):
                    # It's a UserProfile object
                    merged_data['user_profile'] = {
                        'name': user_profile.name,
                        'location': user_profile.location,
                        'primary_activity': user_profile.activity,
                        'completion_score': getattr(user_profile, 'profile_completion', 0),
                        'interests': [i.to_dict() for i in user_profile.get_top_interests(10)],
                        'preferences': getattr(user_profile, 'preferences', {}),
                        'behavioral_patterns': getattr(user_profile, 'behavioral_patterns', {}),
                        'activity_context': getattr(user_profile, 'activity_context', {}),
                        'demographic_hints': getattr(user_profile, 'demographic_hints', {})
                    }
                elif isinstance(user_profile, dict):
                    # It's already a dictionary
                    merged_data['user_profile'] = user_profile
                
            except Exception as e:
                logger.warning(f"Failed to merge user profile data: {e}")
        
        return merged_data
    
    def _add_personalization_metadata(self, events: List[Event], enhanced_interests: Dict[str, Any],
                                     personalization_data: Dict[str, Any]):
        """Add detailed personalization metadata to events"""
        for event in events:
            if not hasattr(event, 'personalization_factors'):
                setattr(event, 'personalization_factors', {})
            
            # Add interest matches
            event_text = f"{event.name} {event.description} {event.subcategory}".lower()
            keywords = enhanced_interests.get('keywords', [])
            
            matched_keywords = [kw for kw in keywords if kw.lower() in event_text]
            setattr(event, 'interest_matches', matched_keywords)
            
            # Add behavioral fit analysis
            user_profile = personalization_data.get('user_profile', {})
            behavioral_patterns = user_profile.get('behavioral_patterns', {})
            preferences = user_profile.get('preferences', {})
            
            behavioral_fit = {}
            
            # Social preference fit
            social_pref = preferences.get('social_preference', 'flexible')
            if social_pref != 'flexible':
                if social_pref == 'group' and event.category in ['music', 'sports']:
                    behavioral_fit['social_fit'] = 'high'
                elif social_pref == 'solo' and event.category in ['arts']:
                    behavioral_fit['social_fit'] = 'high'
                else:
                    behavioral_fit['social_fit'] = 'medium'
            
            # Activity style fit
            activity_style = preferences.get('activity_style', 'balanced')
            if 'adventure' in activity_style and any(word in event_text for word in ['outdoor', 'extreme', 'adventure']):
                behavioral_fit['adventure_fit'] = 'high'
            elif 'creative' in activity_style and event.category == 'arts':
                behavioral_fit['creative_fit'] = 'high'
            elif 'educational' in activity_style and any(word in event_text for word in ['workshop', 'lecture', 'learn']):
                behavioral_fit['educational_fit'] = 'high'
            
            setattr(event, 'behavioral_fit', behavioral_fit)
            
            # Update personalization factors
            event.personalization_factors.update({
                'keyword_matches': len(matched_keywords),
                'category_relevance': 1.0 if event.category in enhanced_interests.get('categories', []) else 0.5,
                'behavioral_fit_score': len(behavioral_fit) / 3.0,  # Normalize by number of possible fits
                'user_profile_completion': user_profile.get('completion_score', 0) / 100.0
            })
    
    def _search_by_location(self, latitude: float, longitude: float) -> List[Event]:
        """Search for events by location"""
        events = []
        
        params = {
            'apikey': self.api_key,
            'latlong': f"{latitude},{longitude}",
            'radius': self.config.get('SEARCH_RADIUS', 50),
            'unit': 'miles',
            'size': 20,
            'sort': 'date,asc'
        }
        
        try:
            response = self._make_request('/events.json', params)
            if response and '_embedded' in response:
                events = self._parse_events(response['_embedded']['events'])
        except Exception as e:
            logger.error(f"Error searching events by location: {e}")
        
        return events
    
    def _search_by_interests(self, latitude: float, longitude: float, 
                           interests: List[str], activity: str) -> List[Event]:
        """Search for events based on user interests and activity"""
        events = []
        
        # Map user interests to Ticketmaster categories
        category_mapping = {
            'music': 'music',
            'sports': 'sports',
            'theater': 'arts',
            'comedy': 'arts',
            'family': 'family',
            'food': 'miscellaneous',
            'fitness': 'sports',
            'technology': 'miscellaneous',
            'art': 'arts',
            'dance': 'arts'
        }
        
        # Determine search categories
        search_categories = []
        if interests:
            for interest in interests:
                category = category_mapping.get(interest.lower())
                if category and category not in search_categories:
                    search_categories.append(category)
        
        # Use AI to determine category from activity if available
        if activity and not search_categories:
            search_categories = self._categorize_activity_with_ai(activity)
        
        # If no specific categories, use default
        if not search_categories:
            search_categories = self.config.get('DEFAULT_CATEGORIES', ['music', 'sports', 'arts'])
        
        # Search for each category
        for category in search_categories:
            try:
                params = {
                    'apikey': self.api_key,
                    'latlong': f"{latitude},{longitude}",
                    'radius': self.config.get('SEARCH_RADIUS', 50),
                    'unit': 'miles',
                    'size': 10,
                    'sort': 'date,asc',
                    'classificationName': category
                }
                
                response = self._make_request('/events.json', params)
                if response and '_embedded' in response:
                    category_events = self._parse_events(response['_embedded']['events'])
                    events.extend(category_events)
                    
            except Exception as e:
                logger.error(f"Error searching events for category {category}: {e}")
                continue
        
        return events
    
    def _categorize_activity_with_ai(self, activity: str) -> List[str]:
        """Use OpenAI to categorize user activity into Ticketmaster categories"""
        try:
            from config.settings import OPENAI_API_KEY
            if not OPENAI_API_KEY:
                return ['miscellaneous']
            
            from openai import OpenAI
            client = OpenAI(api_key=OPENAI_API_KEY)
            
            prompt = f"""
            Based on the activity "{activity}", suggest the most relevant Ticketmaster event categories.
            
            Available categories:
            - music (concerts, festivals, shows)
            - sports (games, tournaments, fitness events)
            - arts (theater, comedy, exhibitions, dance)
            - family (kid-friendly events)
            - miscellaneous (other events)
            
            Return only the category names as a comma-separated list, maximum 3 categories.
            Activity: {activity}
            Categories:
            """
            
            response = client.completions.create(
                model="gpt-3.5-turbo-instruct",
                prompt=prompt,
                max_tokens=50,
                temperature=0.3
            )
            
            categories_text = response.choices[0].text.strip()
            categories = [cat.strip().lower() for cat in categories_text.split(',')]
            
            # Validate categories
            valid_categories = ['music', 'sports', 'arts', 'family', 'miscellaneous']
            return [cat for cat in categories if cat in valid_categories]
            
        except Exception as e:
            logger.warning(f"AI categorization failed: {e}")
            return ['miscellaneous']
    
    def _make_request(self, endpoint: str, params: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Make a request to the Ticketmaster API"""
        url = self.base_url + endpoint
        
        try:
            response = self.session.get(
                url, 
                params=params, 
                timeout=self.config.get('TIMEOUT', 10)
            )
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Ticketmaster API request failed: {e}")
            return None
    
    def _parse_events(self, events_data: List[Dict[str, Any]]) -> List[Event]:
        """Parse events from Ticketmaster API response"""
        events = []
        
        for event_data in events_data:
            try:
                event = self._parse_single_event(event_data)
                if event:
                    events.append(event)
            except Exception as e:
                logger.warning(f"Failed to parse event: {e}")
                continue
        
        return events
    
    def _parse_single_event(self, event_data: Dict[str, Any]) -> Optional[Event]:
        """Parse a single event from API response"""
        try:
            # Basic event info
            event_id = event_data.get('id', '')
            name = event_data.get('name', 'Unknown Event')
            url = event_data.get('url', '')
            
            # Date and time
            dates = event_data.get('dates', {})
            start = dates.get('start', {})
            date = start.get('localDate', '')
            time = start.get('localTime', '')
            
            # Venue information
            venues = event_data.get('_embedded', {}).get('venues', [])
            if not venues:
                return None
            
            venue_data = venues[0]
            venue_name = venue_data.get('name', 'Unknown Venue')
            
            # Address
            address_data = venue_data.get('address', {})
            address = address_data.get('line1', '')
            
            city_data = venue_data.get('city', {})
            city = city_data.get('name', '')
            
            # Coordinates
            location_data = venue_data.get('location', {})
            try:
                latitude = float(location_data.get('latitude', 0))
                longitude = float(location_data.get('longitude', 0))
            except (ValueError, TypeError):
                return None
            
            if not latitude or not longitude:
                return None
            
            # Category
            classifications = event_data.get('classifications', [])
            category = 'miscellaneous'
            subcategory = ''
            
            if classifications:
                segment = classifications[0].get('segment', {})
                genre = classifications[0].get('genre', {})
                category = segment.get('name', 'miscellaneous').lower()
                subcategory = genre.get('name', '')
            
            # Price information
            price_ranges = event_data.get('priceRanges', [])
            price_min = None
            price_max = None
            
            if price_ranges:
                price_min = price_ranges[0].get('min')
                price_max = price_ranges[0].get('max')
            
            # Images
            images = event_data.get('images', [])
            image_url = ''
            if images:
                # Get the largest image
                image_url = max(images, key=lambda img: img.get('width', 0) * img.get('height', 0)).get('url', '')
            
            # Description
            description = event_data.get('info', '')
            
            return Event(
                id=event_id,
                name=name,
                url=url,
                date=date,
                time=time,
                venue=venue_name,
                address=address,
                city=city,
                latitude=latitude,
                longitude=longitude,
                category=category,
                subcategory=subcategory,
                price_min=price_min,
                price_max=price_max,
                image_url=image_url,
                description=description
            )
            
        except Exception as e:
            logger.error(f"Error parsing event data: {e}")
            return None
    
    def _extract_enhanced_interests(self, personalization_data: Dict[str, Any], 
                                  basic_interests: List[str], activity: str) -> Dict[str, Any]:
        """
        Extract and combine interests from personalization data and basic inputs
        
        Args:
            personalization_data: Data from background search with interests
            basic_interests: Basic interest categories
            activity: User activity description
            
        Returns:
            Enhanced interests dictionary with categories, keywords, and confidence scores
        """
        enhanced_interests = {
            'categories': [],
            'keywords': [],
            'category_scores': {},
            'activity_keywords': []
        }
        
        # Start with basic interests
        if basic_interests:
            enhanced_interests['categories'].extend(basic_interests)
            for interest in basic_interests:
                enhanced_interests['category_scores'][interest] = 0.5  # Default confidence
        
        # Extract interests from personalization data
        if personalization_data:
            # Check for interests from background search
            search_results = personalization_data.get('search_results', {})
            search_summaries = personalization_data.get('search_summaries', {})
            
            # Extract from search summaries (these might contain interest indicators)
            for source, summary in search_summaries.items():
                if summary and isinstance(summary, str):
                    interest_keywords = self._extract_keywords_from_text(summary)
                    enhanced_interests['keywords'].extend(interest_keywords)
            
            # If there are extracted interests in the data
            interests_data = personalization_data.get('interests', [])
            if interests_data:
                for interest_item in interests_data:
                    if isinstance(interest_item, dict):
                        category = interest_item.get('category', '')
                        confidence = interest_item.get('confidence', 0.5)
                        keywords = interest_item.get('keywords', [])
                        
                        if category and category not in enhanced_interests['categories']:
                            enhanced_interests['categories'].append(category)
                            enhanced_interests['category_scores'][category] = confidence
                            enhanced_interests['keywords'].extend(keywords)
        
        # Extract keywords from activity description
        if activity:
            activity_keywords = self._extract_keywords_from_text(activity)
            enhanced_interests['activity_keywords'] = activity_keywords
            enhanced_interests['keywords'].extend(activity_keywords)
        
        # Remove duplicates
        enhanced_interests['keywords'] = list(set(enhanced_interests['keywords']))
        enhanced_interests['categories'] = list(set(enhanced_interests['categories']))
        
        logger.info(f"Enhanced interests extracted: {len(enhanced_interests['categories'])} categories, "
                   f"{len(enhanced_interests['keywords'])} keywords")
        
        return enhanced_interests
    
    def _extract_keywords_from_text(self, text: str) -> List[str]:
        """Extract relevant keywords from text content"""
        if not text:
            return []
        
        # Simple keyword extraction - can be enhanced with NLP libraries
        import re
        
        # Define interest-related keywords
        interest_keywords = {
            'music': ['music', 'concert', 'band', 'singer', 'album', 'song', 'artist', 'festival', 'show', 'performance'],
            'sports': ['sport', 'game', 'team', 'fitness', 'exercise', 'basketball', 'football', 'soccer', 'tennis', 'golf'],
            'arts': ['art', 'theater', 'museum', 'gallery', 'dance', 'exhibition', 'culture', 'painting', 'sculpture'],
            'food': ['food', 'restaurant', 'cooking', 'cuisine', 'chef', 'dining', 'culinary', 'recipe', 'meal'],
            'technology': ['tech', 'programming', 'code', 'software', 'computer', 'digital', 'innovation', 'startup'],
            'entertainment': ['movie', 'film', 'tv', 'show', 'entertainment', 'comedy', 'drama', 'cinema'],
            'nature': ['nature', 'outdoor', 'hiking', 'camping', 'park', 'beach', 'environment', 'eco'],
            'social': ['community', 'social', 'networking', 'meetup', 'group', 'volunteer', 'charity'],
            'education': ['education', 'learning', 'workshop', 'seminar', 'course', 'training', 'lecture'],
            'business': ['business', 'networking', 'entrepreneur', 'startup', 'conference', 'professional']
        }
        
        text_lower = text.lower()
        found_keywords = []
        
        for category, keywords in interest_keywords.items():
            for keyword in keywords:
                if keyword in text_lower:
                    found_keywords.append(keyword)
        
        return found_keywords
    
    def _search_by_enhanced_interests(self, latitude: float, longitude: float, 
                                    enhanced_interests: Dict[str, Any], activity: str) -> List[Event]:
        """Search for events based on enhanced interest profile"""
        events = []
        
        # Map enhanced interests to Ticketmaster categories
        category_mapping = {
            'music': 'music',
            'sports': 'sports', 
            'theater': 'arts',
            'arts': 'arts',
            'comedy': 'arts',
            'family': 'family',
            'food': 'miscellaneous',
            'fitness': 'sports',
            'technology': 'miscellaneous',
            'entertainment': 'arts',
            'nature': 'miscellaneous',
            'social': 'miscellaneous',
            'education': 'miscellaneous',
            'business': 'miscellaneous'
        }
        
        # Get categories with confidence scores
        search_categories = []
        category_scores = enhanced_interests.get('category_scores', {})
        
        for category in enhanced_interests.get('categories', []):
            tm_category = category_mapping.get(category.lower())
            if tm_category and tm_category not in search_categories:
                search_categories.append(tm_category)
        
        # If no categories from interests, try to derive from keywords
        if not search_categories and enhanced_interests.get('keywords'):
            keywords_text = ' '.join(enhanced_interests['keywords'])
            search_categories = self._categorize_activity_with_ai(keywords_text)
        
        # If still no categories, use activity
        if not search_categories and activity:
            search_categories = self._categorize_activity_with_ai(activity)
        
        # Fallback to default categories
        if not search_categories:
            search_categories = self.config.get('DEFAULT_CATEGORIES', ['music', 'sports', 'arts'])
        
        # Search for each category with keyword filtering
        for category in search_categories:
            try:
                params = {
                    'apikey': self.api_key,
                    'latlong': f"{latitude},{longitude}",
                    'radius': self.config.get('SEARCH_RADIUS', 50),
                    'unit': 'miles',
                    'size': 15,  # Get more results for better filtering
                    'sort': 'date,asc',
                    'classificationName': category
                }
                
                # Add keyword filtering if available
                keywords = enhanced_interests.get('keywords', [])
                activity_keywords = enhanced_interests.get('activity_keywords', [])
                all_keywords = keywords + activity_keywords
                
                if all_keywords:
                    # Use most relevant keywords for search
                    top_keywords = all_keywords[:3]  # Limit to avoid too restrictive search
                    keyword_query = ' OR '.join(top_keywords)
                    params['keyword'] = keyword_query
                
                response = self._make_request('/events.json', params)
                if response and '_embedded' in response:
                    category_events = self._parse_events(response['_embedded']['events'])
                    events.extend(category_events)
                    
            except Exception as e:
                logger.error(f"Error searching events for enhanced category {category}: {e}")
                continue
        
        return events
    
    def _filter_and_rank_events(self, events: List[Event], enhanced_interests: Dict[str, Any], 
                               personalization_data: Dict[str, Any]) -> List[Event]:
        """
        Filter and rank events based on enhanced user profile using AI analysis
        
        Args:
            events: List of events to filter and rank
            enhanced_interests: Enhanced interest data
            personalization_data: Full personalization data
            
        Returns:
            Filtered and ranked events with relevance scores and AI recommendations
        """
        if not events:
            return events
        
        # Use AI to intelligently rank events
        events = self._ai_rank_events(events, enhanced_interests, personalization_data)
        
        # Apply traditional scoring as backup/boost
        events = self._apply_traditional_scoring(events, enhanced_interests)
        
        # Filter out events with very low relevance
        min_relevance = self.config.get('MIN_RELEVANCE_SCORE', 0.15)
        filtered_events = [event for event in events if getattr(event, 'relevance_score', 0) >= min_relevance]
        
        logger.info(f"AI-filtered {len(events)} events down to {len(filtered_events)} relevant events")
        
        return filtered_events
    
    def _ai_rank_events(self, events: List[Event], enhanced_interests: Dict[str, Any], 
                       personalization_data: Dict[str, Any]) -> List[Event]:
        """Use OpenAI to intelligently rank events based on user profile and activity request"""
        try:
            from config.settings import OPENAI_API_KEY
            if not OPENAI_API_KEY or len(events) == 0:
                return events
            
            from openai import OpenAI
            client = OpenAI(api_key=OPENAI_API_KEY)
            
            # Extract user context
            user_activity = personalization_data.get('activity', '') if personalization_data else ''
            user_interests = enhanced_interests.get('categories', [])
            user_keywords = enhanced_interests.get('keywords', [])
            activity_keywords = enhanced_interests.get('activity_keywords', [])
            
            # Get user profile data if available
            user_profile_data = personalization_data.get('user_profile', {}) if personalization_data else {}
            preferences = user_profile_data.get('preferences', {})
            behavioral_patterns = user_profile_data.get('behavioral_patterns', {})
            activity_context = user_profile_data.get('activity_context', {})
            
            # Create event summaries for AI analysis
            event_summaries = []
            for i, event in enumerate(events[:15]):  # Limit to top 15 events to avoid token limits
                event_summary = {
                    'index': i,
                    'name': event.name,
                    'category': event.category,
                    'subcategory': event.subcategory,
                    'venue': event.venue,
                    'date': event.date,
                    'time': event.time,
                    'description': event.description[:200] if event.description else '',
                    'price_min': event.price_min,
                    'price_max': event.price_max
                }
                event_summaries.append(event_summary)
            
            # Create comprehensive prompt for AI analysis
            prompt = self._create_ai_ranking_prompt(
                user_activity, user_interests, user_keywords, activity_keywords,
                preferences, behavioral_patterns, activity_context, event_summaries
            )
            
            # Get AI ranking
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are an expert event recommendation AI. Analyze user profiles and rank events based on relevance to their specific activity request and interests."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.3
            )
            
            # Parse AI response and apply scores
            ai_rankings = self._parse_ai_rankings(response.choices[0].message.content)
            events = self._apply_ai_rankings(events, ai_rankings)
            
            logger.info(f"AI ranking completed for {len(events)} events")
            
        except Exception as e:
            logger.warning(f"AI ranking failed, falling back to traditional scoring: {e}")
        
        return events
    
    def _create_ai_ranking_prompt(self, user_activity: str, user_interests: List[str], 
                                 user_keywords: List[str], activity_keywords: List[str],
                                 preferences: Dict[str, Any], behavioral_patterns: Dict[str, Any],
                                 activity_context: Dict[str, Any], event_summaries: List[Dict]) -> str:
        """Create a comprehensive prompt for AI event ranking"""
        
        prompt = f"""
You are helping a user find the most relevant events based on their specific request and profile.

USER'S ACTIVITY REQUEST: "{user_activity}"

USER PROFILE:
- Primary Interests: {', '.join(user_interests) if user_interests else 'None specified'}
- Interest Keywords: {', '.join(user_keywords) if user_keywords else 'None'}
- Activity Keywords: {', '.join(activity_keywords) if activity_keywords else 'None'}

PREFERENCES:
- Preferred Categories: {preferences.get('preferred_categories', [])}
- Social Preference: {preferences.get('social_preference', 'flexible')}
- Activity Style: {preferences.get('activity_style', 'balanced')}
- Budget Preference: {preferences.get('budget_preference', 'medium')}
- Preferred Time: {preferences.get('preferred_time', 'flexible')}

BEHAVIORAL PATTERNS:
- Adventure Seeking: {behavioral_patterns.get('adventure_seeker', 0):.2f}
- Social Learning: {behavioral_patterns.get('social_learner', 0):.2f}
- Creative Expression: {behavioral_patterns.get('creative_expression', 0):.2f}
- Learning Oriented: {behavioral_patterns.get('learning_oriented', 0):.2f}

ACTIVITY CONTEXT:
- Intent: {activity_context.get('intent', 'unknown')}
- Urgency: {activity_context.get('urgency', 'medium')}
- Social Setting: {activity_context.get('social_setting', 'flexible')}
- Budget Preference: {activity_context.get('budget_preference', 'medium')}

AVAILABLE EVENTS:
"""
        
        for event in event_summaries:
            price_info = ""
            if event['price_min'] is not None:
                if event['price_max'] and event['price_max'] != event['price_min']:
                    price_info = f" (${event['price_min']}-${event['price_max']})"
                else:
                    price_info = f" (${event['price_min']})"
            elif event['price_min'] == 0 or event['price_min'] is None:
                price_info = " (Free/TBD)"
            
            prompt += f"""
{event['index']}. {event['name']}
   Category: {event['category']} | {event['subcategory']}
   Date/Time: {event['date']} at {event['time']}
   Venue: {event['venue']}{price_info}
   Description: {event['description']}
"""
        
        prompt += f"""

TASK:
Rank these events from 0-10 based on how well they match:
1. The user's specific activity request: "{user_activity}"
2. Their interests and behavioral patterns
3. Their preferences and context

Focus heavily on what the user actually said they want to do that day.

Provide your response as a JSON array with this format:
[
  {{"index": 0, "score": 8.5, "reason": "Perfect match for user's request because..."}},
  {{"index": 1, "score": 7.2, "reason": "Good fit because..."}},
  ...
]

Only include events with scores 5.0 or higher. Sort by score (highest first).
"""
        
        return prompt
    
    def _parse_ai_rankings(self, ai_response: str) -> Dict[int, Dict[str, Any]]:
        """Parse AI ranking response into usable format"""
        rankings = {}
        
        try:
            import json
            import re
            
            # Try to extract JSON from response
            json_match = re.search(r'\[.*?\]', ai_response, re.DOTALL)
            if json_match:
                rankings_data = json.loads(json_match.group())
                
                for item in rankings_data:
                    if isinstance(item, dict) and 'index' in item and 'score' in item:
                        index = item['index']
                        rankings[index] = {
                            'score': float(item['score']),
                            'reason': item.get('reason', ''),
                            'ai_confidence': 0.9
                        }
            
        except Exception as e:
            logger.warning(f"Failed to parse AI rankings: {e}")
        
        return rankings
    
    def _apply_ai_rankings(self, events: List[Event], ai_rankings: Dict[int, Dict[str, Any]]) -> List[Event]:
        """Apply AI rankings to events"""
        for i, event in enumerate(events):
            if i in ai_rankings:
                ranking = ai_rankings[i]
                # Convert AI score (0-10) to relevance score (0-1)
                ai_score = ranking['score'] / 10.0
                
                # Set relevance score and metadata
                setattr(event, 'relevance_score', ai_score)
                setattr(event, 'recommendation_reason', ranking['reason'])
                
                # Update personalization factors
                if not hasattr(event, 'personalization_factors'):
                    setattr(event, 'personalization_factors', {})
                
                event.personalization_factors.update({
                    'ai_score': ai_score,
                    'ai_confidence': ranking['ai_confidence'],
                    'ai_reason': ranking['reason']
                })
            else:
                # Default score for events not ranked by AI
                setattr(event, 'relevance_score', 0.3)
        
        return events
    
    def _apply_traditional_scoring(self, events: List[Event], enhanced_interests: Dict[str, Any]) -> List[Event]:
        """Apply traditional scoring as backup and boost for AI scores"""
        keywords = enhanced_interests.get('keywords', [])
        categories = enhanced_interests.get('categories', [])
        category_scores = enhanced_interests.get('category_scores', {})
        
        for event in events:
            current_score = getattr(event, 'relevance_score', 0.0)
            traditional_boost = 0.0
            
            # Category match bonus
            event_category = event.category.lower()
            if event_category in [cat.lower() for cat in categories]:
                category_confidence = max([category_scores.get(cat, 0.5) for cat in categories 
                                         if cat.lower() == event_category])
                traditional_boost += category_confidence * 0.2
            
            # Keyword matching boost
            event_text = f"{event.name} {event.description} {event.subcategory}".lower()
            keyword_matches = sum(1 for keyword in keywords if keyword.lower() in event_text)
            
            if keywords and keyword_matches > 0:
                keyword_score = (keyword_matches / len(keywords)) * 0.15
                traditional_boost += keyword_score
            
            # Time preference boost
            try:
                from datetime import datetime
                event_date = datetime.strptime(event.date, '%Y-%m-%d')
                days_ahead = (event_date - datetime.now()).days
                
                if 0 <= days_ahead <= 7:  # This week
                    traditional_boost += 0.1
                elif 0 <= days_ahead <= 30:  # This month
                    traditional_boost += 0.05
                    
            except (ValueError, AttributeError):
                pass
            
            # Free events boost
            if event.price_min is None or event.price_min == 0:
                traditional_boost += 0.05
            
            # Apply boost to current score
            final_score = min(current_score + traditional_boost, 1.0)
            setattr(event, 'relevance_score', final_score)
        
        return events
    
    def _init_category_mapper(self) -> Dict[str, Dict[str, Any]]:
        """Initialize enhanced category mapping with subcategories and attributes"""
        return {
            'music': {
                'tm_categories': ['music'],
                'subcategories': {
                    'rock': ['rock', 'alternative', 'indie', 'punk'],
                    'pop': ['pop', 'mainstream', 'dance'],
                    'electronic': ['electronic', 'edm', 'techno', 'house'],
                    'jazz': ['jazz', 'blues', 'swing'],
                    'classical': ['classical', 'orchestra', 'symphony'],
                    'country': ['country', 'folk', 'americana'],
                    'hip-hop': ['hip-hop', 'rap', 'urban'],
                    'festival': ['festival', 'multi-day', 'outdoor']
                },
                'venue_types': ['concert hall', 'arena', 'club', 'festival ground', 'theater'],
                'keywords': ['concert', 'live music', 'band', 'artist', 'album', 'tour']
            },
            'sports': {
                'tm_categories': ['sports'],
                'subcategories': {
                    'team_sports': ['football', 'basketball', 'baseball', 'soccer', 'hockey'],
                    'individual': ['tennis', 'golf', 'boxing', 'mma', 'wrestling'],
                    'outdoor': ['cycling', 'running', 'triathlon', 'skiing'],
                    'motorsports': ['racing', 'formula', 'nascar', 'motorcycle']
                },
                'venue_types': ['stadium', 'arena', 'court', 'field', 'track'],
                'keywords': ['game', 'match', 'championship', 'tournament', 'league']
            },
            'arts': {
                'tm_categories': ['arts', 'theatre'],
                'subcategories': {
                    'theater': ['play', 'musical', 'drama', 'comedy'],
                    'dance': ['ballet', 'contemporary', 'cultural'],
                    'visual': ['exhibition', 'gallery', 'museum'],
                    'comedy': ['stand-up', 'improv', 'sketch']
                },
                'venue_types': ['theater', 'gallery', 'museum', 'arts center'],
                'keywords': ['performance', 'exhibition', 'show', 'cultural', 'artistic']
            },
            'family': {
                'tm_categories': ['family'],
                'subcategories': {
                    'kids': ['children', 'family-friendly', 'educational'],
                    'entertainment': ['circus', 'magic', 'puppet'],
                    'seasonal': ['holiday', 'christmas', 'halloween']
                },
                'venue_types': ['family center', 'park', 'indoor venue'],
                'keywords': ['family', 'kids', 'children', 'all ages']
            },
            'miscellaneous': {
                'tm_categories': ['miscellaneous'],
                'subcategories': {
                    'food': ['food festival', 'wine tasting', 'culinary'],
                    'technology': ['tech conference', 'startup', 'innovation'],
                    'health': ['wellness', 'fitness', 'yoga'],
                    'business': ['networking', 'conference', 'professional']
                },
                'venue_types': ['conference center', 'convention hall', 'outdoor space'],
                'keywords': ['festival', 'expo', 'conference', 'workshop']
            }
        }
    
    def _init_preference_analyzer(self) -> Dict[str, Any]:
        """Initialize preference analysis patterns"""
        return {
            'time_preferences': {
                'morning': {'keywords': ['morning', 'early', 'breakfast', 'sunrise'], 'hours': [6, 7, 8, 9, 10, 11]},
                'afternoon': {'keywords': ['afternoon', 'lunch', 'midday'], 'hours': [12, 13, 14, 15, 16, 17]},
                'evening': {'keywords': ['evening', 'dinner', 'night', 'sunset'], 'hours': [18, 19, 20, 21, 22]},
                'late_night': {'keywords': ['late', 'midnight', 'after hours'], 'hours': [23, 0, 1, 2]}
            },
            'price_sensitivity': {
                'budget': {'keywords': ['cheap', 'free', 'budget', 'affordable'], 'max_price': 25},
                'moderate': {'keywords': ['reasonable', 'fair', 'moderate'], 'max_price': 75},
                'premium': {'keywords': ['premium', 'luxury', 'high-end', 'exclusive'], 'max_price': None}
            },
            'venue_preferences': {
                'intimate': {'keywords': ['small', 'intimate', 'cozy', 'close'], 'capacity': 500},
                'medium': {'keywords': ['medium', 'moderate', 'comfortable'], 'capacity': 2000},
                'large': {'keywords': ['big', 'arena', 'stadium', 'massive'], 'capacity': None}
            }
        }
    
    def _init_behavioral_filter(self) -> Dict[str, Dict[str, Any]]:
        """Initialize behavioral filtering patterns"""
        return {
            'social_preference': {
                'solo': {
                    'boost_categories': ['arts', 'education', 'cultural'],
                    'avoid_categories': ['party', 'festival'],
                    'venue_preference': 'intimate'
                },
                'group': {
                    'boost_categories': ['music', 'sports', 'festival'],
                    'avoid_categories': ['meditation', 'lecture'],
                    'venue_preference': 'large'
                },
                'family': {
                    'boost_categories': ['family', 'educational', 'cultural'],
                    'filter_content': True,
                    'time_preference': 'afternoon'
                }
            },
            'activity_style': {
                'adventurous': {
                    'boost_keywords': ['new', 'unique', 'extreme', 'adventure', 'outdoor'],
                    'avoid_keywords': ['traditional', 'classic', 'routine']
                },
                'educational': {
                    'boost_keywords': ['learn', 'workshop', 'lecture', 'educational', 'cultural'],
                    'boost_categories': ['arts', 'miscellaneous']
                },
                'creative': {
                    'boost_keywords': ['creative', 'artistic', 'hands-on', 'workshop', 'exhibition'],
                    'boost_categories': ['arts']
                }
            },
            'lifestyle': {
                'active': {
                    'boost_categories': ['sports', 'outdoor'],
                    'boost_keywords': ['fitness', 'active', 'outdoor', 'physical']
                },
                'cultural': {
                    'boost_categories': ['arts', 'music'],
                    'boost_keywords': ['cultural', 'artistic', 'performance', 'exhibition']
                },
                'social': {
                    'boost_keywords': ['social', 'networking', 'community', 'group']
                }
            }
        }

========================================
# File: /home/jarvis/Downloads/WhatNowAI_test/services/user_profiling_service.py
========================================

"""
Enhanced User Profiling Service

This service creates comprehensive user profiles by analyzing multiple data sources
and extracting detailed interests, preferences, and behavioral patterns to improve
event recommendations and personalization.
"""

import logging
import re
import json
from typing import Dict, List, Any, Optional, Set
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from collections import Counter
import asyncio
from concurrent.futures import ThreadPoolExecutor

logger = logging.getLogger(__name__)


@dataclass
class UserInterest:
    """Detailed user interest with confidence metrics"""
    category: str
    keywords: List[str]
    confidence: float
    source: str
    evidence: str
    frequency: int = 1
    context: str = ""
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'category': self.category,
            'keywords': self.keywords,
            'confidence': self.confidence,
            'source': self.source,
            'evidence': self.evidence,
            'frequency': self.frequency,
            'context': self.context
        }


@dataclass
class UserProfile:
    """Comprehensive user profile with behavioral insights"""
    name: str
    location: Dict[str, Any]
    activity: str
    social_data: Dict[str, str] = field(default_factory=dict)
    
    # Enhanced profile data
    interests: List[UserInterest] = field(default_factory=list)
    preferences: Dict[str, Any] = field(default_factory=dict)
    behavioral_patterns: Dict[str, Any] = field(default_factory=dict)
    demographic_hints: Dict[str, Any] = field(default_factory=dict)
    activity_context: Dict[str, Any] = field(default_factory=dict)
    
    # Metadata
    profile_completion: float = 0.0
    last_updated: datetime = field(default_factory=datetime.now)
    
    def add_interest(self, interest: UserInterest):
        """Add interest with deduplication and scoring"""
        for existing in self.interests:
            if existing.category == interest.category and existing.source == interest.source:
                # Merge and update
                existing.keywords.extend(interest.keywords)
                existing.keywords = list(set(existing.keywords))
                existing.confidence = max(existing.confidence, interest.confidence)
                existing.frequency += 1
                return
        self.interests.append(interest)
    
    def get_top_interests(self, n: int = 10) -> List[UserInterest]:
        """Get top N interests by confidence and frequency"""
        return sorted(
            self.interests, 
            key=lambda x: (x.confidence * x.frequency), 
            reverse=True
        )[:n]
    
    def calculate_completion(self):
        """Calculate profile completion percentage"""
        score = 0.0
        
        # Basic info (20%)
        if self.name: score += 5
        if self.location.get('city'): score += 5
        if self.activity: score += 10
        
        # Social data (20%)
        social_count = len([v for v in self.social_data.values() if v])
        score += min(social_count * 3, 20)
        
        # Interests (30%)
        interest_score = min(len(self.interests) * 3, 30)
        score += interest_score
        
        # Preferences (15%)
        if self.preferences: score += 15
        
        # Behavioral patterns (15%)
        if self.behavioral_patterns: score += 15
        
        self.profile_completion = min(score, 100.0)
        return self.profile_completion


class AdvancedInterestExtractor:
    """Advanced interest extraction with NLP and context analysis"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        self.interest_taxonomy = self._load_interest_taxonomy()
        self.contextual_patterns = self._load_contextual_patterns()
        self.sentiment_indicators = self._load_sentiment_indicators()
    
    def _load_interest_taxonomy(self) -> Dict[str, Dict[str, Any]]:
        """Load comprehensive interest taxonomy with hierarchical categories"""
        return {
            'music': {
                'keywords': [
                    'music', 'concert', 'festival', 'band', 'artist', 'album', 'song',
                    'guitar', 'piano', 'drums', 'violin', 'jazz', 'rock', 'pop', 'classical',
                    'hip-hop', 'rap', 'electronic', 'edm', 'country', 'blues', 'reggae',
                    'spotify', 'soundcloud', 'vinyl', 'live music', 'symphony', 'opera'
                ],
                'subcategories': ['instruments', 'genres', 'venues', 'streaming', 'recording'],
                'indicators': ['plays', 'listens', 'performs', 'composes', 'produces'],
                'venues': ['concert hall', 'club', 'stadium', 'amphitheater', 'bar'],
                'sentiment_boost': ['love', 'passion', 'obsessed', 'favorite', 'amazing']
            },
            'sports': {
                'keywords': [
                    'sports', 'football', 'basketball', 'baseball', 'soccer', 'tennis',
                    'golf', 'hockey', 'swimming', 'running', 'cycling', 'fitness', 'gym',
                    'marathon', 'triathlon', 'yoga', 'pilates', 'crossfit', 'weightlifting',
                    'volleyball', 'softball', 'wrestling', 'boxing', 'mma', 'skiing'
                ],
                'subcategories': ['team_sports', 'individual_sports', 'fitness', 'outdoor'],
                'indicators': ['plays', 'trains', 'competes', 'coaches', 'watches'],
                'venues': ['stadium', 'gym', 'court', 'field', 'track', 'pool'],
                'sentiment_boost': ['competitive', 'athletic', 'active', 'champion']
            },
            'arts': {
                'keywords': [
                    'art', 'painting', 'drawing', 'sculpture', 'photography', 'gallery',
                    'museum', 'exhibition', 'artist', 'creative', 'design', 'theater',
                    'drama', 'acting', 'dance', 'ballet', 'contemporary', 'crafts',
                    'pottery', 'jewelry', 'fashion', 'illustration', 'digital art'
                ],
                'subcategories': ['visual_arts', 'performing_arts', 'crafts', 'design'],
                'indicators': ['creates', 'exhibits', 'performs', 'designs', 'collects'],
                'venues': ['gallery', 'museum', 'theater', 'studio', 'workshop'],
                'sentiment_boost': ['creative', 'artistic', 'expressive', 'inspiring']
            },
            'technology': {
                'keywords': [
                    'technology', 'programming', 'coding', 'software', 'developer',
                    'engineer', 'computer', 'ai', 'machine learning', 'data science',
                    'startup', 'app', 'website', 'github', 'python', 'javascript',
                    'blockchain', 'crypto', 'iot', 'robotics', 'vr', 'ar', 'gaming'
                ],
                'subcategories': ['programming', 'ai_ml', 'hardware', 'gaming', 'crypto'],
                'indicators': ['develops', 'codes', 'builds', 'programs', 'hacks'],
                'venues': ['hackathon', 'conference', 'meetup', 'coworking', 'lab'],
                'sentiment_boost': ['innovative', 'cutting-edge', 'passionate', 'expert']
            },
            'food': {
                'keywords': [
                    'food', 'cooking', 'baking', 'cuisine', 'restaurant', 'chef',
                    'recipe', 'culinary', 'dining', 'foodie', 'wine', 'beer', 'coffee',
                    'tea', 'organic', 'vegan', 'vegetarian', 'nutrition', 'gourmet',
                    'street food', 'fine dining', 'barbecue', 'dessert', 'cocktails'
                ],
                'subcategories': ['cooking', 'dining', 'beverages', 'nutrition', 'culture'],
                'indicators': ['cooks', 'bakes', 'tastes', 'reviews', 'explores'],
                'venues': ['restaurant', 'kitchen', 'market', 'festival', 'tasting'],
                'sentiment_boost': ['delicious', 'gourmet', 'passionate', 'expert']
            },
            'travel': {
                'keywords': [
                    'travel', 'tourism', 'vacation', 'trip', 'adventure', 'backpacking',
                    'hotel', 'flight', 'destination', 'explore', 'culture', 'sightseeing',
                    'beach', 'mountain', 'city', 'country', 'international', 'domestic',
                    'cruise', 'road trip', 'camping', 'hiking', 'photography'
                ],
                'subcategories': ['destinations', 'activities', 'accommodation', 'transport'],
                'indicators': ['visits', 'explores', 'travels', 'photographs', 'blogs'],
                'venues': ['destinations', 'hotels', 'airports', 'attractions', 'tours'],
                'sentiment_boost': ['wanderlust', 'adventure', 'explorer', 'globe-trotter']
            },
            'nature': {
                'keywords': [
                    'nature', 'outdoor', 'hiking', 'camping', 'wildlife', 'conservation',
                    'environment', 'ecology', 'sustainability', 'gardening', 'plants',
                    'animals', 'birds', 'forest', 'mountains', 'ocean', 'rivers',
                    'national parks', 'trails', 'fishing', 'hunting', 'photography'
                ],
                'subcategories': ['outdoor_activities', 'wildlife', 'conservation', 'gardening'],
                'indicators': ['hikes', 'camps', 'explores', 'photographs', 'conserves'],
                'venues': ['parks', 'trails', 'forests', 'lakes', 'mountains'],
                'sentiment_boost': ['eco-friendly', 'naturalist', 'outdoorsy', 'green']
            }
        }
    
    def _load_contextual_patterns(self) -> Dict[str, List[str]]:
        """Load patterns that indicate depth of interest"""
        return {
            'high_engagement': [
                'passionate about', 'obsessed with', 'love', 'dedicated to',
                'professional', 'expert', 'years of experience', 'certified',
                'compete', 'perform', 'teach', 'mentor', 'lead'
            ],
            'medium_engagement': [
                'enjoy', 'like', 'interested in', 'hobby', 'amateur',
                'learning', 'practicing', 'member', 'participant'
            ],
            'low_engagement': [
                'sometimes', 'occasionally', 'beginner', 'trying',
                'curious about', 'thinking about', 'might'
            ],
            'frequency_indicators': [
                'daily', 'weekly', 'monthly', 'regularly', 'often',
                'frequently', 'always', 'constantly', 'every day'
            ]
        }
    
    def _load_sentiment_indicators(self) -> Dict[str, float]:
        """Load sentiment indicators and their weights"""
        return {
            'love': 0.9, 'passion': 0.9, 'obsessed': 0.8, 'amazing': 0.7,
            'fantastic': 0.7, 'excellent': 0.6, 'great': 0.5, 'good': 0.4,
            'like': 0.3, 'okay': 0.2, 'hate': -0.8, 'terrible': -0.7,
            'awful': -0.6, 'bad': -0.5, 'dislike': -0.4
        }
    
    def extract_interests(self, text: str, source: str, context: str = "") -> List[UserInterest]:
        """Extract interests from text with advanced NLP analysis"""
        if not text:
            return []
        
        text_lower = text.lower()
        interests = []
        
        for category, category_data in self.interest_taxonomy.items():
            # Find keyword matches
            keyword_matches = self._find_keyword_matches(text_lower, category_data['keywords'])
            
            if keyword_matches:
                # Calculate confidence based on multiple factors
                confidence = self._calculate_confidence(
                    text_lower, keyword_matches, category_data
                )
                
                # Extract evidence and context
                evidence = self._extract_evidence(text, keyword_matches)
                interest_context = self._extract_context(text, keyword_matches)
                
                if confidence > 0.2:  # Minimum confidence threshold
                    interest = UserInterest(
                        category=category,
                        keywords=keyword_matches,
                        confidence=confidence,
                        source=source,
                        evidence=evidence,
                        context=f"{context} | {interest_context}".strip(" | ")
                    )
                    interests.append(interest)
        
        return interests
    
    def _find_keyword_matches(self, text: str, keywords: List[str]) -> List[str]:
        """Find keyword matches in text"""
        matches = []
        for keyword in keywords:
            if keyword in text:
                matches.append(keyword)
        return matches
    
    def _calculate_confidence(self, text: str, matches: List[str], category_data: Dict) -> float:
        """Calculate confidence score for interest category"""
        base_confidence = len(matches) / len(category_data['keywords'])
        
        # Boost for engagement indicators
        engagement_boost = 0.0
        for level, patterns in self.contextual_patterns.items():
            for pattern in patterns:
                if pattern in text:
                    if level == 'high_engagement':
                        engagement_boost += 0.3
                    elif level == 'medium_engagement':
                        engagement_boost += 0.2
                    elif level == 'frequency_indicators':
                        engagement_boost += 0.15
        
        # Boost for sentiment
        sentiment_boost = 0.0
        for sentiment, weight in self.sentiment_indicators.items():
            if sentiment in text:
                sentiment_boost += weight * 0.1
        
        # Boost for venue/activity mentions
        venue_boost = 0.0
        for venue in category_data.get('venues', []):
            if venue in text:
                venue_boost += 0.1
        
        # Boost for action indicators
        action_boost = 0.0
        for indicator in category_data.get('indicators', []):
            if indicator in text:
                action_boost += 0.1
        
        total_confidence = min(
            base_confidence + engagement_boost + sentiment_boost + venue_boost + action_boost,
            1.0
        )
        
        return total_confidence
    
    def _extract_evidence(self, text: str, matches: List[str]) -> str:
        """Extract evidence sentences containing keyword matches"""
        sentences = re.split(r'[.!?]+', text)
        evidence_sentences = []
        
        for sentence in sentences:
            if any(match in sentence.lower() for match in matches):
                evidence_sentences.append(sentence.strip())
        
        return ' '.join(evidence_sentences[:2])  # Top 2 evidence sentences
    
    def _extract_context(self, text: str, matches: List[str]) -> str:
        """Extract contextual information about the interest"""
        text_lower = text.lower()
        context_parts = []
        
        # Look for time indicators
        time_patterns = ['since', 'for', 'years', 'months', 'recently', 'started']
        for pattern in time_patterns:
            if pattern in text_lower:
                context_parts.append(f"temporal:{pattern}")
        
        # Look for skill level indicators
        skill_patterns = ['beginner', 'intermediate', 'advanced', 'professional', 'expert']
        for pattern in skill_patterns:
            if pattern in text_lower:
                context_parts.append(f"skill:{pattern}")
        
        return ', '.join(context_parts)


class BehavioralAnalyzer:
    """Analyze user behavior patterns from text and social data"""
    
    def __init__(self):
        self.behavior_patterns = self._load_behavior_patterns()
    
    def _load_behavior_patterns(self) -> Dict[str, List[str]]:
        """Load behavioral pattern indicators"""
        return {
            'social_learner': [
                'group', 'class', 'workshop', 'meetup', 'club', 'team',
                'community', 'together', 'friends', 'social'
            ],
            'solo_activities': [
                'alone', 'individual', 'personal', 'solo', 'private',
                'meditation', 'reading', 'writing', 'reflection'
            ],
            'adventure_seeker': [
                'adventure', 'extreme', 'adrenaline', 'challenge', 'risk',
                'new', 'explore', 'discover', 'unknown', 'exciting'
            ],
            'comfort_zone': [
                'familiar', 'routine', 'regular', 'same', 'usual',
                'comfortable', 'safe', 'known', 'predictable'
            ],
            'creative_expression': [
                'create', 'make', 'build', 'design', 'artistic',
                'original', 'unique', 'innovative', 'express'
            ],
            'learning_oriented': [
                'learn', 'study', 'education', 'knowledge', 'skill',
                'improve', 'develop', 'grow', 'understand', 'research'
            ],
            'health_conscious': [
                'healthy', 'wellness', 'fitness', 'nutrition', 'organic',
                'exercise', 'mindful', 'balance', 'wellbeing'
            ],
            'time_preferences': {
                'morning': ['morning', 'early', 'dawn', 'sunrise', 'am'],
                'evening': ['evening', 'night', 'sunset', 'pm', 'late'],
                'weekend': ['weekend', 'saturday', 'sunday', 'days off'],
                'weekday': ['weekday', 'workday', 'monday', 'friday']
            }
        }
    
    def analyze_behavior(self, text: str, social_data: Dict[str, str]) -> Dict[str, Any]:
        """Analyze behavioral patterns from user data"""
        text_lower = text.lower() if text else ""
        patterns = {}
        
        # Analyze text for behavioral indicators
        for pattern_type, keywords in self.behavior_patterns.items():
            if pattern_type == 'time_preferences':
                patterns[pattern_type] = {}
                for time_type, time_keywords in keywords.items():
                    score = sum(1 for keyword in time_keywords if keyword in text_lower)
                    patterns[pattern_type][time_type] = score / len(time_keywords)
            else:
                score = sum(1 for keyword in keywords if keyword in text_lower)
                patterns[pattern_type] = score / len(keywords)
        
        # Analyze social data for platform preferences
        platform_activity = {}
        for platform, handle in social_data.items():
            if handle:
                platform_activity[platform] = self._infer_platform_behavior(platform)
        
        patterns['platform_preferences'] = platform_activity
        
        return patterns
    
    def _infer_platform_behavior(self, platform: str) -> Dict[str, str]:
        """Infer behavioral traits from social platform usage"""
        platform_traits = {
            'twitter': {'communication': 'concise', 'engagement': 'public', 'content': 'news_opinion'},
            'instagram': {'communication': 'visual', 'engagement': 'aesthetic', 'content': 'lifestyle'},
            'linkedin': {'communication': 'professional', 'engagement': 'networking', 'content': 'career'},
            'github': {'communication': 'technical', 'engagement': 'collaborative', 'content': 'development'},
            'tiktok': {'communication': 'creative', 'engagement': 'viral', 'content': 'entertainment'},
            'youtube': {'communication': 'educational', 'engagement': 'educational', 'content': 'learning'}
        }
        return platform_traits.get(platform, {'communication': 'social', 'engagement': 'casual'})


class EnhancedUserProfilingService:
    """Main service for enhanced user profiling"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        self.interest_extractor = AdvancedInterestExtractor(config)
        self.behavior_analyzer = BehavioralAnalyzer()
        self.executor = ThreadPoolExecutor(max_workers=4)
    
    def create_enhanced_profile(
        self, 
        name: str, 
        location: Dict[str, Any], 
        activity: str,
        social_data: Dict[str, str] = None,
        search_results: Dict[str, Any] = None
    ) -> UserProfile:
        """Create comprehensive user profile with advanced analysis"""
        
        logger.info(f"Creating enhanced profile for {name}")
        
        profile = UserProfile(
            name=name,
            location=location,
            activity=activity,
            social_data=social_data or {}
        )
        
        # Extract interests from activity description
        if activity:
            activity_interests = self.interest_extractor.extract_interests(
                activity, 'user_input', 'primary_activity'
            )
            for interest in activity_interests:
                profile.add_interest(interest)
        
        # Extract interests from search results if available
        if search_results:
            self._process_search_results(profile, search_results)
        
        # Analyze behavioral patterns
        all_text = f"{activity} {' '.join(social_data.values() if social_data else [])}"
        profile.behavioral_patterns = self.behavior_analyzer.analyze_behavior(
            all_text, social_data or {}
        )
        
        # Infer demographic hints
        profile.demographic_hints = self._infer_demographics(profile)
        
        # Analyze activity context
        profile.activity_context = self._analyze_activity_context(activity)
        
        # Set preferences based on analysis
        profile.preferences = self._generate_preferences(profile)
        
        # Calculate profile completion
        profile.calculate_completion()
        
        logger.info(f"Enhanced profile created with {len(profile.interests)} interests "
                   f"and {profile.profile_completion:.1f}% completion")
        
        return profile
    
    def _process_search_results(self, profile: UserProfile, search_results: Dict[str, Any]):
        """Process search results to extract additional interests and context"""
        
        # Process search summaries
        summaries = search_results.get('search_summaries', {})
        for source, summary in summaries.items():
            if summary and isinstance(summary, str):
                interests = self.interest_extractor.extract_interests(
                    summary, f'search_{source}', source
                )
                for interest in interests:
                    profile.add_interest(interest)
        
        # Process raw search results if available
        raw_results = search_results.get('search_results', {})
        for source, results in raw_results.items():
            if isinstance(results, list):
                for result in results[:3]:  # Process top 3 results per source
                    if isinstance(result, dict):
                        content = result.get('content', '')
                        if content:
                            interests = self.interest_extractor.extract_interests(
                                content, f'search_{source}', 'web_content'
                            )
                            for interest in interests:
                                profile.add_interest(interest)
    
    def _infer_demographics(self, profile: UserProfile) -> Dict[str, Any]:
        """Infer demographic hints from profile data"""
        demographics = {}
        
        # Age group inference from interests and language
        young_adult_indicators = ['college', 'university', 'student', 'party', 'club', 'gaming']
        middle_age_indicators = ['family', 'career', 'professional', 'mortgage', 'kids']
        senior_indicators = ['retirement', 'grandchildren', 'volunteer', 'garden']
        
        all_text = f"{profile.activity} {' '.join([i.evidence for i in profile.interests])}"
        text_lower = all_text.lower()
        
        young_score = sum(1 for indicator in young_adult_indicators if indicator in text_lower)
        middle_score = sum(1 for indicator in middle_age_indicators if indicator in text_lower)
        senior_score = sum(1 for indicator in senior_indicators if indicator in text_lower)
        
        if young_score > middle_score and young_score > senior_score:
            demographics['age_group_hint'] = 'young_adult'
        elif middle_score > senior_score:
            demographics['age_group_hint'] = 'middle_age'
        elif senior_score > 0:
            demographics['age_group_hint'] = 'senior'
        
        # Lifestyle inference
        if any(cat in ['fitness', 'sports', 'nature'] for cat in [i.category for i in profile.interests]):
            demographics['lifestyle_hint'] = 'active'
        elif any(cat in ['arts', 'music', 'technology'] for cat in [i.category for i in profile.interests]):
            demographics['lifestyle_hint'] = 'creative'
        elif any(cat in ['food', 'travel', 'culture'] for cat in [i.category for i in profile.interests]):
            demographics['lifestyle_hint'] = 'experiential'
        
        return demographics
    
    def _analyze_activity_context(self, activity: str) -> Dict[str, Any]:
        """Analyze the context and intent behind user's activity request"""
        if not activity:
            return {}
        
        activity_lower = activity.lower()
        context = {}
        
        # Intent analysis
        if any(word in activity_lower for word in ['want', 'need', 'looking for', 'search']):
            context['intent'] = 'seeking'
        elif any(word in activity_lower for word in ['love', 'enjoy', 'passion']):
            context['intent'] = 'pursuing_interest'
        elif any(word in activity_lower for word in ['learn', 'try', 'new']):
            context['intent'] = 'exploring'
        
        # Urgency analysis
        if any(word in activity_lower for word in ['tonight', 'today', 'now', 'immediate']):
            context['urgency'] = 'high'
        elif any(word in activity_lower for word in ['weekend', 'soon', 'this week']):
            context['urgency'] = 'medium'
        else:
            context['urgency'] = 'low'
        
        # Social context
        if any(word in activity_lower for word in ['with friends', 'group', 'family', 'date']):
            context['social_setting'] = 'group'
        elif any(word in activity_lower for word in ['alone', 'solo', 'myself']):
            context['social_setting'] = 'solo'
        else:
            context['social_setting'] = 'flexible'
        
        # Budget hints
        if any(word in activity_lower for word in ['free', 'cheap', 'budget', 'affordable']):
            context['budget_preference'] = 'low'
        elif any(word in activity_lower for word in ['premium', 'high-end', 'luxury', 'expensive']):
            context['budget_preference'] = 'high'
        else:
            context['budget_preference'] = 'medium'
        
        return context
    
    def _generate_preferences(self, profile: UserProfile) -> Dict[str, Any]:
        """Generate user preferences based on profile analysis"""
        preferences = {}
        
        # Event type preferences based on interests
        top_interests = profile.get_top_interests(5)
        preferences['preferred_categories'] = [i.category for i in top_interests]
        
        # Time preferences from behavioral patterns
        time_prefs = profile.behavioral_patterns.get('time_preferences', {})
        if time_prefs:
            preferred_time = max(time_prefs, key=time_prefs.get)
            preferences['preferred_time'] = preferred_time
        
        # Social preferences
        if profile.behavioral_patterns.get('social_learner', 0) > 0.3:
            preferences['social_preference'] = 'group'
        elif profile.behavioral_patterns.get('solo_activities', 0) > 0.3:
            preferences['social_preference'] = 'solo'
        else:
            preferences['social_preference'] = 'flexible'
        
        # Activity style preferences
        if profile.behavioral_patterns.get('adventure_seeker', 0) > 0.3:
            preferences['activity_style'] = 'adventurous'
        elif profile.behavioral_patterns.get('learning_oriented', 0) > 0.3:
            preferences['activity_style'] = 'educational'
        elif profile.behavioral_patterns.get('creative_expression', 0) > 0.3:
            preferences['activity_style'] = 'creative'
        else:
            preferences['activity_style'] = 'balanced'
        
        # Budget preference from activity context
        budget_pref = profile.activity_context.get('budget_preference', 'medium')
        preferences['budget_preference'] = budget_pref
        
        return preferences
    
    def get_recommendation_context(self, profile: UserProfile) -> Dict[str, Any]:
        """Generate context for event recommendations"""
        return {
            'user_profile': {
                'name': profile.name,
                'location': profile.location,
                'primary_activity': profile.activity,
                'completion_score': profile.profile_completion
            },
            'interests': [i.to_dict() for i in profile.get_top_interests(10)],
            'preferences': profile.preferences,
            'behavioral_patterns': profile.behavioral_patterns,
            'activity_context': profile.activity_context,
            'demographic_hints': profile.demographic_hints
        }

========================================
# File: /home/jarvis/Downloads/WhatNowAI_test/services/mapping_service.py
========================================

"""
Mapping service for interactive event visualization

This module manages map markers, event categorization, and geographical data
for the interactive map interface. Supports filtering, searching, and real-time
event display with category-based organization and statistics.
"""

import logging
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
import json

logger = logging.getLogger(__name__)


@dataclass
class MapMarker:
    """Map marker data structure"""
    id: str
    name: str
    latitude: float
    longitude: float
    category: str
    subcategory: str = ""
    description: str = ""
    url: str = ""
    date: str = ""
    time: str = ""
    venue: str = ""
    address: str = ""
    price_min: Optional[float] = None
    price_max: Optional[float] = None
    image_url: str = ""
    source: str = "unknown"  # ticketmaster, eventbrite, etc.
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert marker to dictionary for JSON serialization"""
        return {
            'id': self.id,
            'name': self.name,
            'latitude': self.latitude,
            'longitude': self.longitude,
            'category': self.category,
            'subcategory': self.subcategory,
            'description': self.description,
            'url': self.url,
            'date': self.date,
            'time': self.time,
            'venue': self.venue,
            'address': self.address,
            'price_min': self.price_min,
            'price_max': self.price_max,
            'image_url': self.image_url,
            'source': self.source
        }


class MappingService:
    """Service for aggregating events from multiple APIs and displaying on a map"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize mapping service
        
        Args:
            config: Configuration dictionary
        """
        self.config = config
        self.markers = []
        
    def clear_markers(self):
        """Clear all markers"""
        self.markers = []
    
    def add_ticketmaster_events(self, events: List[Any]):
        """Add events from Ticketmaster to the map"""
        for event in events:
            marker = MapMarker(
                id=f"tm_{event.id}",
                name=event.name,
                latitude=event.latitude,
                longitude=event.longitude,
                category=event.category,
                subcategory=event.subcategory,
                description=event.description,
                url=event.url,
                date=event.date,
                time=event.time,
                venue=event.venue,
                address=event.address,
                price_min=event.price_min,
                price_max=event.price_max,
                image_url=event.image_url,
                source="ticketmaster"
            )
            self.markers.append(marker)
    
    def add_allevents_events(self, events: List[Any]):
        """Add events from AllEvents to the map"""
        for event in events:
            marker = MapMarker(
                id=f"ae_{event.id}",
                name=event.name,
                latitude=event.latitude,
                longitude=event.longitude,
                category=event.category,
                subcategory=event.subcategory,
                description=event.description,
                url=event.url,
                date=event.date,
                time=event.time,
                venue=event.venue,
                address=event.address,
                price_min=event.price_min,
                price_max=event.price_max,
                image_url=event.image_url,
                source="allevents"
            )
            self.markers.append(marker)

    def add_eventbrite_events(self, events: List[Dict[str, Any]]):
        """Add events from Eventbrite to the map (placeholder for future integration)"""
        for event in events:
            try:
                marker = MapMarker(
                    id=f"eb_{event.get('id', '')}",
                    name=event.get('name', {}).get('text', 'Unknown Event'),
                    latitude=float(event.get('venue', {}).get('latitude', 0)),
                    longitude=float(event.get('venue', {}).get('longitude', 0)),
                    category=event.get('category', 'miscellaneous'),
                    description=event.get('description', {}).get('text', ''),
                    url=event.get('url', ''),
                    date=event.get('start', {}).get('local', '').split('T')[0],
                    time=event.get('start', {}).get('local', '').split('T')[1] if 'T' in event.get('start', {}).get('local', '') else '',
                    venue=event.get('venue', {}).get('name', ''),
                    address=event.get('venue', {}).get('address', {}).get('localized_address_display', ''),
                    source="eventbrite"
                )
                
                if marker.latitude and marker.longitude:
                    self.markers.append(marker)
                    
            except Exception as e:
                logger.warning(f"Failed to parse Eventbrite event: {e}")
                continue
    
    def add_meetup_events(self, events: List[Dict[str, Any]]):
        """Add events from Meetup to the map (placeholder for future integration)"""
        for event in events:
            try:
                venue = event.get('venue', {})
                marker = MapMarker(
                    id=f"mu_{event.get('id', '')}",
                    name=event.get('name', 'Unknown Event'),
                    latitude=float(venue.get('lat', 0)),
                    longitude=float(venue.get('lon', 0)),
                    category='meetup',
                    description=event.get('description', ''),
                    url=event.get('link', ''),
                    date=event.get('local_date', ''),
                    time=event.get('local_time', ''),
                    venue=venue.get('name', ''),
                    address=venue.get('address_1', ''),
                    source="meetup"
                )
                
                if marker.latitude and marker.longitude:
                    self.markers.append(marker)
                    
            except Exception as e:
                logger.warning(f"Failed to parse Meetup event: {e}")
                continue
    
    def add_custom_locations(self, locations: List[Dict[str, Any]]):
        """Add custom locations to the map"""
        for location in locations:
            try:
                marker = MapMarker(
                    id=f"custom_{location.get('id', len(self.markers))}",
                    name=location.get('name', 'Custom Location'),
                    latitude=float(location.get('latitude', 0)),
                    longitude=float(location.get('longitude', 0)),
                    category=location.get('category', 'custom'),
                    description=location.get('description', ''),
                    url=location.get('url', ''),
                    address=location.get('address', ''),
                    source="custom"
                )
                
                if marker.latitude and marker.longitude:
                    self.markers.append(marker)
                    
            except Exception as e:
                logger.warning(f"Failed to parse custom location: {e}")
                continue
    
    def get_markers_by_category(self, category: str) -> List[MapMarker]:
        """Get all markers for a specific category"""
        return [marker for marker in self.markers if marker.category.lower() == category.lower()]
    
    def get_markers_by_source(self, source: str) -> List[MapMarker]:
        """Get all markers from a specific source"""
        return [marker for marker in self.markers if marker.source.lower() == source.lower()]
    
    def get_all_markers(self) -> List[MapMarker]:
        """Get all markers"""
        return self.markers
    
    def get_map_data(self, center_lat: float, center_lng: float) -> Dict[str, Any]:
        """
        Get map data for frontend display
        
        Args:
            center_lat: Center latitude for the map
            center_lng: Center longitude for the map
            
        Returns:
            Dictionary containing map configuration and markers
        """
        # Limit markers for performance
        max_markers = self.config.get('MAX_MARKERS', 50)
        limited_markers = self.markers[:max_markers]
        
        # Group markers by category for better organization
        categories = {}
        for marker in limited_markers:
            category = marker.category
            if category not in categories:
                categories[category] = []
            categories[category].append(marker.to_dict())
        
        return {
            'center': {
                'latitude': center_lat,
                'longitude': center_lng
            },
            'zoom': self.config.get('DEFAULT_ZOOM', 12),
            'markers': [marker.to_dict() for marker in limited_markers],
            'categories': categories,
            'total_markers': len(self.markers),
            'sources': list(set(marker.source for marker in self.markers)),
            'tile_server': self.config.get('TILE_SERVER', 'https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png'),
            'attribution': self.config.get('ATTRIBUTION', '&copy; OpenStreetMap contributors')
        }
    
    def get_category_stats(self) -> Dict[str, int]:
        """Get statistics about markers by category"""
        stats = {}
        for marker in self.markers:
            category = marker.category
            stats[category] = stats.get(category, 0) + 1
        return stats
    
    def filter_markers_by_distance(self, center_lat: float, center_lng: float, 
                                 max_distance_km: float) -> List[MapMarker]:
        """
        Filter markers by distance from a center point
        
        Args:
            center_lat: Center latitude
            center_lng: Center longitude
            max_distance_km: Maximum distance in kilometers
            
        Returns:
            List of markers within the specified distance
        """
        import math
        
        def haversine_distance(lat1, lon1, lat2, lon2):
            """Calculate the haversine distance between two points"""
            R = 6371  # Earth's radius in kilometers
            
            lat1_rad = math.radians(lat1)
            lon1_rad = math.radians(lon1)
            lat2_rad = math.radians(lat2)
            lon2_rad = math.radians(lon2)
            
            dlat = lat2_rad - lat1_rad
            dlon = lon2_rad - lon1_rad
            
            a = math.sin(dlat/2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon/2)**2
            c = 2 * math.asin(math.sqrt(a))
            
            return R * c
        
        filtered_markers = []
        for marker in self.markers:
            distance = haversine_distance(
                center_lat, center_lng,
                marker.latitude, marker.longitude
            )
            if distance <= max_distance_km:
                filtered_markers.append(marker)
        
        return filtered_markers
    
    def search_markers(self, query: str) -> List[MapMarker]:
        """
        Search markers by name, description, or venue
        
        Args:
            query: Search query string
            
        Returns:
            List of matching markers
        """
        query_lower = query.lower()
        matching_markers = []
        
        for marker in self.markers:
            if (query_lower in marker.name.lower() or
                query_lower in marker.description.lower() or
                query_lower in marker.venue.lower() or
                query_lower in marker.category.lower()):
                matching_markers.append(marker)
        
        return matching_markers

========================================
# File: /home/jarvis/Downloads/WhatNowAI_test/services/__init__.py
========================================

# Services package

========================================
# File: /home/jarvis/Downloads/WhatNowAI_test/services/tts_service.py
========================================

"""
Text-to-Speech service using Microsoft Edge TTS

This module provides text-to-speech functionality for the WhatNowAI application,
including dynamic text generation for onboarding steps and audio file management.
"""
import asyncio
import edge_tts
import os
import uuid
from typing import Optional, Tuple, Dict
import logging
from datetime import datetime

logger = logging.getLogger(__name__)


class TTSService:
    """Text-to-Speech service for generating audio from text"""
    
    def __init__(self, audio_dir: str, voice: str = "en-US-JennyNeural"):
        """
        Initialize TTS service
        
        Args:
            audio_dir: Directory to save audio files
            voice: Voice to use for TTS
        """
        self.audio_dir = audio_dir
        self.voice = voice
        self._ensure_audio_dir()
    
    def _ensure_audio_dir(self) -> None:
        """Ensure audio directory exists"""
        os.makedirs(self.audio_dir, exist_ok=True)
    
    async def generate_audio(self, text: str, voice: Optional[str] = None) -> Tuple[Optional[str], Optional[str]]:
        """
        Generate audio from text using edge-tts
        
        Args:
            text: Text to convert to speech
            voice: Voice to use (optional, uses default if not provided)
            
        Returns:
            Tuple of (audio_id, audio_path) or (None, None) if failed
        """
        try:
            if not text.strip():
                logger.warning("Empty text provided for TTS generation")
                return None, None
            
            # Create unique filename
            audio_id = str(uuid.uuid4())
            audio_path = os.path.join(self.audio_dir, f"{audio_id}.mp3")
            
            # Use provided voice or default
            selected_voice = voice or self.voice
            
            # Generate speech
            communicate = edge_tts.Communicate(text, selected_voice)
            await communicate.save(audio_path)
            
            logger.info(f"Audio generated successfully: {audio_id}")
            return audio_id, audio_path
            
        except Exception as e:
            logger.error(f"TTS Error: {e}")
            return None, None
    
    def generate_audio_sync(self, text: str, voice: Optional[str] = None) -> Tuple[Optional[str], Optional[str]]:
        """
        Synchronous wrapper for TTS generation
        
        Args:
            text: Text to convert to speech
            voice: Voice to use (optional)
            
        Returns:
            Tuple of (audio_id, audio_path) or (None, None) if failed
        """
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            return loop.run_until_complete(self.generate_audio(text, voice))
        except Exception as e:
            logger.error(f"TTS Sync Error: {e}")
            return None, None
        finally:
            loop.close()
    
    def get_audio_path(self, audio_id: str) -> str:
        """Get full path for audio file"""
        return os.path.join(self.audio_dir, f"{audio_id}.mp3")
    
    def audio_exists(self, audio_id: str) -> bool:
        """Check if audio file exists"""
        return os.path.exists(self.get_audio_path(audio_id))
    
    def cleanup_old_audio(self, max_age_hours: int = 24) -> None:
        """Clean up old audio files"""
        try:
            import time
            current_time = time.time()
            max_age_seconds = max_age_hours * 3600
            
            for filename in os.listdir(self.audio_dir):
                if filename.endswith('.mp3'):
                    file_path = os.path.join(self.audio_dir, filename)
                    file_age = current_time - os.path.getctime(file_path)
                    
                    if file_age > max_age_seconds:
                        try:
                            os.remove(file_path)
                            logger.info(f"Cleaned up old audio file: {filename}")
                        except OSError as e:
                            logger.warning(f"Failed to remove old audio file {filename}: {e}")
                            
        except Exception as e:
            logger.error(f"Error during audio cleanup: {e}")


def get_time_based_greeting() -> str:
    """Get time-appropriate greeting"""
    hour = datetime.now().hour
    
    if 5 <= hour < 12:
        return "Good morning"
    elif 12 <= hour < 17:
        return "Good afternoon"
    elif 17 <= hour < 22:
        return "Good evening"
    else:
        return "Hello"


def get_introduction_text(step: str, location_data: Optional[Dict] = None) -> str:
    """
    Generate dynamic introduction text based on time, location, and step
    
    Args:
        step: The onboarding step
        location_data: Optional location information
        
    Returns:
        Personalized introduction text
    """
    greeting = get_time_based_greeting()
    
    # Extract location info if available
    location_context = ""
    if location_data:
        city = location_data.get('city', '')
        country = location_data.get('country', '')
        if city and country:
            location_context = f" from {city}, {country}"
        elif country:
            location_context = f" from {country}"
    
    texts = {
        "step_name": f"Welcome to WhatNow AI! First, I'd love to know your name!",
        
        "step_activity": f"Perfect! Now tell me, what would you like to do today?",
        
        "step_location": f"Great choice! To give you the best local recommendations, I'll need to know where you are.",
        
        "processing": f"Excellent! Now I'm creating your personalized recommendations. This will just take a moment."
    }
    
    return texts.get(step, "Let's continue!")


# Backward compatibility - keep static texts as fallback
INTRODUCTION_TEXTS = {
    "step_name": "First, what's your name? You can also share social media handles for better recommendations.",
    "step_activity": "Perfect! Now tell me, what would you like to do today?",
    "step_location": "Great! To give you local recommendations, I'll need your location. You can share it or skip this step.",
    "processing": "Excellent! I'm creating your personalized action plan. Just a moment please."
}
