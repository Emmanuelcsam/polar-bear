
========================================
# File: C:\Users\Saem1001\Documents\GitHub\ai_detect\net\neural_ide_lite\ai_assist.py
========================================

"""
AI Assist: Simplified AI-powered code analysis and suggestions for Neural Weaver.
This module integrates tools like Pylint and OpenAI to provide actionable,
easy-to-understand feedback on the Python code inside the Blocks.
"""

import subprocess
import os
from openai import OpenAI
import json

# --- Configuration ---
# Store the API key in a more persistent way across sessions.
# This avoids asking the user for the key every time they start the app.
API_KEY_FILE = os.path.join(os.path.expanduser("~"), ".neural_weaver", "openai.key")

def save_api_key(api_key: str):
    """Saves the OpenAI API key to a local file."""
    os.makedirs(os.path.dirname(API_KEY_FILE), exist_ok=True)
    with open(API_KEY_FILE, 'w') as f:
        f.write(api_key)

def load_api_key() -> str | None:
    """Loads the OpenAI API key from a local file."""
    if os.path.exists(API_KEY_FILE):
        with open(API_KEY_FILE, 'r') as f:
            return f.read().strip()
    return None

class BlockAnalyzer:
    """
    Analyzes the code within a block for quality, style, and potential errors.
    This replaces the original 'CodeAnalyzer' with a focus on simplicity.
    """
    def __init__(self, code_content: str):
        """
        Initializes the analyzer with the code to be analyzed.
        It writes the code to a temporary file for tool processing.
        """
        # Create a temporary file to run analysis tools against.
        self.temp_file_path = "temp_block_code.py"
        with open(self.temp_file_path, "w", encoding="utf-8") as f:
            f.write(code_content)

    def analyze(self) -> dict:
        """
        Runs a suite of analysis tools and returns a structured,
        user-friendly summary of the findings.
        """
        print("Running static analysis on block code...")
        results = {
            "score": 10.0,
            "summary": "Excellent! No issues found.",
            "issues": []
        }
        
        try:
            # We use Pylint as it provides a score and detailed feedback.
            process = subprocess.run(
                ["pylint", self.temp_file_path],
                capture_output=True,
                text=True,
                check=False # Don't throw an error on non-zero exit code
            )
            
            pylint_output = process.stdout
            
            # --- Parse Pylint Output ---
            # Find the score
            score_line = [line for line in pylint_output.split('\n') if "Your code has been rated at" in line]
            if score_line:
                score_str = score_line[0].split('/')[0].split('at ')[-1].strip()
                try:
                    results["score"] = float(score_str)
                except ValueError:
                    pass # Keep default score if parsing fails
            
            # Find issues (warnings and errors)
            issues_found = []
            for line in pylint_output.split('\n'):
                if ":" in line and any(c in line for c in "WCREF"):
                    parts = line.split(':')
                    if len(parts) >= 4 and parts[1].strip().isdigit():
                        issue = {
                            "line": int(parts[1].strip()),
                            "type": parts[2].strip(),
                            "message": ":".join(parts[3:]).strip()
                        }
                        issues_found.append(issue)
            
            results["issues"] = issues_found
            
            # Update summary based on score and issues
            if not issues_found:
                 results["summary"] = "Excellent! No issues found."
            else:
                error_count = sum(1 for i in issues_found if i['type'].startswith('E'))
                warning_count = len(issues_found) - error_count
                results["summary"] = f"Found {error_count} error(s) and {warning_count} warning(s)."

        except FileNotFoundError:
            results["summary"] = "Pylint not found. Please install it to enable code analysis."
            results["issues"].append({"line": 0, "type": "Setup Error", "message": "The 'pylint' command was not found in your system's PATH."})
        except Exception as e:
            results["summary"] = f"An unexpected error occurred during analysis."
            results["issues"].append({"line": 0, "type": "System Error", "message": str(e)})
            
        finally:
            # Clean up the temporary file
            if os.path.exists(self.temp_file_path):
                os.remove(self.temp_file_path)
        
        return results

class AISuggestor:
    """
    Provides code suggestions and improvements using OpenAI's models.
    Manages the API key and provides a clean interface for getting suggestions.
    """
    def __init__(self, api_key: str | None = None):
        self.api_key = api_key or load_api_key()
        self.openai_client = None
        if self.api_key:
            try:
                self.openai_client = OpenAI(api_key=self.api_key)
            except Exception as e:
                print(f"Failed to initialize OpenAI client: {e}")

    def is_ready(self) -> bool:
        """Checks if the AI suggestor is configured and ready to use."""
        return self.openai_client is not None

    def get_suggestion(self, code: str, analysis_issues: list) -> str:
        """

        Gets a code improvement suggestion from OpenAI's GPT-4o-mini model.
        The prompt is context-aware, including the code and the issues found.
        """
        if not self.is_ready():
            return "AI Suggestor is not configured. Please provide an OpenAI API key in the settings."

        # Create a summary of the issues for the prompt
        issue_summary = "\n".join([f"- Line {i['line']}: {i['message']} ({i['type']})" for i in analysis_issues])

        prompt = f"""
        You are an expert Python programmer assisting in a visual programming environment.
        A user has written the following code for a 'block'. Please improve it.

        Your task is to:
        1. Fix the specific issues identified below.
        2. Improve the code's readability and efficiency.
        3. Adhere to Python best practices (PEP 8).
        4. Add comments where the logic is complex.
        
        ONLY return the complete, corrected Python code. Do not include any explanations, markdown, or intro/outro text.

        --- START OF CODE ---
        {code}
        --- END OF CODE ---

        --- ISSUES FOUND ---
        {issue_summary if issue_summary else "No specific issues were found, but please review for general improvements."}
        --- END OF ISSUES ---

        Corrected Code:
        """
        
        try:
            print("Sending request to OpenAI for code suggestion...")
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}]
            )
            suggestion = response.choices[0].message.content
            # Clean up the response to ensure it's only code
            if suggestion.strip().startswith("```python"):
                suggestion = suggestion.split("```python\n")[1].split("\n```")[0]
            return suggestion
        
        except Exception as e:
            return f"# AI Error: Could not get a suggestion.\n# Reason: {e}"

# --- Example Usage ---
if __name__ == '__main__':
    # This demonstrates how the new AI Assist module works.
    
    # Example code with some issues
    bad_code = """
import sys
def   MyFunction( name,age):
     print("hello "+name)
     if age>18:
        return True
    else:
         return False
unused_variable = 5
"""
    
    print("--- Testing BlockAnalyzer ---")
    analyzer = BlockAnalyzer(bad_code)
    analysis_result = analyzer.analyze()
    print(json.dumps(analysis_result, indent=2))
    
    print("\n--- Testing AISuggestor ---")
    # To run this part, you need to set your OpenAI API key as an environment variable
    # or be prompted to enter it.
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("Skipping AISuggestor test: OPENAI_API_KEY environment variable not set.")
    else:
        suggester = AISuggestor(api_key=api_key)
        if suggester.is_ready():
            suggestion = suggester.get_suggestion(bad_code, analysis_result['issues'])
            print("\n--- Original Code ---")
            print(bad_code)
            print("\n--- AI Suggested Code ---")
            print(suggestion)
        else:
            print("Could not initialize AI Suggestor.")

========================================
# File: C:\Users\Saem1001\Documents\GitHub\ai_detect\net\neural_ide_lite\auto_healer.py
========================================

"""
Auto Healer: An intelligent tool for automatically diagnosing and fixing
runtime errors in Neural Weaver blocks. This module simplifies the original
'AutoFixer' by focusing on a clear, AI-driven workflow.
"""

import subprocess
import sys
import os
import requests
from bs4 import BeautifulSoup
from openai import OpenAI
from ai_assist import load_api_key # Use the shared API key loader

class AutoHealer:
    """
    Diagnoses and proposes fixes for runtime errors in a Python script.
    It combines runtime analysis, web searching for context, and AI for a solution.
    """
    def __init__(self, file_path: str, api_key: str | None = None):
        """
        Initializes the AutoHealer.

        Args:
            file_path (str): The absolute path to the Python script to be healed.
            api_key (str, optional): OpenAI API key. If not provided, it will be loaded from the shared store.
        """
        self.file_path = file_path
        self.api_key = api_key or load_api_key()
        self.openai_client = OpenAI(api_key=self.api_key) if self.api_key else None

    def is_ready(self) -> bool:
        """Checks if the AutoHealer has the necessary API key to function."""
        return self.openai_client is not None

    def diagnose(self) -> tuple[str | None, str | None]:
        """
        Runs the script in a separate process to capture its output and, more
        importantly, any runtime errors.

        Returns:
            A tuple containing (stdout, stderr). If an error occurs, stderr
            will contain the traceback.
        """
        print(f"Diagnosing script: {self.file_path}")
        try:
            result = subprocess.run(
                [sys.executable, self.file_path],
                capture_output=True,
                text=True,
                check=False, # We want to capture errors, not crash the launcher
                encoding='utf-8'
            )
            return result.stdout, result.stderr
        except FileNotFoundError:
            return None, f"Healing Error: The script was not found at {self.file_path}."
        except Exception as e:
            return None, f"Healing Error: A system-level error occurred while running the script: {e}"

    def research_error(self, error_message: str) -> str:
        """
        Performs a targeted web search for the error message to find context,
        focusing on Stack Overflow for reliable solutions.

        Args:
            error_message (str): The stderr output from the script execution.

        Returns:
            A summary of the most relevant solution found, or a message indicating
            no solution was found.
        """
        if not error_message:
            return "No error message to research."

        # Extract the most relevant line from the error for a cleaner search
        last_line = error_message.strip().split('\n')[-1]
        query = f"site:stackoverflow.com python {last_line}"
        print(f"Researching online for: '{query}'")

        try:
            # Use a common user agent to avoid being blocked
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}
            response = requests.get("https://www.google.com/search", params={'q': query}, headers=headers)
            response.raise_for_status()

            soup = BeautifulSoup(response.text, 'html.parser')
            link_tag = soup.find('a', href=lambda href: href and "stackoverflow.com/questions" in href)

            if not link_tag:
                return "Could not find a relevant Stack Overflow page from the search results."

            url = link_tag['href']
            if url.startswith('/url?q='):
                url = url.split('&')[0].replace('/url?q=', '')

            print(f"Found potential solution at: {url}")
            return self._scrape_solution(url)
        except requests.exceptions.RequestException as e:
            return f"Web search failed. Could not connect to the internet to find a solution. Error: {e}"

    def _scrape_solution(self, url: str) -> str:
        """Scrapes the highest-voted answer from a Stack Overflow page."""
        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            response = requests.get(url, headers=headers)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # --- FIXED LINE ---
            # Correctly search for the accepted answer first, then fall back to the first answer.
            # Using attrs dictionary for attributes with hyphens is the correct syntax.
            answer = soup.find('div', class_='accepted-answer')
            if not answer:
                answer = soup.find('div', class_='answer')

            if answer:
                # Extract the code blocks and text for context
                code_elements = answer.select('.s-prose .js-post-body pre code')
                solution_text = "\n\n".join([code.get_text() for code in code_elements])
                return solution_text if solution_text else "Found a solution page, but could not extract code snippets."
            return "Could not find a clear answer on the Stack Overflow page."
        except requests.exceptions.RequestException as e:
            return f"Failed to access the solution page. Error: {e}"

    def propose_fix(self, original_code: str, error_message: str, research_summary: str) -> str:
        """
        Uses OpenAI's AI to synthesize a fix based on the code, the error, and
        the online research.

        Args:
            original_code (str): The full original code of the script.
            error_message (str): The error captured during diagnosis.
            research_summary (str): The context gathered from web research.

        Returns:
            The AI-generated, fully corrected code.
        """
        if not self.is_ready():
            return "# Auto-Heal Error: AI is not configured. Please set your OpenAI API key."

        prompt = f"""
        You are an automated Python debugging assistant. Your task is to fix a script that has a runtime error.

        Here is the original code:
        ---
        {original_code}
        ---

        When executed, it produced this error:
        ---
        {error_message}
        ---

        An automated search for a solution found this related information from Stack Overflow:
        ---
        {research_summary}
        ---

        Based on all the provided information, please generate the complete, corrected Python code.
        Your output should ONLY be the Python code itself, without any extra explanations or markdown formatting.
        """
        print("Generating AI-powered fix...")
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}]
            )
            fixed_code = response.choices[0].message.content.strip()
            # Clean up potential markdown code fences
            if fixed_code.startswith("```python"):
                fixed_code = fixed_code.split("```python\n", 1)[1].rsplit("\n```", 1)[0]
            return fixed_code
        except Exception as e:
            return f"# Auto-Heal Error: The AI could not generate a fix.\n# Reason: {e}"

    def apply_fix(self, fixed_code: str) -> str:
        """
        Applies the fix by replacing the original file's content.
        It creates a backup of the original file first.
        """
        try:
            backup_path = self.file_path + ".bak"
            if os.path.exists(self.file_path):
                 os.rename(self.file_path, backup_path)
                 print(f"Created backup of original file at: {backup_path}")
            else:
                 return "Error: Original file not found to apply fix."


            with open(self.file_path, 'w', encoding='utf-8') as f:
                f.write(fixed_code)
            return "‚úÖ Fix applied successfully. Please try running the flow again."
        except Exception as e:
            return f"‚ùå Error: Failed to write the fix to the file. Reason: {e}"


# --- Example Usage ---
if __name__ == "__main__":
    print("--- Testing AutoHealer ---")
    
    # Create a dummy script with a common runtime error
    script_to_fix = "test_error_script.py"
    with open(script_to_fix, 'w') as f:
        # This will cause an AttributeError because os.get_login() doesn't exist on all platforms
        # and is often empty. A better function is os.getlogin().
        f.write("import os\nprint(f'User: {os.get_logon()}')") 

    # To run this part, you need to set your OpenAI API key
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("\nSkipping AutoHealer test: OPENAI_API_KEY environment variable not set.")
    else:
        healer = AutoHealer(script_to_fix, api_key=api_key)

        # 1. Diagnose the script
        stdout, stderr = healer.diagnose()

        if stderr:
            print("\n--- ‚ùó Error Detected ---")
            print(stderr)

            # 2. Research the error
            print("\n--- üîç Researching Error ---")
            solution = healer.research_error(stderr)
            print(f"Research result:\n{solution[:300]}...") # Print first 300 chars

            # 3. Propose a fix
            print("\n--- ü§ñ Proposing AI Fix ---")
            with open(script_to_fix, 'r') as f:
                original_code = f.read()
            
            ai_fix = healer.propose_fix(original_code, stderr, solution)
            print("AI's proposed code:\n---")
            print(ai_fix)
            print("---\n")
            
            # 4. Apply the fix
            if "Auto-Heal Error" not in ai_fix:
                status = healer.apply_fix(ai_fix)
                print(status)
                
                # 5. Re-diagnose to verify
                print("\n--- ‚úÖ Verifying Fix ---")
                new_stdout, new_stderr = healer.diagnose()
                if new_stderr:
                    print("Verification failed. The script still has an error:")
                    print(new_stderr)
                else:
                    print("Verification successful! Script now runs without errors.")
                    print(f"New output: {new_stdout}")
        else:
            print("\n--- ‚úÖ No Errors Detected ---")
            print(f"Script output: {stdout}")

    # Clean up test files
    if os.path.exists(script_to_fix):
        os.remove(script_to_fix)
    if os.path.exists(script_to_fix + ".bak"):
        os.remove(script_to_fix + ".bak")

========================================
# File: C:\Users\Saem1001\Documents\GitHub\ai_detect\net\neural_ide_lite\launch_neural_weaver.py
========================================

#!/usr/bin/env python3
"""
Neural Weaver Launcher
Handles dependency checks and launches the main application.
This new version is designed to be more robust and user-friendly.
"""

import sys
import subprocess
import os
from pathlib import Path

# --- Configuration ---
# A dictionary of required and optional packages.
# Key: The name used for the import check.
# Value: The package name for installation via pip.
PACKAGES = {
    "required": {
        "tkinter": "tkinter", # Usually built-in
        "networkx": "networkx",
        "matplotlib": "matplotlib",
        "psutil": "psutil",
        "numpy": "numpy",
        "pyyaml": "pyyaml",
        "ttkthemes": "ttkthemes",
        "Pillow": "Pillow", # For image handling in Tkinter
    },
    "optional": {
        "openai": "openai",
        "requests": "requests",
        "beautifulsoup4": "beautifulsoup4",
        "pylint": "pylint"
    }
}

# --- Helper Functions ---

def check_python_version():
    """
    Checks if the current Python version is 3.7 or higher.
    This is crucial for modern language features and library compatibility.
    """
    print("Step 1: Checking Python version...")
    if sys.version_info < (3, 7):
        print(f"‚ùå Error: Python 3.7 or higher is required.")
        print(f"   Your version is: {sys.version}")
        return False
    print(f"‚úÖ Python version {sys.version_info.major}.{sys.version_info.minor} is compatible.")
    return True

def get_missing_packages():
    """
    Checks for missing required and optional packages.
    Returns two lists: one for missing required packages, one for missing optional.
    """
    print("\nStep 2: Checking for required packages...")
    missing_required = []
    missing_optional = []

    # Check required packages
    for module, package in PACKAGES["required"].items():
        try:
            # Skip checking for tkinter as it's handled differently
            if module != 'tkinter':
                __import__(module)
        except ImportError:
            missing_required.append(package)

    # Special check for tkinter
    try:
        __import__('tkinter')
    except ImportError:
        missing_required.append('python3-tk') # Suggests the common package name on Linux

    if not missing_required:
        print("‚úÖ All required packages are installed.")
    else:
        print(f"‚ö†Ô∏è Missing required packages: {', '.join(missing_required)}")

    # Check optional packages for enhanced features
    print("\nStep 3: Checking for optional packages (for AI and advanced features)...")
    for module, package in PACKAGES["optional"].items():
        try:
            __import__(module)
        except ImportError:
            missing_optional.append(package)

    if not missing_optional:
        print("‚úÖ All optional packages are installed.")
    else:
        print(f"‚ö†Ô∏è Missing optional packages: {', '.join(missing_optional)}")

    return missing_required, missing_optional

def install_packages(packages_to_install: list):
    """
    Installs a list of packages using pip.
    """
    if not packages_to_install:
        return True

    print(f"\nInstalling packages: {', '.join(packages_to_install)}")
    print("This may take a moment...")
    try:
        # Ensure pip is up-to-date
        subprocess.check_call([sys.executable, "-m", "pip", "install", "--upgrade", "pip"])
        # Install the packages
        subprocess.check_call([sys.executable, "-m", "pip", "install"] + packages_to_install)
        print("\n‚úÖ Installation successful!")
        return True
    except subprocess.CalledProcessError as e:
        print(f"\n‚ùå Error during installation: {e}")
        print("Please try installing the packages manually and run the launcher again.")
        return False
    except Exception as e:
        print(f"\n‚ùå An unexpected error occurred: {e}")
        return False

def launch_app():
    """
    Finds and launches the main Neural Weaver application.
    """
    print("\nStep 4: Launching Neural Weaver...")
    print("-" * 50)
    script_dir = Path(__file__).parent.resolve()
    main_app_file = script_dir / "neural_weaver_main.py"

    if not main_app_file.exists():
        print(f"‚ùå Critical Error: Main application file not found!")
        print(f"   Expected at: {main_app_file}")
        print("   Please ensure 'neural_weaver_main.py' is in the same directory as this launcher.")
        return

    # Add the script's directory to the Python path to ensure imports work correctly
    sys.path.insert(0, str(script_dir))
    
    try:
        # Import the main function from the application file and run it
        from neural_weaver_main import main as run_app
        run_app()
    except ImportError as e:
        print(f"\n‚ùå Error: Could not import the main application.")
        print(f"   Details: {e}")
        print("   This might be due to a missing dependency or an issue in the main script.")
    except Exception as e:
        print(f"\n‚ùå An unexpected error occurred while launching the application:")
        import traceback
        traceback.print_exc()

# --- Main Execution ---

def main():
    """
    Main function to run the launcher sequence.
    """
    print("=" * 50)
    print("      Welcome to the Neural Weaver Launcher")
    print("=" * 50)

    if not check_python_version():
        input("\nPress Enter to exit.")
        sys.exit(1)

    missing_required, missing_optional = get_missing_packages()

    if missing_required:
        prompt = f"\nSome required packages are missing. Do you want to install them now? (y/n): "
        if input(prompt).lower() == 'y':
            if not install_packages(missing_required):
                input("\nPress Enter to exit.")
                sys.exit(1)
        else:
            print("\nCannot start without required packages. Exiting.")
            sys.exit(1)

    if missing_optional:
        prompt = f"\nOptional packages for AI features are missing. Install them for the best experience? (y/n): "
        if input(prompt).lower() == 'y':
            install_packages(missing_optional)

    launch_app()
    print("-" * 50)
    print("Neural Weaver has closed. Thank you for using it!")


if __name__ == "__main__":
    main()

========================================
# File: C:\Users\Saem1001\Documents\GitHub\ai_detect\net\neural_ide_lite\neural_weaver_main.py
========================================

#!/usr/bin/env python3
"""
Neural Weaver: A Visual IDE for Building Data Flows
This is the main application file, rewritten from the ground up to provide
an intuitive, block-based, visual environment for creating and running
complex data processing and neural network flows.
"""

import tkinter as tk
from tkinter import ttk, messagebox, filedialog, simpledialog, font
from ttkthemes import ThemedTk
import os
import sys
import subprocess
import threading
import queue
from pathlib import Path
import psutil
from PIL import Image, ImageTk, ImageDraw, ImageFont

# --- Proactive Fix: Added missing imports from the 'typing' module ---
from typing import Optional, List, Dict, Any

# Import rewritten support modules
from weaver_config import ConfigManager, FlowConfig, BlockConfig
from ai_assist import BlockAnalyzer, AISuggestor, save_api_key, load_api_key
from auto_healer import AutoHealer
from weaver_tools import PerformanceProfiler, MessageDebugger, Message

# --- Constants and Configuration ---
APP_NAME = "Neural Weaver"
APP_VERSION = "2.0"
BLOCK_WIDTH = 180
BLOCK_HEIGHT = 80
PIN_RADIUS = 6
GRID_SIZE = 20

# --- Main Application Class ---

class NeuralWeaverApp:
    """
    The main class for the Neural Weaver application. It orchestrates the UI,
    user interactions, and the backend processing of flows.
    """
    def __init__(self, root):
        self.root = root
        self.setup_main_window()

        # Backend Services
        self.config_manager = ConfigManager()
        self.profiler = PerformanceProfiler()
        self.profiler.start_monitoring()
        self.debugger = MessageDebugger()

        # App State
        self.current_flow: Optional[FlowConfig] = None
        self.selected_block_id: Optional[str] = None
        self.process_manager: Dict[str, Any] = {} # Maps block_id to its subprocess and psutil process
        self.output_queue: queue.Queue = queue.Queue() # For thread-safe UI updates from subprocesses
        self.is_running_flow = False
        self._drag_data: Dict[str, Any] = {} # For handling drag-and-drop
        
        # UI Components
        self.build_ui()
        
        # Load last opened flow or show welcome
        self.load_initial_flow()
        
        # Start the UI update loop
        self.root.after(100, self.process_output_queue)

    def setup_main_window(self):
        """Configures the main application window."""
        self.root.title(f"{APP_NAME} - {APP_VERSION}")
        self.root.geometry("1600x900")
        self.root.protocol("WM_DELETE_WINDOW", self.on_close)
        
        # --- Styling ---
        self.style = ttk.Style()
        self.style.theme_use('clam')

        # Glassy Dark Theme Colors
        BG_COLOR = "#2c2f33"
        FG_COLOR = "#ffffff"
        INACTIVE_BG_COLOR = "#23272a"
        ACCENT_COLOR = "#7289da"
        BORDER_COLOR = "#4f545c"
        CANVAS_BG = "#1e1f22"
        TEXT_AREA_BG = "#23272a"
        BUTTON_BG = "#40444b"

        # Configure styles for a dark, glassy feel
        self.style.configure('.', background=BG_COLOR, foreground=FG_COLOR, bordercolor=BORDER_COLOR, font=('Segoe UI', 10))
        self.style.configure('TFrame', background=BG_COLOR)
        self.style.configure('TLabel', background=BG_COLOR, foreground=FG_COLOR)
        self.style.configure('TButton', background=BUTTON_BG, foreground=FG_COLOR, borderwidth=1, focusthickness=3, focuscolor=ACCENT_COLOR, padding=5)
        self.style.map('TButton', background=[('active', ACCENT_COLOR)])
        self.style.configure('Treeview', background=TEXT_AREA_BG, foreground=FG_COLOR, fieldbackground=TEXT_AREA_BG, rowheight=25)
        self.style.map('Treeview', background=[('selected', ACCENT_COLOR)])
        self.style.configure('Treeview.Heading', background=BUTTON_BG, font=('Segoe UI', 10, 'bold'))
        self.style.configure('Vertical.TScrollbar', background=BG_COLOR, troughcolor=BUTTON_BG)
        self.style.configure('Inspector.TFrame', background=INACTIVE_BG_COLOR, relief='solid', borderwidth=1)
        self.style.configure('Inspector.TLabel', background=INACTIVE_BG_COLOR, font=('Segoe UI', 11, 'bold'))
        self.style.configure('Header.TLabel', font=('Segoe UI', 12, 'bold'), foreground=ACCENT_COLOR)
        self.style.configure('TPanedwindow', background=BG_COLOR)
        self.style.configure('TNotebook', background=BG_COLOR, tabmargins=[2, 5, 2, 0])
        self.style.configure('TNotebook.Tab', background=BUTTON_BG, foreground='white', padding=[10, 5])
        self.style.map('TNotebook.Tab', background=[('selected', ACCENT_COLOR)], foreground=[('selected', 'white')])
        
        self.root.configure(bg=BG_COLOR)

    def build_ui(self):
        """Constructs the main UI layout with Palette, Canvas, and Inspector."""
        main_pane = ttk.PanedWindow(self.root, orient=tk.HORIZONTAL)
        main_pane.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

        # --- Left Panel: Block Palette ---
        palette_frame = ttk.Frame(main_pane, width=250, style='Inspector.TFrame')
        main_pane.add(palette_frame, weight=0)
        ttk.Label(palette_frame, text="Block Palette", style='Header.TLabel', anchor='center').pack(pady=10, fill='x')

        self.block_palette = ttk.Treeview(palette_frame, show="tree")
        self.block_palette.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        self.populate_block_palette()
        self.block_palette.bind('<ButtonPress-1>', self.on_palette_drag_start)

        # --- Center Panel: Canvas ---
        canvas_container = ttk.Frame(main_pane)
        main_pane.add(canvas_container, weight=1)
        
        toolbar = ttk.Frame(canvas_container)
        toolbar.pack(fill=tk.X, pady=(0, 5))
        self.build_toolbar(toolbar)

        self.canvas = tk.Canvas(canvas_container, bg="#1e1f22", highlightthickness=0)
        self.canvas.pack(fill=tk.BOTH, expand=True)
        self.canvas.bind('<Button-3>', self.on_canvas_right_click)

        # --- Right Panel: Inspector ---
        self.inspector_frame = ttk.Frame(main_pane, width=350, style='Inspector.TFrame')
        main_pane.add(self.inspector_frame, weight=0)
        
        self.inspector_notebook = ttk.Notebook(self.inspector_frame)
        self.inspector_notebook.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        self.build_inspector_tabs()
        self.show_inspector_message("Select a block to see its details or right-click the canvas for flow options.")

    def build_toolbar(self, parent):
        """Builds the main toolbar for flow control."""
        ttk.Button(parent, text="‚ñ∂ Run Flow", command=self.run_flow).pack(side=tk.LEFT, padx=5)
        ttk.Button(parent, text="‚èπ Stop Flow", command=self.stop_flow).pack(side=tk.LEFT, padx=5)
        ttk.Separator(parent, orient=tk.VERTICAL).pack(side=tk.LEFT, padx=10, fill='y', pady=5)
        ttk.Button(parent, text="üíæ Save Flow", command=self.save_current_flow).pack(side=tk.LEFT, padx=5)
        self.flow_title_label = ttk.Label(parent, text="No Flow Loaded", font=('Segoe UI', 12, 'bold'))
        self.flow_title_label.pack(side=tk.RIGHT, padx=20)

    def build_inspector_tabs(self):
        """Creates the tabs within the inspector panel."""
        self.settings_tab = ttk.Frame(self.inspector_notebook)
        self.logs_tab = ttk.Frame(self.inspector_notebook)
        self.perf_tab = ttk.Frame(self.inspector_notebook)
        self.ai_tab = ttk.Frame(self.inspector_notebook)
        
        self.inspector_notebook.add(self.settings_tab, text="Settings")
        self.inspector_notebook.add(self.logs_tab, text="Logs")
        self.inspector_notebook.add(self.perf_tab, text="Performance")
        self.inspector_notebook.add(self.ai_tab, text="AI Assist ‚ú®")

        # Add log text area now so it's always available
        self.log_text = tk.Text(self.logs_tab, wrap=tk.WORD, bg="#23272a", fg="lightgrey", relief=tk.FLAT, borderwidth=0)
        self.log_text.pack(fill=tk.BOTH, expand=True, padx=2, pady=2)
        self.log_text.config(state=tk.DISABLED)

    def populate_block_palette(self):
        """Fills the block palette with predefined block types."""
        data_cat = self.block_palette.insert("", "end", text="Data I/O")
        proc_cat = self.block_palette.insert("", "end", text="Processing")
        nn_cat = self.block_palette.insert("", "end", text="Neural Network")
        
        self.block_palette.insert(data_cat, "end", text="File Input", values=("data_input", "Read data from a file (CSV, TXT)."))
        self.block_palette.insert(data_cat, "end", text="File Output", values=("data_output", "Save data to a file."))
        self.block_palette.insert(proc_cat, "end", text="Custom Python", values=("custom_python", "Write your own Python logic."))
        self.block_palette.insert(nn_cat, "end", text="Dense Layer", values=("nn_layer", "A fully connected neural network layer."))
        
        self.block_palette.item(data_cat, open=True)
        self.block_palette.item(proc_cat, open=True)
        self.block_palette.item(nn_cat, open=True)

    def on_palette_drag_start(self, event):
        """Initiates a drag-and-drop operation from the palette."""
        item_id = self.block_palette.identify_row(event.y)
        if not item_id or not self.current_flow:
            return

        try:
            item_values = self.block_palette.item(item_id, "values")
        except tk.TclError:
            return # Clicked on a category header

        if not item_values:
            return
        
        block_type, description = item_values
        block_name = self.block_palette.item(item_id, "text")

        # Create a semi-transparent temporary window to represent the dragged block
        drag_window = tk.Toplevel(self.root)
        drag_window.overrideredirect(True)
        drag_window.attributes('-alpha', 0.7)
        drag_window.geometry(f"{BLOCK_WIDTH}x{BLOCK_HEIGHT}+{event.x_root}+{event.y_root}")
        
        label_frame = tk.Frame(drag_window, bg="#7289da")
        label_frame.pack(expand=True, fill='both')
        label = tk.Label(label_frame, text=block_name, fg="white", bg="#7289da", font=('Segoe UI', 10, 'bold'))
        label.pack(expand=True, fill='both')
        
        drag_window.lift()

        def on_drag_move(e):
            drag_window.geometry(f"+{e.x_root-BLOCK_WIDTH//2}+{e.y_root-BLOCK_HEIGHT//2}")

        def on_drag_drop(e):
            drag_window.destroy()
            self.root.unbind('<Motion>')
            self.root.unbind('<ButtonRelease-1>')
            x, y = self.canvas.canvasx(e.x), self.canvas.canvasy(e.y)
            self.add_new_block(block_type, block_name, description, {"x": int(x), "y": int(y)})

        self.root.bind('<Motion>', on_drag_move)
        self.root.bind('<ButtonRelease-1>', on_drag_drop)

    def on_canvas_right_click(self, event):
        """Shows a context menu on the canvas."""
        menu = tk.Menu(self.root, tearoff=0, bg="#2c2f33", fg="#ffffff", activebackground="#7289da", relief=tk.FLAT)
        menu.add_command(label="New Flow...", command=self.create_new_flow)
        menu.add_command(label="Open Flow...", command=self.open_flow_dialog)
        
        if self.current_flow:
            menu.add_separator()
            menu.add_command(label="Save Flow", command=self.save_current_flow)
            menu.add_command(label=f"Validate '{self.current_flow.name}'", command=self.validate_current_flow)
        
        menu.add_separator()
        menu.add_command(label="Settings...", command=self.show_settings)
        menu.tk_popup(event.x_root, event.y_root)

    # --- Flow Management ---

    def load_initial_flow(self):
        """Loads the first available flow or creates a default one."""
        flows = self.config_manager.list_flows()
        if flows:
            self.load_flow_by_name(flows[0])
        else:
            self.create_new_flow(from_template="Simple Data Pipeline")

    def create_new_flow(self, from_template=None):
        """Creates a new, empty flow or loads one from a template."""
        if self.is_running_flow:
            messagebox.showwarning("Flow Running", "Cannot create a new flow while one is running.")
            return

        if from_template:
            try:
                self.current_flow = self.config_manager.load_template(from_template)
            except FileNotFoundError:
                messagebox.showerror("Error", f"Template '{from_template}' not found. Creating empty flow.")
                self.current_flow = FlowConfig(name="New Untitled Flow")
        else:
            self.current_flow = FlowConfig(name="New Untitled Flow")
        
        self.redraw_canvas()
        self.update_flow_title()

    def open_flow_dialog(self):
        """Shows a dialog to open an existing flow."""
        flows = self.config_manager.list_flows()
        if not flows:
            messagebox.showinfo("No Flows", "No saved flows found. Create a new one!")
            return

        # Simple dialog to choose a flow
        win = tk.Toplevel(self.root)
        win.title("Open Flow")
        ttk.Label(win, text="Select a flow to open:").pack(pady=10)
        listbox = tk.Listbox(win, bg="#23272a", fg="white", selectbackground="#7289da")
        listbox.pack(padx=10, pady=5, fill=tk.BOTH, expand=True)
        for flow_name in flows:
            listbox.insert(tk.END, flow_name)
        
        def on_select():
            selected = listbox.get(listbox.curselection())
            self.load_flow_by_name(selected)
            win.destroy()

        ttk.Button(win, text="Open", command=on_select).pack(pady=10)

    def load_flow_by_name(self, name: str):
        """Loads a flow and displays it on the canvas."""
        try:
            self.current_flow = self.config_manager.load_flow(name)
            self.redraw_canvas()
            self.update_flow_title()
            self.show_inspector_message("Flow loaded successfully. Select a block to view details.")
        except Exception as e:
            messagebox.showerror("Load Error", f"Failed to load flow '{name}':\n{e}")

    def save_current_flow(self):
        """Saves the currently active flow."""
        if not self.current_flow:
            messagebox.showwarning("Warning", "No flow is currently loaded.")
            return
        
        try:
            self.config_manager.save_flow(self.current_flow)
            self.update_flow_title() # In case the name was changed
            messagebox.showinfo("Success", f"Flow '{self.current_flow.name}' saved successfully.")
        except Exception as e:
            messagebox.showerror("Save Error", f"Failed to save flow:\n{e}")
    
    def validate_current_flow(self):
        """Validates the current flow for errors."""
        if not self.current_flow:
            return
        errors = ConfigManager.validate_flow(self.current_flow)
        if not errors:
            messagebox.showinfo("Validation", "‚úÖ This flow is valid!")
        else:
            messagebox.showwarning("Validation Issues", "Found issues:\n\n" + "\n".join(errors))

    # --- Block Management ---

    def add_new_block(self, block_type: str, name: str, desc: str, pos: Dict[str, int]):
        """Adds a new block to the current flow."""
        if not self.current_flow:
            return
        
        new_id = f"block_{os.urandom(4).hex()}"
        new_block = BlockConfig(id=new_id, name=name, description=desc, block_type=block_type, position=pos)
        self.current_flow.blocks.append(new_block)
        self.draw_block(new_block)
        self.select_block(new_id)

    def draw_block(self, block: BlockConfig):
        """Draws a single block on the canvas."""
        x, y = block.position['x'], block.position['y']
        tag = f"block_{block.id}"
        
        self.canvas.create_rectangle(x, y, x + BLOCK_WIDTH, y + BLOCK_HEIGHT, fill="#40444b", outline="#7289da", width=2, tags=(tag, "block_body"))
        self.canvas.create_text(x + BLOCK_WIDTH/2, y + 20, text=block.name, fill="white", font=('Segoe UI', 10, 'bold'), tags=tag)
        
        self.canvas.create_oval(x - PIN_RADIUS, y + BLOCK_HEIGHT/2 - PIN_RADIUS, x + PIN_RADIUS, y + BLOCK_HEIGHT/2 + PIN_RADIUS, fill="cyan", tags=(tag, "pin", "input_pin", f"pin_{block.id}_in"))
        self.canvas.create_oval(x + BLOCK_WIDTH - PIN_RADIUS, y + BLOCK_HEIGHT/2 - PIN_RADIUS, x + BLOCK_WIDTH + PIN_RADIUS, y + BLOCK_HEIGHT/2 + PIN_RADIUS, fill="magenta", tags=(tag, "pin", "output_pin", f"pin_{block.id}_out"))

        self.canvas.tag_bind(tag, '<ButtonPress-1>', lambda e, b_id=block.id: self.on_block_press(e, b_id))
        self.canvas.tag_bind(tag, '<B1-Motion>', self.on_block_drag)
        self.canvas.tag_bind(tag, '<ButtonRelease-1>', self.on_block_release)

    def on_block_press(self, event, block_id):
        """Handles when a block is clicked."""
        self.select_block(block_id)
        self._drag_data = {'x': event.x, 'y': event.y, 'id': block_id}
        self.canvas.lift(f"block_{block_id}") # Bring to front

    def on_block_drag(self, event):
        """Handles dragging a block."""
        if not self._drag_data: return
        dx = event.x - self._drag_data['x']
        dy = event.y - self._drag_data['y']
        
        tag = f"block_{self._drag_data['id']}"
        self.canvas.move(tag, dx, dy)
        
        self._drag_data['x'] = event.x
        self._drag_data['y'] = event.y
        self.redraw_connections()

    def on_block_release(self, event):
        """Handles when a block is released after dragging."""
        if not self._drag_data: return
        block_id = self._drag_data['id']
        block = self.get_block_by_id(block_id)
        if block:
            body_items = self.canvas.find_withtag(f"block_{block_id} and block_body")
            if body_items:
                coords = self.canvas.coords(body_items[0])
                block.position['x'] = int(coords[0])
                block.position['y'] = int(coords[1])
        self._drag_data = {}
        self.redraw_canvas()

    def get_block_by_id(self, block_id: str) -> Optional[BlockConfig]:
        """Finds a block in the current flow by its ID."""
        if self.current_flow:
            return next((b for b in self.current_flow.blocks if b.id == block_id), None)
        return None

    def select_block(self, block_id: str):
        """Selects a block and updates the inspector panel."""
        self.selected_block_id = block_id
        self.redraw_canvas() # Redraw to handle selection highlight
        self.update_inspector()

    # --- Canvas & UI Redrawing ---
    
    def redraw_canvas(self):
        """Clears and redraws the entire canvas from the current flow data."""
        self.canvas.delete("all")
        if not self.current_flow:
            return
            
        for block in self.current_flow.blocks:
            self.draw_block(block)
        
        if self.selected_block_id:
            tag = f"block_{self.selected_block_id}"
            body_items = self.canvas.find_withtag(f"{tag} and block_body")
            if body_items:
                self.canvas.itemconfig(body_items[0], outline="yellow", width=3)
        
        self.redraw_connections()

    def redraw_connections(self):
        """Draws the lines representing dependencies between blocks."""
        self.canvas.delete("connection")
        if not self.current_flow:
            return

        for block in self.current_flow.blocks:
            for dep_id in block.dependencies:
                out_pin_items = self.canvas.find_withtag(f"pin_{dep_id}_out")
                in_pin_items = self.canvas.find_withtag(f"pin_{block.id}_in")

                if out_pin_items and in_pin_items:
                    out_coords = self.canvas.coords(out_pin_items[0])
                    in_coords = self.canvas.coords(in_pin_items[0])
                    
                    x1, y1 = (out_coords[0] + out_coords[2]) / 2, (out_coords[1] + out_coords[3]) / 2
                    x2, y2 = (in_coords[0] + in_coords[2]) / 2, (in_coords[1] + in_coords[3]) / 2
                    
                    self.canvas.create_line(x1, y1, x1 + 50, y1, x2 - 50, y2, x2, y2, smooth=True, arrow=tk.LAST, fill="white", width=2, tags="connection")

    def update_flow_title(self):
        """Updates the flow title label."""
        if self.current_flow:
            self.flow_title_label.config(text=self.current_flow.name)
        else:
            self.flow_title_label.config(text="No Flow Loaded")

    def update_inspector(self):
        """Updates the inspector panel based on the selected block."""
        for tab in self.inspector_notebook.tabs():
            for widget in self.inspector_notebook.nametowidget(tab).winfo_children():
                widget.destroy()

        block = self.get_block_by_id(self.selected_block_id)
        if not block:
            self.show_inspector_message("No block selected.")
            return

        # --- Populate Settings Tab ---
        ttk.Label(self.settings_tab, text=f"Settings: {block.name}", style='Header.TLabel').pack(pady=10, fill=tk.X, padx=5)
        
        # --- Populate AI Tab ---
        ttk.Button(self.ai_tab, text="üîç Analyze Code", command=self.analyze_selected_block).pack(pady=10, fill=tk.X, padx=10)
        ttk.Button(self.ai_tab, text="‚ú® Get AI Suggestion", command=self.get_ai_suggestion).pack(pady=5, fill=tk.X, padx=10)
        ttk.Button(self.ai_tab, text="ü™Ñ Auto-Heal Error", command=self.auto_heal_block).pack(pady=5, fill=tk.X, padx=10)

    def show_inspector_message(self, message):
        """Displays a message in the inspector panel when no block is selected."""
        for tab in self.inspector_notebook.tabs():
            for widget in self.inspector_notebook.nametowidget(tab).winfo_children():
                widget.destroy()
        label = ttk.Label(self.settings_tab, text=message, wraplength=300, justify=tk.CENTER, anchor='center')
        label.pack(expand=True, padx=20, pady=20)

    # --- AI & Healing Integration ---

    def analyze_selected_block(self):
        messagebox.showinfo("Analyze", "Code analysis would be implemented here.")

    def get_ai_suggestion(self):
        messagebox.showinfo("AI Suggestion", "AI suggestions would be implemented here.")

    def auto_heal_block(self):
        messagebox.showinfo("Auto-Heal", "Auto-healing would be implemented here.")

    def show_settings(self):
        """Opens a dialog for application-level settings like the API key."""
        key = simpledialog.askstring("Settings", "Enter your OpenAI API Key:", parent=self.root)
        if key:
            save_api_key(key)
            messagebox.showinfo("Success", "API Key saved. AI features are now available.")

    # --- Flow Execution ---

    def run_flow(self):
        """Executes the entire flow based on dependencies."""
        if self.is_running_flow:
            messagebox.showwarning("Warning", "A flow is already running.")
            return
        if not self.current_flow: return
        
        messagebox.showinfo("Run Flow", "Flow execution would start here, processing blocks in order.")
        self.is_running_flow = True

    def stop_flow(self):
        """Stops all running blocks in the flow."""
        messagebox.showinfo("Stop Flow", "Stopping all running blocks.")
        self.is_running_flow = False
        
    def process_output_queue(self):
        """Processes messages from subprocesses to update the UI."""
        try:
            while True:
                block_id, tag, line = self.output_queue.get_nowait()
                if self.selected_block_id == block_id:
                    self.log_text.config(state=tk.NORMAL)
                    self.log_text.insert(tk.END, line)
                    self.log_text.see(tk.END)
                    self.log_text.config(state=tk.DISABLED)
        except queue.Empty:
            pass
        finally:
            self.root.after(100, self.process_output_queue)

    # --- App Lifecycle ---

    def on_close(self):
        """Handles the application close event."""
        if messagebox.askokcancel("Quit", "Do you want to exit Neural Weaver?"):
            self.profiler.stop_monitoring()
            self.root.destroy()

# --- Main Entry Point ---

def main():
    """The main function to create and run the Neural Weaver application."""
    root = ThemedTk(theme="clam")
    app = NeuralWeaverApp(root)
    root.mainloop()

if __name__ == '__main__':
    main()

========================================
# File: C:\Users\Saem1001\Documents\GitHub\ai_detect\net\neural_ide_lite\setup.py
========================================

import subprocess
import sys

def install(package):
    """
    Installs a given package using pip.
    This function is a simple wrapper around the pip install command.

    Args:
        package (str): The name of the package to install.
    """
    try:
        print(f"Installing {package}...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", package])
        print(f"‚úÖ Successfully installed {package}")
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Failed to install {package}. Pip returned a non-zero exit code.")
        print(f"   Error: {e}")
    except Exception as e:
        print(f"‚ùå An unexpected error occurred while installing {package}.")
        print(f"   Error: {e}")

def main():
    """
    Main function to set up the environment for Neural Weaver.
    It installs all required and optional dependencies.
    """
    print("--- Starting Neural Weaver Setup ---")

    # A comprehensive list of packages needed for full functionality.
    # We've added ttkthemes for styling and Pillow for better image support in the UI.
    all_packages = [
        # Core UI and Logic
        "ttkthemes",
        "Pillow",
        "networkx",
        "matplotlib",
        "psutil",
        "numpy",
        "pyyaml",
        # Optional AI & Analysis Features
        "openai",
        "requests",
        "beautifulsoup4",
        "pylint",
    ]

    print("\nThis script will install all necessary packages for Neural Weaver.")
    
    # Iterate through the list and install each package
    for package in all_packages:
        install(package)
    
    print("\n--- Setup Complete ---")
    print("\nFor AI features using GitHub Copilot (if you choose to enable it):")
    print("1. Ensure you have the GitHub CLI installed ('gh').")
    print("2. Authenticate by running: gh auth login")
    print("3. Install the Copilot extension: gh extension install github/gh-copilot")
    print("\nFor AI features using OpenAI:")
    print("1. You will need an API key from https://platform.openai.com/")
    print("2. The application will prompt you to enter this key when needed.")
    
    print("\nYou can now run the application using 'launch_neural_weaver.py'.")

if __name__ == "__main__":
    main()

========================================
# File: C:\Users\Saem1001\Documents\GitHub\ai_detect\net\neural_ide_lite\weaver_config.py
========================================

"""
Weaver Config: Configuration Manager for Neural Weaver
Handles the loading, saving, and validation of "Flows" (formerly projects)
and "Blocks" (formerly scripts). It uses human-readable YAML files.
"""

import yaml
from pathlib import Path
from dataclasses import dataclass, field, asdict
from typing import Dict, List, Any, Optional
from datetime import datetime
import os
import networkx as nx

# --- Data Structures for Flows and Blocks ---

@dataclass
class BlockConfig:
    """
    Configuration for a single 'Block' on the canvas.
    This is the new, more user-friendly version of 'ScriptConfig'.
    """
    id: str
    name: str
    description: str = "A configurable processing block."
    block_type: str = "custom"  # e.g., 'data_input', 'text_processor', 'image_classifier'
    file_path: Optional[str] = None
    dependencies: List[str] = field(default_factory=list)
    
    # User-friendly settings, replacing 'parameters'
    settings: Dict[str, Any] = field(default_factory=dict)
    
    # For UI positioning on the canvas
    position: Dict[str, int] = field(default_factory=lambda: {"x": 100, "y": 100})
    
    # Advanced options
    auto_restart: bool = False
    max_retries: int = 3
    
@dataclass
class FlowConfig:
    """
    Configuration for an entire 'Flow' or 'Weave'.
    This is the new version of 'ProjectConfig'.
    """
    name: str
    version: str = "1.0"
    description: str = "A Neural Weaver data flow."
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    modified_at: str = field(default_factory=lambda: datetime.now().isoformat())
    blocks: List[BlockConfig] = field(default_factory=list)
    global_settings: Dict[str, Any] = field(default_factory=dict)

# --- Main Configuration Manager Class ---

class ConfigManager:
    """
    Manages all configurations for Neural Weaver, including Flows and Templates.
    Provides a clean API for the main application to interact with the file system.
    """
    
    def __init__(self, base_dir: Optional[Path] = None):
        """
        Initializes the configuration manager, creating necessary directories.
        """
        if base_dir:
            self.config_dir = base_dir
        else:
            self.config_dir = Path.home() / ".neural_weaver"
            
        self.flows_dir = self.config_dir / "flows"
        self.templates_dir = self.config_dir / "templates"
        
        # Ensure all necessary directories exist
        self.config_dir.mkdir(exist_ok=True)
        self.flows_dir.mkdir(exist_ok=True)
        self.templates_dir.mkdir(exist_ok=True)
        
        # Populate with default templates if the directory is empty
        self._create_default_templates_if_needed()

    def _create_default_templates_if_needed(self):
        """Checks if default templates exist and creates them if not."""
        if any(self.templates_dir.iterdir()):
            return # Templates already exist
        
        print("Creating default flow templates...")
        
        # --- Template Definitions ---
        
        # 1. Simple Data Processing Pipeline
        pipeline_template = FlowConfig(
            name="Simple Data Pipeline",
            description="A basic ETL (Extract, Transform, Load) pipeline.",
            blocks=[
                BlockConfig(id="block_1", name="Load CSV Data", block_type="data_input", position={"x": 50, "y": 100},
                            settings={"file_path": "path/to/your/data.csv"}),
                BlockConfig(id="block_2", name="Filter Rows", block_type="data_transform", position={"x": 300, "y": 100},
                            dependencies=["block_1"], settings={"filter_column": "age", "operator": ">", "value": 30}),
                BlockConfig(id="block_3", name="Save Results", block_type="data_output", position={"x": 550, "y": 100},
                            dependencies=["block_2"], settings={"output_file": "path/to/filtered_data.csv"})
            ]
        )
        self.save_template("simple_data_pipeline", pipeline_template)
        
        # 2. Basic Neural Network
        nn_template = FlowConfig(
            name="Basic Neural Network",
            description="A simple feed-forward neural network for classification.",
            blocks=[
                BlockConfig(id="input", name="Input Layer", block_type="nn_layer", position={"x": 50, "y": 150},
                            settings={"neurons": 784, "activation": "none"}),
                BlockConfig(id="hidden1", name="Hidden Layer", block_type="nn_layer", position={"x": 300, "y": 50},
                            dependencies=["input"], settings={"neurons": 128, "activation": "relu"}),
                BlockConfig(id="hidden2", name="Hidden Layer", block_type="nn_layer", position={"x": 300, "y": 250},
                            dependencies=["input"], settings={"neurons": 128, "activation": "relu"}),
                BlockConfig(id="output", name="Output Layer", block_type="nn_layer", position={"x": 550, "y": 150},
                            dependencies=["hidden1", "hidden2"], settings={"neurons": 10, "activation": "softmax"})
            ],
            global_settings={"learning_rate": 0.001, "optimizer": "Adam", "epochs": 10}
        )
        self.save_template("basic_neural_network", nn_template)

    def save_flow(self, flow_config: FlowConfig) -> Path:
        """
        Saves a Flow configuration to a YAML file.
        Updates the 'modified_at' timestamp automatically.
        """
        flow_config.modified_at = datetime.now().isoformat()
        file_path = self.flows_dir / f"{flow_config.name.replace(' ', '_').lower()}.yaml"
        with open(file_path, 'w', encoding='utf-8') as f:
            # Use asdict to convert the dataclass to a dictionary for dumping
            yaml.dump(asdict(flow_config), f, default_flow_style=False, sort_keys=False)
        return file_path

    def load_flow(self, flow_name: str) -> FlowConfig:
        """Loads a Flow configuration from a YAML file."""
        file_path = self.flows_dir / f"{flow_name.replace(' ', '_').lower()}.yaml"
        if not file_path.exists():
            raise FileNotFoundError(f"Flow '{flow_name}' not found at {file_path}")
            
        with open(file_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)
            
        # Reconstruct the dataclass from the loaded dictionary
        data['blocks'] = [BlockConfig(**b) for b in data.get('blocks', [])]
        return FlowConfig(**data)

    def delete_flow(self, flow_name: str):
        """Deletes a flow file."""
        file_path = self.flows_dir / f"{flow_name.replace(' ', '_').lower()}.yaml"
        if file_path.exists():
            file_path.unlink()
        else:
            raise FileNotFoundError(f"Flow '{flow_name}' not found for deletion.")

    def list_flows(self) -> List[str]:
        """Returns a list of all available Flow names."""
        return [p.stem.replace('_', ' ').title() for p in self.flows_dir.glob("*.yaml")]

    def save_template(self, template_name: str, flow_config: FlowConfig):
        """Saves a Flow configuration as a reusable template."""
        file_path = self.templates_dir / f"{template_name.replace(' ', '_').lower()}.yaml"
        with open(file_path, 'w', encoding='utf-8') as f:
            yaml.dump(asdict(flow_config), f, default_flow_style=False, sort_keys=False)

    def load_template(self, template_name: str) -> FlowConfig:
        """Loads a template and returns it as a new FlowConfig object."""
        file_path = self.templates_dir / f"{template_name.replace(' ', '_').lower()}.yaml"
        if not file_path.exists():
            raise FileNotFoundError(f"Template '{template_name}' not found at {file_path}")

        with open(file_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)
        
        data['blocks'] = [BlockConfig(**b) for b in data.get('blocks', [])]
        # Reset name so the user can define a new one
        data['name'] = f"New Flow from {template_name.replace('_', ' ').title()}"
        return FlowConfig(**data)

    def list_templates(self) -> List[str]:
        """Returns a list of all available template names."""
        return [p.stem.replace('_', ' ').title() for p in self.templates_dir.glob("*.yaml")]

    @staticmethod
    def validate_flow(flow_config: FlowConfig) -> List[str]:
        """
        Validates a flow for common issues like duplicate IDs or cyclic dependencies.
        Returns a list of error messages. An empty list means the flow is valid.
        """
        errors = []
        block_ids = [block.id for block in flow_config.blocks]

        # 1. Check for duplicate block IDs
        if len(block_ids) != len(set(block_ids)):
            errors.append("Error: Duplicate Block IDs found. Each block must have a unique ID.")

        # 2. Check for dependency issues using NetworkX for robust cycle detection
        graph = nx.DiGraph()
        for block in flow_config.blocks:
            graph.add_node(block.id)
            for dep_id in block.dependencies:
                if dep_id not in block_ids:
                    errors.append(f"Error: Block '{block.name}' has a broken connection to non-existent block '{dep_id}'.")
                else:
                    graph.add_edge(dep_id, block.id)
        
        # 3. Check for cycles (e.g., A -> B -> A)
        try:
            cycles = list(nx.simple_cycles(graph))
            if cycles:
                # Provide a more user-friendly cycle description
                cycle_paths = " -> ".join(cycles[0]) + f" -> {cycles[0][0]}"
                errors.append(f"Error: A ciprcular connection was detected: {cycle_paths}. Blocks cannot depend on each other in a loop.")
        except Exception as e:
            errors.append(f"An unexpected error occurred during validation: {e}")
            
        return errors

# --- Example Usage ---
if __name__ == "__main__":
    # This demonstrates how the ConfigManager works.
    print("--- Testing Weaver ConfigManager ---")
    
    # Create a temporary directory for testing
    test_dir = Path("./temp_weaver_config")
    if not test_dir.exists():
        test_dir.mkdir()
        
    config_mgr = ConfigManager(base_dir=test_dir)
    
    # List initial templates
    print("\nAvailable Templates:")
    templates = config_mgr.list_templates()
    for t in templates:
        print(f"- {t}")
        
    # Create a new flow from a template
    new_flow = config_mgr.load_template(templates[0])
    new_flow.name = "My Test Data Flow"
    new_flow.description = "A test flow created from a template."
    
    # Add a new block
    new_block = BlockConfig(id="block_4", name="Log Output", dependencies=["block_3"], position={"x": 800, "y": 100})
    new_flow.blocks.append(new_block)
    
    # Save the new flow
    config_mgr.save_flow(new_flow)
    print(f"\nSaved new flow: '{new_flow.name}'")
    
    # List all flows
    print("\nAvailable Flows:")
    for f in config_mgr.list_flows():
        print(f"- {f}")
        
    # Load and validate the flow
    loaded_flow = config_mgr.load_flow(new_flow.name)
    print(f"\nLoaded flow '{loaded_flow.name}' with {len(loaded_flow.blocks)} blocks.")
    
    validation_errors = ConfigManager.validate_flow(loaded_flow)
    if not validation_errors:
        print("‚úÖ Flow validation successful.")
    else:
        print("‚ùå Flow validation failed:")
        for error in validation_errors:
            print(f"  - {error}")
            
    # Clean up the temporary directory
    import shutil
    shutil.rmtree(test_dir)
    print("\nCleaned up temporary test directory.")

========================================
# File: C:\Users\Saem1001\Documents\GitHub\ai_detect\net\neural_ide_lite\weaver_tools.py
========================================

"""
Weaver Tools: Advanced analysis tools for Neural Weaver.
This module contains the backend logic for performance profiling and message
debugging, adapted from the original 'neural_ide_tools.py'. The UI components
have been removed, as they will be built directly into the main application's
inspector panel for a more integrated experience.
"""

import time
import psutil
import threading
from collections import deque, defaultdict
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any
import numpy as np
import json
import re

# --- Performance Profiler ---

@dataclass
class PerformanceMetrics:
    """A single snapshot of performance measurements for a Block."""
    timestamp: float = field(default_factory=time.time)
    cpu_percent: float = 0.0
    memory_mb: float = 0.0
    # Custom metrics can be logged from the Block's code
    custom_metrics: Dict[str, float] = field(default_factory=dict)

@dataclass
class BlockProfile:
    """Holds the complete performance profile for a single Block."""
    block_id: str
    # Use a deque for efficient, fixed-size history
    metrics_history: deque = field(default_factory=lambda: deque(maxlen=300)) # 5 minutes of data
    bottlenecks: List[str] = field(default_factory=list)
    suggestions: List[str] = field(default_factory=list)
    # Describes how the block uses resources
    usage_pattern: str = "Balanced" # e.g., "CPU Intensive", "Memory Heavy"

class PerformanceProfiler:
    """
    The backend engine for monitoring the performance of all active blocks.
    It runs in a separate thread to avoid blocking the UI.
    """
    
    def __init__(self):
        self.block_profiles: Dict[str, BlockProfile] = {}
        self.monitored_processes: Dict[str, psutil.Process] = {}
        self.is_monitoring = False
        self.monitor_thread = None
        
        # Configurable thresholds for analysis
        self.thresholds = {
            'cpu_high': 80.0,      # percent
            'memory_high': 1024.0, # MB
            'memory_leak_slope': 0.5 # MB increase per second
        }

    def start_monitoring(self):
        """Starts the performance monitoring thread."""
        if self.is_monitoring:
            return
        print("Starting performance profiler...")
        self.is_monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()

    def stop_monitoring(self):
        """Stops the performance monitoring thread."""
        print("Stopping performance profiler...")
        self.is_monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=2)

    def add_block(self, block_id: str, process: psutil.Process):
        """Registers a new block and its process to be monitored."""
        if block_id not in self.block_profiles:
            self.block_profiles[block_id] = BlockProfile(block_id=block_id)
        self.monitored_processes[block_id] = process
        print(f"Profiler now tracking block: {block_id} (PID: {process.pid})")

    def remove_block(self, block_id: str):
        """Stops monitoring a block, typically when its process ends."""
        if block_id in self.monitored_processes:
            del self.monitored_processes[block_id]
        # We keep the profile data for later analysis
        print(f"Profiler stopped tracking block: {block_id}")

    def _monitor_loop(self):
        """The main loop that periodically collects and analyzes metrics."""
        while self.is_monitoring:
            try:
                # Iterate over a copy of keys to allow modification during loop
                for block_id in list(self.monitored_processes.keys()):
                    process = self.monitored_processes.get(block_id)
                    if process and process.is_running():
                        metrics = self._collect_metrics(process)
                        profile = self.block_profiles[block_id]
                        profile.metrics_history.append(metrics)
                        # Analyze performance every few seconds
                        if len(profile.metrics_history) % 5 == 0:
                            self._analyze_profile(profile)
                    else:
                        # Process has stopped, remove it from monitoring
                        self.remove_block(block_id)
                time.sleep(1) # Collection interval
            except Exception as e:
                print(f"Error in profiler loop: {e}")

    def _collect_metrics(self, process: psutil.Process) -> PerformanceMetrics:
        """Collects CPU and Memory metrics for a single process."""
        try:
            with process.oneshot():
                cpu = process.cpu_percent(interval=0.1)
                mem = process.memory_info().rss / (1024 * 1024) # to MB
                return PerformanceMetrics(cpu_percent=cpu, memory_mb=mem)
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            # This can happen if the process ends between checks
            return PerformanceMetrics()

    def _analyze_profile(self, profile: BlockProfile):
        """Analyzes a block's recent performance history to find issues."""
        if len(profile.metrics_history) < 10:
            return # Not enough data to analyze

        history = list(profile.metrics_history)
        recent_metrics = history[-60:] # Analyze last minute
        
        # Reset analysis results
        profile.bottlenecks.clear()
        profile.suggestions.clear()
        
        # --- Analysis Logic ---
        avg_cpu = np.mean([m.cpu_percent for m in recent_metrics])
        avg_mem = np.mean([m.memory_mb for m in recent_metrics])

        # High CPU usage
        if avg_cpu > self.thresholds['cpu_high']:
            profile.bottlenecks.append(f"High CPU Usage (avg {avg_cpu:.1f}%)")
            profile.suggestions.append("The code is very compute-intensive. Consider optimizing algorithms or using more efficient libraries like NumPy.")
        
        # High Memory usage
        if avg_mem > self.thresholds['memory_high']:
            profile.bottlenecks.append(f"High Memory Usage (avg {avg_mem:.1f} MB)")
            profile.suggestions.append("The block is using a lot of memory. Try processing data in smaller chunks or streams.")
            
        # Memory Leak Detection
        if len(recent_metrics) > 30:
            timestamps = np.array([m.timestamp for m in recent_metrics])
            memory_points = np.array([m.memory_mb for m in recent_metrics])
            # Fit a line to the memory usage over time
            slope, _ = np.polyfit(timestamps, memory_points, 1)
            if slope > self.thresholds['memory_leak_slope']:
                profile.bottlenecks.append(f"Potential Memory Leak (growing at {slope:.2f} MB/s)")
                profile.suggestions.append("Memory usage is consistently increasing. Check for data being appended to lists in a loop without being cleared.")

        # Determine usage pattern
        if avg_cpu > 60:
            profile.usage_pattern = "CPU Intensive"
        elif avg_mem > 500:
            profile.usage_pattern = "Memory Heavy"
        else:
            profile.usage_pattern = "Balanced"

    def get_profile(self, block_id: str) -> Optional[BlockProfile]:
        """Returns the full performance profile for a given block."""
        return self.block_profiles.get(block_id)

# --- Message Debugger ---

@dataclass
class Message:
    """Represents a single message passed between Blocks."""
    sender_id: str
    receiver_id: str
    payload: Any
    timestamp: float = field(default_factory=time.time)
    
    def to_json(self):
        """Serializes the message for transport or logging."""
        return json.dumps({
            "sender_id": self.sender_id,
            "receiver_id": self.receiver_id,
            "payload": self.payload,
            "timestamp": self.timestamp
        })

class MessageDebugger:
    """
    A backend service to log, inspect, and manage the flow of messages
    between all blocks in a flow.
    """
    def __init__(self, max_log_size: int = 5000):
        self.message_log: deque = deque(maxlen=max_log_size)
        self.stats = defaultdict(lambda: {"sent": 0, "received": 0})
    
    def log_message(self, message: Message):
        """Logs a message and updates statistics."""
        self.message_log.append(message)
        self.stats[message.sender_id]["sent"] += 1
        if message.receiver_id != "BROADCAST":
            self.stats[message.receiver_id]["received"] += 1
        else:
            # In a broadcast, we can't easily track all receivers here,
            # but the UI could show this.
            pass

    def get_messages(self, filter_text: str = "") -> List[Message]:
        """
        Returns a list of logged messages, optionally filtered by a string
        that can match sender, receiver, or payload content.
        """
        if not filter_text:
            return list(self.message_log)

        filtered_messages = []
        try:
            # Support simple text search and basic regex
            filter_regex = re.compile(filter_text, re.IGNORECASE)
            for msg in self.message_log:
                # Search in sender, receiver, and string representation of payload
                if filter_regex.search(msg.sender_id) or \
                   filter_regex.search(msg.receiver_id) or \
                   filter_regex.search(str(msg.payload)):
                    filtered_messages.append(msg)
        except re.error:
            # If regex is invalid, fall back to simple string contains
            for msg in self.message_log:
                 if filter_text.lower() in msg.sender_id.lower() or \
                    filter_text.lower() in msg.receiver_id.lower() or \
                    filter_text.lower() in str(msg.payload).lower():
                     filtered_messages.append(msg)
                     
        return filtered_messages

    def get_stats(self) -> Dict:
        """Returns statistics about message traffic."""
        return {
            "total_messages": len(self.message_log),
            "block_stats": dict(self.stats)
        }

    def clear(self):
        """Clears the message log and statistics."""
        self.message_log.clear()
        self.stats.clear()

# --- Example Usage ---
if __name__ == "__main__":
    print("--- Testing Weaver Tools ---")

    # --- Profiler Test ---
    print("\n--- Performance Profiler Test ---")
    profiler = PerformanceProfiler()
    profiler.start_monitoring()
    
    # Simulate a running process (in a real scenario, this would be a subprocess)
    # For this test, we monitor the current python process
    try:
        current_process = psutil.Process(os.getpid())
        profiler.add_block("test_block_1", current_process)
        
        print("Monitoring current process for 5 seconds...")
        time.sleep(5)
        
        profile = profiler.get_profile("test_block_1")
        if profile and profile.metrics_history:
            print(f"Collected {len(profile.metrics_history)} metric snapshots.")
            last_metric = profile.metrics_history[-1]
            print(f"Last CPU: {last_metric.cpu_percent:.2f}%, Last Memory: {last_metric.memory_mb:.2f} MB")
            print(f"Identified usage pattern: {profile.usage_pattern}")
        else:
            print("Failed to collect metrics.")
            
    except Exception as e:
        print(f"Could not run profiler test: {e}")
    finally:
        profiler.stop_monitoring()


    # --- Message Debugger Test ---
    print("\n--- Message Debugger Test ---")
    debugger = MessageDebugger()
    
    # Simulate some message traffic
    debugger.log_message(Message("block_A", "block_B", {"data": "hello world"}))
    debugger.log_message(Message("block_B", "block_C", {"value": 123}))
    debugger.log_message(Message("block_A", "BROADCAST", {"alert": "system update"}))
    
    all_msgs = debugger.get_messages()
    print(f"Logged {len(all_msgs)} messages.")
    
    filtered_msgs = debugger.get_messages(filter_text="block_A")
    print(f"Found {len(filtered_msgs)} messages from 'block_A'.")

    stats = debugger.get_stats()
    print("Message Stats:")
    import json
    print(json.dumps(stats, indent=2))
