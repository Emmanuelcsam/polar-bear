Automated Fiber Optic Inspection System
Updates: Balancing 3 Dimensional Analysis with Democracy 

Pixel Vectors
Self adjusting algorithm
Reinforcement learning
Situational based computations

System Architecture

app.py - Main
Coordinates the entire workflow
Manages configuration and file paths
process.py - Image Preprocessing
Applies multiple OpenCV transformations
Creates reimagined versions of input images
Splits image into 49 variations based on opencv tutorials
separation.py - Fiber Segmentation
Identifies core, cladding, and ferrule regions
Uses multiple methods with consensus voting (Democracy)
Learns how to better separate from output
detection.py - Defect Detection
Uses research method and thresholding 
Creates comparison
data_acquisition.py - Results Aggregation
Combines all detection results
Removes duplicates and generates final report

Input Image → Processing → Separation → Detection → Data Acquisition 

(Pre)Processing
Purpose: Creates multiple filtered versions to enhance defect visibility
Function: reimagine_image(image_path, output_folder)
Applied Transformations:
Thresholding (8 types):
Binary, Binary Inverse, Truncate
To Zero, To Zero Inverse
Adaptive Mean, Adaptive Gaussian
Otsu's Method
Color Space Conversions:
HSV, LAB
12 different colormaps (Jet, Rainbow, Hot, etc.)
Preprocessing Filters:
Gaussian Blur, Median Blur, Bilateral Filter
Morphological operations (Erode, Dilate, Open, Close)
Edge detection (Canny, Sobel, Laplacian)

Thresholding Techniques
Binary Threshold:
ret, thresh_binary = cv2.threshold(gray_img, 127, 255, cv2.THRESH_BINARY)
# Pixels > 127 → 255 (white)
# Pixels ≤ 127 → 0 (black)
Adaptive Threshold:
adaptive_thresh_gaussian = cv2.adaptiveThreshold(
    gray_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
    cv2.THRESH_BINARY, 11, 2
)
# Threshold varies based on local neighborhood
Otsu's Method:
ret, otsu_thresh = cv2.threshold(
    gray_img, 0, 255, 
    cv2.THRESH_BINARY + cv2.THRESH_OTSU
)
# Automatically calculates optimal threshold


(Pre)Processing
Morphological Transformations
Kernel Creation:
kernel = np.ones((5,5), np.uint8)
Operations:
Erosion - Removes pixels at boundarieseroded = cv2.erode(thresh_binary, kernel, iterations=1)
Dilation - Adds pixels to boundariesdilated = cv2.dilate(thresh_binary, kernel, iterations=1)
Opening - Erosion followed by dilation (removes noise)opening = cv2.morphologyEx(thresh_binary, cv2.MORPH_OPEN, kernel)
Closing - Dilation followed by erosion (fills gaps)closing = cv2.morphologyEx(thresh_binary, cv2.MORPH_CLOSE, kernel)

Separation Process
Isolation
Function: run_method_isolated(method_name, image_path, temp_output)
Process:
Generate Runner Script:script_content = f"""
import sys, json, os
from pathlib import Path
import matplotlib
matplotlib.use('Agg')  # Non-interactive backend
os.environ['QT_QPA_PLATFORM'] = 'offscreen'
sys.path.insert(0, r"{self.methods_dir.resolve()}")"""
Execute in Subprocess:subprocess.run(
    [sys.executable, str(runner_script_path)],
    capture_output=True, text=True, timeout=120,
    env={**os.environ, 'QT_QPA_PLATFORM': 'offscreen'}
)
Effects:
Prevents method crashes from affecting main process
2-minute timeout for hung processes
Isolated environment for each method


Consensus Process
Stage 1: Weighted Pixel Vote
weighted_votes = np.zeros((h, w, 3), dtype=np.float32)  # [core, cladding, ferrule]
for result in valid_results:
    weight = method_scores[result.method_name] * result.confidence
    weighted_votes[:,:,0] += (result.masks['core'] > 0) * weight
Stage 2: Find High-Agreement Methods
for result in valid_results:
    core_iou = calculate_iou(result.masks['core'], prelim_core_mask)
    if core_iou > 0.6 and cladding_iou > 0.6:
        high_agreement_results.append(result)
Stage 3: Average Parameters
final_center = (np.average(cx_list, weights=weights), 
                np.average(cy_list, weights=weights))
final_core_radius = np.average(core_radii, weights=weights)

Performance Tracking
Function: update_learning(consensus, all_results)
python
# Evaluate each method against consensus
for result in all_results:
    core_iou = calculate_iou(result.masks['core'], consensus_masks['core'])
    cladding_iou = calculate_iou(result.masks['cladding'], consensus_masks['cladding'])
    avg_iou = (core_iou + cladding_iou) / 2
    
    # Update score with exponential moving average
    learning_rate = 0.1
    target_score = 0.1 + (1.9 * avg_iou)  # Map IoU [0,1] to [0.1,2.0]
    new_score = current_score * (1-learning_rate) + target_score * learning_rate
    
    self.dataset_stats['method_scores'][result.method_name] = new_score
Result: Methods that agree with consensus get higher weights in future runs




 Detection
feature_extractors = [
    ("Stats", self._extract_statistical_features),      # mean, std, skew, kurtosis
    ("LBP", self._extract_lbp_features),               # texture patterns
    ("GLCM", self._extract_glcm_features),             # co-occurrence matrix
    ("FFT", self._extract_fourier_features),           # frequency domain
    ("Gradient", self._extract_gradient_features),      # edge information
    ("SVD", self._extract_svd_features),               # singular values
    ("Entropy", self._extract_entropy_features),        # information content
    ("Morph", self._extract_morphological_features),    # shape metrics
]

for name, extractor in feature_extractors:
    features.update(extractor(gray_image))

1. Global Analysis - Mahalanobis Distance: how far a data point is from a distribution, taking into account the distribution's shape and orientation
diff = test_vector - reference_mean
mahalanobis_dist = np.sqrt(diff.T @ inv_covariance @ diff)
2. Structural Similarity index measure (SSIM):
ssim_index = compute_ssim(test_image, reference_archetype)
3. Local Anomaly Map:
# Sliding window comparison
for y in range(0, h-win_size, stride):
    for x in range(0, w-win_size, stride):
        local_score = compare_windows(test_win, ref_win)
        anomaly_map[y:y+win_size, x:x+win_size] = max(anomaly_map, local_score)
4. Specific Defect Detection:
Scratches: Hough line detection
Digs: Black-hat morphology
Contamination: Blob detection
Detection

Next Iteration
Increase speed of detection
Large Dataset Training Using HPC Units
Increase saved variables 
Add Adaptive Parameter Tuning
Add Feature-Based Similarity Detection
Defect-Specific Learning: Each defect type builds its own pattern library
Parameter Optimization: Learns optimal scales, kernel sizes, etc. for specific defects
Template Matching: Directly looks for similar visual patterns
Feature Signatures: Learns statistical properties of each defect type
Gets better at finding defects similar to ones it's seen
use the best-performing algorithms based on historical data
Split into modules
Separation improvements
Integrate more learning algorithms into separation.py
Make separation.py auto import algorithms based on folder









