META-TOOLS FOLDER - DETAILED FILE DESCRIPTIONS
===============================================

QUICK DEBRIEF (First 5 Points):
1. The meta-tools folder contains 30+ utility scripts for data analysis, file organization, and machine learning workflows
2. Most scripts feature interactive modes (no command-line arguments needed) and auto-install dependencies
3. Core functionality includes duplicate detection, image processing, dataset augmentation, and project analysis
4. Scripts are designed for fiber optic inspection workflows but are general-purpose tools
5. All tools include comprehensive logging, progress tracking, and detailed reporting capabilities

DETAILED FILE DESCRIPTIONS:
==========================

ADVANCED IMAGE PROCESSING & CLUSTERING:
---------------------------------------

adv-sort.py (226 lines)
- ADVANCED CHARACTER/IMAGE SORTER with adaptive clustering
- Uses perceptual hashing (pHash/dHash) and color histograms for image similarity
- Implements DBSCAN clustering with adaptive epsilon adjustment
- Features SQLite caching (features.sqlite) for performance optimization
- Creates JSON/TXT reports and color-coded montages per cluster
- Interactive mode with configurable outlier percentage targets
- Supports classification rules from external classification.txt file
- Handles large datasets with efficient feature vector computation

character-sort.py (191 lines)
- Lightweight version of image clustering using perceptual hashing only
- Simple implementation focusing on basic similarity detection
- Uses DBSCAN clustering with standard scaling
- Extracts perceptual hash and color histogram features
- Creates organized output directories for clustered images
- Ideal for quick image organization tasks without advanced features

DATASET ANALYSIS & MANAGEMENT:
------------------------------

analyze_dataset.py (148 lines)
- Comprehensive image dataset analyzer for machine learning workflows
- Calculates file hashes (MD5) for duplicate detection
- Extracts image properties: dimensions, color mode, format
- Computes statistical metrics: mean/std/min/max intensity
- Special fiber optic analysis: detects circular content patterns
- Generates detailed analysis reports in JSON format
- Supports various image formats through PIL integration

augment_dataset.py (227 lines)
- Professional data augmentation tool for machine learning datasets
- Implements 5 augmentation techniques: rotation, noise, brightness, blur, elastic transform
- Configurable augmentation factor (default: 5 versions per image)
- Ensures minimum images per class for balanced datasets
- Uses reproducible random seeding (seed=42) for consistent results
- Applies OpenCV transformations with parameter randomization
- Designed specifically for fiber optic image datasets

generate_augmentations.py (327 lines)
- Advanced augmentation using Albumentations library
- Loads configuration from JSON files for customizable parameters
- Implements fiber optic-specific augmentations: scratch simulation
- Professional-grade transformations: RandomRotate90, ShiftScaleRotate
- Applies realistic noise, blur, and brightness adjustments
- Tracks creation count for monitoring augmentation progress
- Supports complex elastic deformations for realistic variations

simple_augment.py (249 lines)
- Simplified augmentation tool with basic transformations
- Implements rotation, brightness adjustment, and Gaussian noise
- Features custom scratch and contamination simulation
- Uses reproducible seeding for consistent results
- Direct OpenCV implementation without external libraries
- Ideal for quick dataset expansion without complex dependencies

reorganize_dataset.py (474 lines)
- Intelligent dataset reorganization based on naming conventions
- Extracts conditions from directory names: clean, scratched, contaminated, etc.
- Identifies fiber types: 91, 50, SMA from directory structure
- Generates systematic filenames with condition and type metadata
- Implements file hash verification for integrity checking
- Creates organized directory structures for machine learning workflows
- Supports multiple contamination levels and fiber specifications

DUPLICATE DETECTION & CLEANUP:
------------------------------

duplicate-file-remover.py (465 lines)
- Comprehensive duplicate file finder and remover with safety features
- Auto-installs dependencies (tqdm, colorama) for enhanced user experience
- Interactive mode with detailed logging and progress tracking
- Content-based deduplication using SHA-256 hashing
- Safe deletion with trash folder option for recovery
- Handles large directories with memory-efficient processing
- Generates detailed reports of removed duplicates and space savings

duplicate-finder.py (255 lines)
- Basic duplicate detection tool for general file management
- Identifies duplicates by content hash with configurable minimum size
- Two-pass algorithm: size grouping followed by hash comparison
- Integrated with configuration system for ignore patterns
- Generates cleanup suggestions without automatic deletion
- Tracks total waste and provides storage optimization insights
- Works with directory tree traversal and hidden file filtering

duplicate-img-remover.py (602 lines)
- Exact duplicate image detector for 100% identical matches
- Byte-for-byte comparison using SHA-256 hashing
- Auto-installs PIL, tqdm, colorama for enhanced functionality
- Interactive preview mode for visual confirmation
- Comprehensive logging with timestamp and progress tracking
- Supports all major image formats through PIL integration
- Safe deletion with detailed reporting and recovery options

duplicate-img-remover-advanced.py (796 lines)
- Advanced visual content-based duplicate detection system
- Multiple detection methods: exact match, perceptual hash, color histogram
- Smart similarity threshold adjustment for different image types
- Visual preview option for manual verification
- Comprehensive dependency management and auto-installation
- Detailed analysis reports with similarity scores
- Handles visually identical images with different names/formats

SYSTEM UTILITIES & FILE MANAGEMENT:
-----------------------------------

empty-folder-remover.py (296 lines)
- Robust recursive empty directory removal tool
- Color-coded terminal output with timestamp logging
- Dependency checking and auto-installation capabilities
- Interactive confirmation for safe operation
- Handles nested empty directories efficiently
- Comprehensive error handling and recovery
- Detailed operation reports with statistics

file-crawl.py (358 lines)
- Deep file crawler and organizer with keyword-based searching
- Two modes: single search and batch search operations
- Case-insensitive substring and regex matching
- Cross-platform compatibility (Windows/macOS/Linux)
- UTF-8 logging with JSON reports and statistics
- Duplicate handling with hash-based renaming
- Optional tqdm progress bars for large operations

file_type_extractor.py (495 lines)
- Specialized tool for extracting files by type from directory trees
- Interactive mode with multiple file type support
- Intelligent duplicate handling with automatic renaming
- Progress tracking and comprehensive logging
- Auto-installs dependencies for enhanced functionality
- Generates detailed extraction reports with statistics
- Handles complex directory structures efficiently

folder_file_renamer.py (371 lines)
- Systematic file renaming based on parent directory names
- Color-coded terminal interface with timestamp logging
- Dependency management with automatic installation
- Preserves file extensions while updating base names
- Handles naming conflicts with intelligent numbering
- Comprehensive backup and recovery options
- Detailed operation logs with before/after tracking

IMAGE ORGANIZATION & ANALYSIS:
------------------------------

image-crawler.py / img-crawl.py (723/724 lines) [Nearly identical tools]
- Deep recursive image discovery and organization systems
- Automatic duplicate detection with SHA-256 hashing
- Interactive execution of organization scripts
- Comprehensive unit testing suites included
- Windows-compatible with ASCII output formatting
- Auto-dependency installation and management
- Detailed logging with UTF-8 encoding support

img_csv.py (115 lines)
- Converts single images to detailed CSV pixel data files
- Grayscale conversion with pixel-by-pixel analysis
- Exports X/Y coordinates, grayscale values, and binary representations
- Includes comprehensive image metadata in CSV headers
- Handles various image formats through OpenCV integration
- Useful for detailed image analysis and machine learning preprocessing

size-sort.py (252 lines)
- Image organization tool based on pixel dimensions
- Interactive mode with yes/no confirmation prompts
- Sorts images into resolution-based folders
- PIL integration for accurate dimension detection
- Handles various image formats with error recovery
- User-friendly directory selection and validation

PROJECT ANALYSIS & STATISTICS:
------------------------------

project-stats.py (1013 lines)
- Comprehensive directory analysis with neural network visualization
- Auto-installs dependencies: networkx, matplotlib, plotly, pandas, numpy
- Analyzes file relationships and code dependencies
- Generates interactive reports with network graphs
- Creates visual representations of project structure
- Professional HTML reports with embedded visualizations
- Supports multiple programming languages and frameworks

project-stats-lite.py (462 lines)
- Minimal but robust directory analyzer
- Interactive configuration with date filtering
- Dependency graph creation with NetworkX
- Plotly visualizations for project insights
- HTML report generation with Jinja2 templates
- File pattern analysis and statistics
- Connection mapping between project components

CODE ANALYSIS & DEVELOPMENT:
----------------------------

code-analyzer.py (386 lines)
- Multi-language code dependency analyzer
- Maps imports, function calls, and code relationships
- Supports Python, JavaScript, Java, C++, C, Go
- AST parsing for accurate code structure analysis
- Complexity metrics and statistics calculation
- Interactive configuration with ConfigLoader integration
- Detailed reporting of code organization and dependencies

templater.py (523 lines)
- Enhanced subfolder and file generator with advanced features
- Robust error handling and dependency management
- JSON configuration support for complex structures
- Path cleaning and normalization utilities
- Cross-platform compatibility with proper escaping
- Interactive mode for dynamic content creation
- Comprehensive logging and progress tracking

TESTING & CONFIGURATION:
------------------------

test_duplicate_remover.py (66 lines)
- Unit test suite for duplicate removal functionality
- Creates temporary test environments with known duplicates
- Validates SHA-256 hash calculations
- Tests exact duplicate detection accuracy
- Verifies different content detection capabilities
- Simple but comprehensive test coverage

SUPPORTING FILES:
----------------

requirements.txt
- Comprehensive dependency list for the entire meta-tools suite
- Includes core libraries: numpy, opencv-python, scikit-learn
- Web scraping tools: selenium, webdriver-manager, beautifulsoup4
- CAPTCHA handling: pytesseract, Pillow, pyautogui
- Data processing: pandas, matplotlib, reportlab
- Hardware interfaces: mpremote, pyserial, watchdog

features.sqlite
- SQLite database for caching image feature vectors
- Stores perceptual hash and color histogram data
- Optimizes performance for repeat image analysis
- Used by advanced sorting and clustering tools
- Persistent storage for large dataset processing

summary.txt
- Example output from image clustering operations
- Shows results: 351 total images organized into 35 groups
- Demonstrates clustering effectiveness with 273 unique images
- Provides template for understanding clustering results
- Statistical breakdown of group sizes and distributions

fiber_optic_classification_report.md
- Detailed analysis report for fiber optic end face classification
- Categorizes 19 images into defect types: scratches, UBET defects
- Provides percentage breakdowns and file listings
- Describes visual characteristics of each defect category
- Professional documentation template for ML classification results

zen-reader-v1.html (3758 lines)
- Advanced text reading application with focus enhancement
- Modern CSS styling with glass morphism effects
- Interactive reading modes and comprehension tools
- Professional typography and responsive design
- Reading analytics and progress tracking
- Accessibility features and customization options

SUMMARY STATISTICS:
==================
- Total Scripts: 30+ utility tools
- Lines of Code: ~15,000+ across all files
- Primary Languages: Python (100% of scripts)
- Dependencies: Auto-managed with pip installation
- Target Domain: Machine learning, data analysis, file management
- Key Features: Interactive modes, comprehensive logging, progress tracking
- Platform Support: Cross-platform (Windows/macOS/Linux)
- Documentation: Inline comments and detailed docstrings
- Error Handling: Robust with recovery mechanisms
- Testing: Unit tests included for critical components

The meta-tools folder represents a comprehensive toolkit for data scientists and machine learning engineers working with image datasets, particularly in the fiber optic inspection domain. Each tool is designed for standalone operation while maintaining integration capabilities for complex workflows.
